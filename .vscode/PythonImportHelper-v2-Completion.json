[
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "sphinx_rtd_theme",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sphinx_rtd_theme",
        "description": "sphinx_rtd_theme",
        "detail": "sphinx_rtd_theme",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "elegantrl.agents",
        "description": "elegantrl.agents",
        "isExtraImport": true,
        "detail": "elegantrl.agents",
        "documentation": {}
    },
    {
        "label": "AgentA2C",
        "importPath": "elegantrl.agents",
        "description": "elegantrl.agents",
        "isExtraImport": true,
        "detail": "elegantrl.agents",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "elegantrl.train.config",
        "description": "elegantrl.train.config",
        "isExtraImport": true,
        "detail": "elegantrl.train.config",
        "documentation": {}
    },
    {
        "label": "train_agent",
        "importPath": "elegantrl.train.run",
        "description": "elegantrl.train.run",
        "isExtraImport": true,
        "detail": "elegantrl.train.run",
        "documentation": {}
    },
    {
        "label": "copy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "copy",
        "description": "copy",
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "random",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "random",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "AdamW",
        "importPath": "torch.optim",
        "description": "torch.optim",
        "isExtraImport": true,
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "Batch",
        "importPath": "torch_geometric.data",
        "description": "torch_geometric.data",
        "isExtraImport": true,
        "detail": "torch_geometric.data",
        "documentation": {}
    },
    {
        "label": "Data",
        "importPath": "torch_geometric.data",
        "description": "torch_geometric.data",
        "isExtraImport": true,
        "detail": "torch_geometric.data",
        "documentation": {}
    },
    {
        "label": "RGCNConv",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "Sequential",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "to_dense_batch",
        "importPath": "torch_geometric.utils",
        "description": "torch_geometric.utils",
        "isExtraImport": true,
        "detail": "torch_geometric.utils",
        "documentation": {}
    },
    {
        "label": "deque",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "random",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "IterableDataset",
        "importPath": "torch.utils.data.dataset",
        "description": "torch.utils.data.dataset",
        "isExtraImport": true,
        "detail": "torch.utils.data.dataset",
        "documentation": {}
    },
    {
        "label": "ray",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ray",
        "description": "ray",
        "detail": "ray",
        "documentation": {}
    },
    {
        "label": "tune",
        "importPath": "ray",
        "description": "ray",
        "isExtraImport": true,
        "detail": "ray",
        "documentation": {}
    },
    {
        "label": "pprint",
        "importPath": "pprint",
        "description": "pprint",
        "isExtraImport": true,
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "pprint",
        "importPath": "pprint",
        "description": "pprint",
        "isExtraImport": true,
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "pprint",
        "importPath": "pprint",
        "description": "pprint",
        "isExtraImport": true,
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "pprint",
        "importPath": "pprint",
        "description": "pprint",
        "isExtraImport": true,
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "ConcurrencyLimiter",
        "importPath": "ray.tune.search",
        "description": "ray.tune.search",
        "isExtraImport": true,
        "detail": "ray.tune.search",
        "documentation": {}
    },
    {
        "label": "Algorithm",
        "importPath": "ray.rllib.algorithms",
        "description": "ray.rllib.algorithms",
        "isExtraImport": true,
        "detail": "ray.rllib.algorithms",
        "documentation": {}
    },
    {
        "label": "register_env",
        "importPath": "ray.tune",
        "description": "ray.tune",
        "isExtraImport": true,
        "detail": "ray.tune",
        "documentation": {}
    },
    {
        "label": "RunConfig",
        "importPath": "ray.air",
        "description": "ray.air",
        "isExtraImport": true,
        "detail": "ray.air",
        "documentation": {}
    },
    {
        "label": "FailureConfig",
        "importPath": "ray.air",
        "description": "ray.air",
        "isExtraImport": true,
        "detail": "ray.air",
        "documentation": {}
    },
    {
        "label": "ScalingConfig",
        "importPath": "ray.air",
        "description": "ray.air",
        "isExtraImport": true,
        "detail": "ray.air",
        "documentation": {}
    },
    {
        "label": "TuneConfig",
        "importPath": "ray.tune.tune_config",
        "description": "ray.tune.tune_config",
        "isExtraImport": true,
        "detail": "ray.tune.tune_config",
        "documentation": {}
    },
    {
        "label": "CheckpointConfig",
        "importPath": "ray.air.config",
        "description": "ray.air.config",
        "isExtraImport": true,
        "detail": "ray.air.config",
        "documentation": {}
    },
    {
        "label": "psutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "psutil",
        "description": "psutil",
        "detail": "psutil",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "a2c",
        "importPath": "ray.rllib.algorithms.a2c",
        "description": "ray.rllib.algorithms.a2c",
        "isExtraImport": true,
        "detail": "ray.rllib.algorithms.a2c",
        "documentation": {}
    },
    {
        "label": "ddpg",
        "importPath": "ray.rllib.algorithms.ddpg",
        "description": "ray.rllib.algorithms.ddpg",
        "isExtraImport": true,
        "detail": "ray.rllib.algorithms.ddpg",
        "documentation": {}
    },
    {
        "label": "ppo",
        "importPath": "ray.rllib.algorithms.ppo",
        "description": "ray.rllib.algorithms.ppo",
        "isExtraImport": true,
        "detail": "ray.rllib.algorithms.ppo",
        "documentation": {}
    },
    {
        "label": "sac",
        "importPath": "ray.rllib.algorithms.sac",
        "description": "ray.rllib.algorithms.sac",
        "isExtraImport": true,
        "detail": "ray.rllib.algorithms.sac",
        "documentation": {}
    },
    {
        "label": "td3",
        "importPath": "ray.rllib.algorithms.td3",
        "description": "ray.rllib.algorithms.td3",
        "isExtraImport": true,
        "detail": "ray.rllib.algorithms.td3",
        "documentation": {}
    },
    {
        "label": "optuna",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "optuna",
        "description": "optuna",
        "detail": "optuna",
        "documentation": {}
    },
    {
        "label": "NormalActionNoise",
        "importPath": "stable_baselines3.common.noise",
        "description": "stable_baselines3.common.noise",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.noise",
        "documentation": {}
    },
    {
        "label": "OrnsteinUhlenbeckActionNoise",
        "importPath": "stable_baselines3.common.noise",
        "description": "stable_baselines3.common.noise",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.noise",
        "documentation": {}
    },
    {
        "label": "NormalActionNoise",
        "importPath": "stable_baselines3.common.noise",
        "description": "stable_baselines3.common.noise",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.noise",
        "documentation": {}
    },
    {
        "label": "OrnsteinUhlenbeckActionNoise",
        "importPath": "stable_baselines3.common.noise",
        "description": "stable_baselines3.common.noise",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.noise",
        "documentation": {}
    },
    {
        "label": "linear_schedule",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "A2C",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "DDPG",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "PPO",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "SAC",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "TD3",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "A2C",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "DDPG",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "PPO",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "SAC",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "TD3",
        "importPath": "stable_baselines3",
        "description": "stable_baselines3",
        "isExtraImport": true,
        "detail": "stable_baselines3",
        "documentation": {}
    },
    {
        "label": "BaseCallback",
        "importPath": "stable_baselines3.common.callbacks",
        "description": "stable_baselines3.common.callbacks",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.callbacks",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "SubprocVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "DummyVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "SubprocVecEnv",
        "importPath": "stable_baselines3.common.vec_env",
        "description": "stable_baselines3.common.vec_env",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.vec_env",
        "documentation": {}
    },
    {
        "label": "config",
        "importPath": "finrl",
        "description": "finrl",
        "isExtraImport": true,
        "detail": "finrl",
        "documentation": {}
    },
    {
        "label": "config",
        "importPath": "finrl",
        "description": "finrl",
        "isExtraImport": true,
        "detail": "finrl",
        "documentation": {}
    },
    {
        "label": "config",
        "importPath": "finrl",
        "description": "finrl",
        "isExtraImport": true,
        "detail": "finrl",
        "documentation": {}
    },
    {
        "label": "config_tickers",
        "importPath": "finrl",
        "description": "finrl",
        "isExtraImport": true,
        "detail": "finrl",
        "documentation": {}
    },
    {
        "label": "config",
        "importPath": "finrl",
        "description": "finrl",
        "isExtraImport": true,
        "detail": "finrl",
        "documentation": {}
    },
    {
        "label": "config",
        "importPath": "finrl",
        "description": "finrl",
        "isExtraImport": true,
        "detail": "finrl",
        "documentation": {}
    },
    {
        "label": "config_tickers",
        "importPath": "finrl",
        "description": "finrl",
        "isExtraImport": true,
        "detail": "finrl",
        "documentation": {}
    },
    {
        "label": "config_tickers",
        "importPath": "finrl",
        "description": "finrl",
        "isExtraImport": true,
        "detail": "finrl",
        "documentation": {}
    },
    {
        "label": "config",
        "importPath": "finrl",
        "description": "finrl",
        "isExtraImport": true,
        "detail": "finrl",
        "documentation": {}
    },
    {
        "label": "config_tickers",
        "importPath": "finrl",
        "description": "finrl",
        "isExtraImport": true,
        "detail": "finrl",
        "documentation": {}
    },
    {
        "label": "config_tickers",
        "importPath": "finrl",
        "description": "finrl",
        "isExtraImport": true,
        "detail": "finrl",
        "documentation": {}
    },
    {
        "label": "config",
        "importPath": "finrl",
        "description": "finrl",
        "isExtraImport": true,
        "detail": "finrl",
        "documentation": {}
    },
    {
        "label": "config_tickers",
        "importPath": "finrl",
        "description": "finrl",
        "isExtraImport": true,
        "detail": "finrl",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "finrl.meta.env_stock_trading.env_stocktrading",
        "description": "finrl.meta.env_stock_trading.env_stocktrading",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "finrl.meta.env_stock_trading.env_stocktrading",
        "description": "finrl.meta.env_stock_trading.env_stocktrading",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "finrl.meta.env_stock_trading.env_stocktrading",
        "description": "finrl.meta.env_stock_trading.env_stocktrading",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "finrl.meta.env_stock_trading.env_stocktrading",
        "description": "finrl.meta.env_stock_trading.env_stocktrading",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "finrl.meta.env_stock_trading.env_stocktrading",
        "description": "finrl.meta.env_stock_trading.env_stocktrading",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "finrl.meta.env_stock_trading.env_stocktrading",
        "description": "finrl.meta.env_stock_trading.env_stocktrading",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "finrl.meta.env_stock_trading.env_stocktrading",
        "description": "finrl.meta.env_stock_trading.env_stocktrading",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "data_split",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "GroupByScaler",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "importPath": "finrl.meta.preprocessor.preprocessors",
        "description": "finrl.meta.preprocessor.preprocessors",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "datetime",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "datetime",
        "description": "datetime",
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "joblib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "joblib",
        "description": "joblib",
        "detail": "joblib",
        "documentation": {}
    },
    {
        "label": "finrl.agents.stablebaselines3.hyperparams_opt",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "finrl.agents.stablebaselines3.hyperparams_opt",
        "description": "finrl.agents.stablebaselines3.hyperparams_opt",
        "detail": "finrl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "importPath": "finrl.agents.stablebaselines3.models",
        "description": "finrl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "finrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "importPath": "finrl.agents.stablebaselines3.models",
        "description": "finrl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "finrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "importPath": "finrl.agents.stablebaselines3.models",
        "description": "finrl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "finrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "importPath": "finrl.agents.stablebaselines3.models",
        "description": "finrl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "finrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLEnsembleAgent",
        "importPath": "finrl.agents.stablebaselines3.models",
        "description": "finrl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "finrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "importPath": "finrl.agents.stablebaselines3.models",
        "description": "finrl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "finrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLEnsembleAgent",
        "importPath": "finrl.agents.stablebaselines3.models",
        "description": "finrl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "finrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "importPath": "finrl.agents.stablebaselines3.models",
        "description": "finrl.agents.stablebaselines3.models",
        "isExtraImport": true,
        "detail": "finrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "check_and_make_directories",
        "importPath": "finrl.main",
        "description": "finrl.main",
        "isExtraImport": true,
        "detail": "finrl.main",
        "documentation": {}
    },
    {
        "label": "check_and_make_directories",
        "importPath": "finrl.main",
        "description": "finrl.main",
        "isExtraImport": true,
        "detail": "finrl.main",
        "documentation": {}
    },
    {
        "label": "check_and_make_directories",
        "importPath": "finrl.main",
        "description": "finrl.main",
        "isExtraImport": true,
        "detail": "finrl.main",
        "documentation": {}
    },
    {
        "label": "check_and_make_directories",
        "importPath": "finrl.main",
        "description": "finrl.main",
        "isExtraImport": true,
        "detail": "finrl.main",
        "documentation": {}
    },
    {
        "label": "check_and_make_directories",
        "importPath": "finrl.main",
        "description": "finrl.main",
        "isExtraImport": true,
        "detail": "finrl.main",
        "documentation": {}
    },
    {
        "label": "check_and_make_directories",
        "importPath": "finrl.main",
        "description": "finrl.main",
        "isExtraImport": true,
        "detail": "finrl.main",
        "documentation": {}
    },
    {
        "label": "check_and_make_directories",
        "importPath": "finrl.main",
        "description": "finrl.main",
        "isExtraImport": true,
        "detail": "finrl.main",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "plot_return",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_plot",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_daily_return",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "plot_return",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_plot",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_daily_return",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_plot",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_daily_return",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_plot",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_daily_return",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_plot",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_daily_return",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_plot",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_daily_return",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_plot",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_daily_return",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_plot",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_daily_return",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "importPath": "finrl.plot",
        "description": "finrl.plot",
        "isExtraImport": true,
        "detail": "finrl.plot",
        "documentation": {}
    },
    {
        "label": "itertools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "itertools",
        "description": "itertools",
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "configure",
        "importPath": "stable_baselines3.common.logger",
        "description": "stable_baselines3.common.logger",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "configure",
        "importPath": "stable_baselines3.common.logger",
        "description": "stable_baselines3.common.logger",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "configure",
        "importPath": "stable_baselines3.common.logger",
        "description": "stable_baselines3.common.logger",
        "isExtraImport": true,
        "detail": "stable_baselines3.common.logger",
        "documentation": {}
    },
    {
        "label": "DATA_SAVE_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAINED_MODEL_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "DATA_SAVE_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAINED_MODEL_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "ERL_PARAMS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "RLlib_PARAMS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "SAC_PARAMS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "RLlib_PARAMS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_BASE_URL",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "DATA_SAVE_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "ERL_PARAMS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAINED_MODEL_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "RLlib_PARAMS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "ERL_PARAMS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "RLlib_PARAMS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "SAC_PARAMS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "DATA_SAVE_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAINED_MODEL_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "DATA_SAVE_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAINED_MODEL_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "ERL_PARAMS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "RLlib_PARAMS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "SAC_PARAMS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "RLlib_PARAMS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "DATA_SAVE_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAINED_MODEL_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_START_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_END_DATE",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "DATA_SAVE_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "TRAINED_MODEL_DIR",
        "importPath": "finrl.config",
        "description": "finrl.config",
        "isExtraImport": true,
        "detail": "finrl.config",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "importPath": "finrl.config_tickers",
        "description": "finrl.config_tickers",
        "isExtraImport": true,
        "detail": "finrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "finrl.meta.preprocessor.yahoodownloader",
        "description": "finrl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "finrl.meta.preprocessor.yahoodownloader",
        "description": "finrl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "finrl.meta.preprocessor.yahoodownloader",
        "description": "finrl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "finrl.meta.preprocessor.yahoodownloader",
        "description": "finrl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "finrl.meta.preprocessor.yahoodownloader",
        "description": "finrl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "finrl.meta.preprocessor.yahoodownloader",
        "description": "finrl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "finrl.meta.preprocessor.yahoodownloader",
        "description": "finrl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "finrl.meta.preprocessor.yahoodownloader",
        "description": "finrl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "finrl.meta.preprocessor.yahoodownloader",
        "description": "finrl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "finrl.meta.preprocessor.yahoodownloader",
        "description": "finrl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "finrl.meta.preprocessor.yahoodownloader",
        "description": "finrl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "importPath": "finrl.meta.preprocessor.yahoodownloader",
        "description": "finrl.meta.preprocessor.yahoodownloader",
        "isExtraImport": true,
        "detail": "finrl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "matplotlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib",
        "description": "matplotlib",
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "importPath": "finrl.meta.data_processor",
        "description": "finrl.meta.data_processor",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "importPath": "finrl.meta.data_processor",
        "description": "finrl.meta.data_processor",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "importPath": "finrl.meta.data_processor",
        "description": "finrl.meta.data_processor",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "importPath": "finrl.meta.data_processor",
        "description": "finrl.meta.data_processor",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "importPath": "finrl.meta.data_processor",
        "description": "finrl.meta.data_processor",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "importPath": "finrl.meta.data_processor",
        "description": "finrl.meta.data_processor",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "importPath": "finrl.meta.data_processor",
        "description": "finrl.meta.data_processor",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "importPath": "finrl.meta.data_processor",
        "description": "finrl.meta.data_processor",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "importPath": "finrl.meta.data_processor",
        "description": "finrl.meta.data_processor",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "calc_train_trade_data",
        "importPath": "finrl.meta.data_processors.func",
        "description": "finrl.meta.data_processors.func",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "calc_train_trade_starts_ends_if_rolling",
        "importPath": "finrl.meta.data_processors.func",
        "description": "finrl.meta.data_processors.func",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "date2str",
        "importPath": "finrl.meta.data_processors.func",
        "description": "finrl.meta.data_processors.func",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "str2date",
        "importPath": "finrl.meta.data_processors.func",
        "description": "finrl.meta.data_processors.func",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "date2str",
        "importPath": "finrl.meta.data_processors.func",
        "description": "finrl.meta.data_processors.func",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "str2date",
        "importPath": "finrl.meta.data_processors.func",
        "description": "finrl.meta.data_processors.func",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "ProcessPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ProcessPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ProcessPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "alpaca_trade_api",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "alpaca_trade_api",
        "description": "alpaca_trade_api",
        "detail": "alpaca_trade_api",
        "documentation": {}
    },
    {
        "label": "exchange_calendars",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "exchange_calendars",
        "description": "exchange_calendars",
        "detail": "exchange_calendars",
        "documentation": {}
    },
    {
        "label": "pytz",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytz",
        "description": "pytz",
        "detail": "pytz",
        "documentation": {}
    },
    {
        "label": "StockDataFrame",
        "importPath": "stockstats",
        "description": "stockstats",
        "isExtraImport": true,
        "detail": "stockstats",
        "documentation": {}
    },
    {
        "label": "StockDataFrame",
        "importPath": "stockstats",
        "description": "stockstats",
        "isExtraImport": true,
        "detail": "stockstats",
        "documentation": {}
    },
    {
        "label": "StockDataFrame",
        "importPath": "stockstats",
        "description": "stockstats",
        "isExtraImport": true,
        "detail": "stockstats",
        "documentation": {}
    },
    {
        "label": "StockDataFrame",
        "importPath": "stockstats",
        "description": "stockstats",
        "isExtraImport": true,
        "detail": "stockstats",
        "documentation": {}
    },
    {
        "label": "StockDataFrame",
        "importPath": "stockstats",
        "description": "stockstats",
        "isExtraImport": true,
        "detail": "stockstats",
        "documentation": {}
    },
    {
        "label": "StockDataFrame",
        "importPath": "stockstats",
        "description": "stockstats",
        "isExtraImport": true,
        "detail": "stockstats",
        "documentation": {}
    },
    {
        "label": "StockDataFrame",
        "importPath": "stockstats",
        "description": "stockstats",
        "isExtraImport": true,
        "detail": "stockstats",
        "documentation": {}
    },
    {
        "label": "calendar",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "calendar",
        "description": "calendar",
        "detail": "calendar",
        "documentation": {}
    },
    {
        "label": "ccxt",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ccxt",
        "description": "ccxt",
        "detail": "ccxt",
        "documentation": {}
    },
    {
        "label": "jqdatasdk",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "jqdatasdk",
        "description": "jqdatasdk",
        "detail": "jqdatasdk",
        "documentation": {}
    },
    {
        "label": "calc_all_filenames",
        "importPath": "func",
        "description": "func",
        "isExtraImport": true,
        "detail": "func",
        "documentation": {}
    },
    {
        "label": "date2str",
        "importPath": "func",
        "description": "func",
        "isExtraImport": true,
        "detail": "func",
        "documentation": {}
    },
    {
        "label": "remove_all_files",
        "importPath": "func",
        "description": "func",
        "isExtraImport": true,
        "detail": "func",
        "documentation": {}
    },
    {
        "label": "wrds",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "wrds",
        "description": "wrds",
        "detail": "wrds",
        "documentation": {}
    },
    {
        "label": "Timestamp",
        "importPath": "sqlite3",
        "description": "sqlite3",
        "isExtraImport": true,
        "detail": "sqlite3",
        "documentation": {}
    },
    {
        "label": "yfinance",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "yfinance",
        "description": "yfinance",
        "detail": "yfinance",
        "documentation": {}
    },
    {
        "label": "gymnasium",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gymnasium",
        "description": "gymnasium",
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gymnasium",
        "description": "gymnasium",
        "isExtraImport": true,
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "seeding",
        "importPath": "gymnasium.utils",
        "description": "gymnasium.utils",
        "isExtraImport": true,
        "detail": "gymnasium.utils",
        "documentation": {}
    },
    {
        "label": "seeding",
        "importPath": "gymnasium.utils",
        "description": "gymnasium.utils",
        "isExtraImport": true,
        "detail": "gymnasium.utils",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "gym",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gym",
        "description": "gym",
        "detail": "gym",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gym",
        "description": "gym",
        "isExtraImport": true,
        "detail": "gym",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gym",
        "description": "gym",
        "isExtraImport": true,
        "detail": "gym",
        "documentation": {}
    },
    {
        "label": "spaces",
        "importPath": "gym",
        "description": "gym",
        "isExtraImport": true,
        "detail": "gym",
        "documentation": {}
    },
    {
        "label": "seeding",
        "importPath": "gym.utils",
        "description": "gym.utils",
        "isExtraImport": true,
        "detail": "gym.utils",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "threading",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "threading",
        "description": "threading",
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "AlpacaProcessor",
        "importPath": "finrl.meta.data_processors.processor_alpaca",
        "description": "finrl.meta.data_processors.processor_alpaca",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.processor_alpaca",
        "documentation": {}
    },
    {
        "label": "AlpacaProcessor",
        "importPath": "finrl.meta.data_processors.processor_alpaca",
        "description": "finrl.meta.data_processors.processor_alpaca",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.processor_alpaca",
        "documentation": {}
    },
    {
        "label": "AlpacaProcessor",
        "importPath": "finrl.meta.data_processors.processor_alpaca",
        "description": "finrl.meta.data_processors.processor_alpaca",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.processor_alpaca",
        "documentation": {}
    },
    {
        "label": "AlpacaProcessor",
        "importPath": "finrl.meta.data_processors.processor_alpaca",
        "description": "finrl.meta.data_processors.processor_alpaca",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.processor_alpaca",
        "documentation": {}
    },
    {
        "label": "AlpacaProcessor",
        "importPath": "finrl.meta.data_processors.processor_alpaca",
        "description": "finrl.meta.data_processors.processor_alpaca",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.processor_alpaca",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "stable_baselines3.common",
        "description": "stable_baselines3.common",
        "isExtraImport": true,
        "detail": "stable_baselines3.common",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "stable_baselines3.common",
        "description": "stable_baselines3.common",
        "isExtraImport": true,
        "detail": "stable_baselines3.common",
        "documentation": {}
    },
    {
        "label": "AgentPPO",
        "importPath": "finrl.meta.paper_trading.common",
        "description": "finrl.meta.paper_trading.common",
        "isExtraImport": true,
        "detail": "finrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "train",
        "importPath": "finrl.meta.paper_trading.common",
        "description": "finrl.meta.paper_trading.common",
        "isExtraImport": true,
        "detail": "finrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "test",
        "importPath": "finrl.meta.paper_trading.common",
        "description": "finrl.meta.paper_trading.common",
        "isExtraImport": true,
        "detail": "finrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "alpaca_history",
        "importPath": "finrl.meta.paper_trading.common",
        "description": "finrl.meta.paper_trading.common",
        "isExtraImport": true,
        "detail": "finrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "DIA_history",
        "importPath": "finrl.meta.paper_trading.common",
        "description": "finrl.meta.paper_trading.common",
        "isExtraImport": true,
        "detail": "finrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "numpy.random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy.random",
        "description": "numpy.random",
        "detail": "numpy.random",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "Normal",
        "importPath": "torch.distributions.normal",
        "description": "torch.distributions.normal",
        "isExtraImport": true,
        "detail": "torch.distributions.normal",
        "documentation": {}
    },
    {
        "label": "Normal",
        "importPath": "torch.distributions.normal",
        "description": "torch.distributions.normal",
        "isExtraImport": true,
        "detail": "torch.distributions.normal",
        "documentation": {}
    },
    {
        "label": "Normal",
        "importPath": "torch.distributions.normal",
        "description": "torch.distributions.normal",
        "isExtraImport": true,
        "detail": "torch.distributions.normal",
        "documentation": {}
    },
    {
        "label": "Normal",
        "importPath": "torch.distributions.normal",
        "description": "torch.distributions.normal",
        "isExtraImport": true,
        "detail": "torch.distributions.normal",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "finrl.meta.env_stock_trading.env_stocktrading_np",
        "description": "finrl.meta.env_stock_trading.env_stocktrading_np",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stocktrading_np",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "finrl.meta.env_stock_trading.env_stocktrading_np",
        "description": "finrl.meta.env_stock_trading.env_stocktrading_np",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stocktrading_np",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "finrl.meta.env_stock_trading.env_stocktrading_np",
        "description": "finrl.meta.env_stock_trading.env_stocktrading_np",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stocktrading_np",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "finrl.meta.env_stock_trading.env_stocktrading_np",
        "description": "finrl.meta.env_stock_trading.env_stocktrading_np",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stocktrading_np",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "finrl.meta.env_stock_trading.env_stocktrading_np",
        "description": "finrl.meta.env_stock_trading.env_stocktrading_np",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stocktrading_np",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "finrl.meta.env_stock_trading.env_stocktrading_np",
        "description": "finrl.meta.env_stock_trading.env_stocktrading_np",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stocktrading_np",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "importPath": "finrl.meta.env_stock_trading.env_stocktrading_np",
        "description": "finrl.meta.env_stock_trading.env_stocktrading_np",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stocktrading_np",
        "documentation": {}
    },
    {
        "label": "matplotlib.ticker",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.ticker",
        "description": "matplotlib.ticker",
        "detail": "matplotlib.ticker",
        "documentation": {}
    },
    {
        "label": "matplotlib.dates",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.dates",
        "description": "matplotlib.dates",
        "detail": "matplotlib.dates",
        "documentation": {}
    },
    {
        "label": "Value",
        "importPath": "multiprocessing.sharedctypes",
        "description": "multiprocessing.sharedctypes",
        "isExtraImport": true,
        "detail": "multiprocessing.sharedctypes",
        "documentation": {}
    },
    {
        "label": "BaseEstimator",
        "importPath": "sklearn.base",
        "description": "sklearn.base",
        "isExtraImport": true,
        "detail": "sklearn.base",
        "documentation": {}
    },
    {
        "label": "TransformerMixin",
        "importPath": "sklearn.base",
        "description": "sklearn.base",
        "isExtraImport": true,
        "detail": "sklearn.base",
        "documentation": {}
    },
    {
        "label": "MaxAbsScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "MinMaxScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "tushare",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tushare",
        "description": "tushare",
        "detail": "tushare",
        "documentation": {}
    },
    {
        "label": "WrdsProcessor",
        "importPath": "finrl.meta.data_processors.processor_wrds",
        "description": "finrl.meta.data_processors.processor_wrds",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.processor_wrds",
        "documentation": {}
    },
    {
        "label": "YahooFinanceProcessor",
        "importPath": "finrl.meta.data_processors.processor_yahoofinance",
        "description": "finrl.meta.data_processors.processor_yahoofinance",
        "isExtraImport": true,
        "detail": "finrl.meta.data_processors.processor_yahoofinance",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "ArgumentParser",
        "importPath": "argparse",
        "description": "argparse",
        "isExtraImport": true,
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "pyfolio",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pyfolio",
        "description": "pyfolio",
        "detail": "pyfolio",
        "documentation": {}
    },
    {
        "label": "timeseries",
        "importPath": "pyfolio",
        "description": "pyfolio",
        "isExtraImport": true,
        "detail": "pyfolio",
        "documentation": {}
    },
    {
        "label": "AlpacaPaperTrading",
        "importPath": "finrl.meta.env_stock_trading.env_stock_papertrading",
        "description": "finrl.meta.env_stock_trading.env_stock_papertrading",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stock_papertrading",
        "documentation": {}
    },
    {
        "label": "AlpacaPaperTrading",
        "importPath": "finrl.meta.env_stock_trading.env_stock_papertrading",
        "description": "finrl.meta.env_stock_trading.env_stock_papertrading",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stock_papertrading",
        "documentation": {}
    },
    {
        "label": "AlpacaPaperTrading",
        "importPath": "finrl.meta.env_stock_trading.env_stock_papertrading",
        "description": "finrl.meta.env_stock_trading.env_stock_papertrading",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stock_papertrading",
        "documentation": {}
    },
    {
        "label": "AlpacaPaperTrading",
        "importPath": "finrl.meta.env_stock_trading.env_stock_papertrading",
        "description": "finrl.meta.env_stock_trading.env_stock_papertrading",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stock_papertrading",
        "documentation": {}
    },
    {
        "label": "test",
        "importPath": "finrl.test",
        "description": "finrl.test",
        "isExtraImport": true,
        "detail": "finrl.test",
        "documentation": {}
    },
    {
        "label": "gc",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gc",
        "description": "gc",
        "detail": "gc",
        "documentation": {}
    },
    {
        "label": "SinopacProcessor",
        "importPath": "processor_sinopac",
        "description": "processor_sinopac",
        "isExtraImport": true,
        "detail": "processor_sinopac",
        "documentation": {}
    },
    {
        "label": "SinopacProcessor",
        "importPath": "processor_sinopac",
        "description": "processor_sinopac",
        "isExtraImport": true,
        "detail": "processor_sinopac",
        "documentation": {}
    },
    {
        "label": "SinopacProcessor",
        "importPath": "processor_sinopac",
        "description": "processor_sinopac",
        "isExtraImport": true,
        "detail": "processor_sinopac",
        "documentation": {}
    },
    {
        "label": "SinopacDownloader",
        "importPath": "shioajidownloader",
        "description": "shioajidownloader",
        "isExtraImport": true,
        "detail": "shioajidownloader",
        "documentation": {}
    },
    {
        "label": "SinopacDownloader",
        "importPath": "shioajidownloader",
        "description": "shioajidownloader",
        "isExtraImport": true,
        "detail": "shioajidownloader",
        "documentation": {}
    },
    {
        "label": "SinopacDownloader",
        "importPath": "shioajidownloader",
        "description": "shioajidownloader",
        "isExtraImport": true,
        "detail": "shioajidownloader",
        "documentation": {}
    },
    {
        "label": "SinopacDownloader",
        "importPath": "shioajidownloader",
        "description": "shioajidownloader",
        "isExtraImport": true,
        "detail": "shioajidownloader",
        "documentation": {}
    },
    {
        "label": "SinopacDownloader",
        "importPath": "shioajidownloader",
        "description": "shioajidownloader",
        "isExtraImport": true,
        "detail": "shioajidownloader",
        "documentation": {}
    },
    {
        "label": "shioaji",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shioaji",
        "description": "shioaji",
        "detail": "shioaji",
        "documentation": {}
    },
    {
        "label": "Exchange",
        "importPath": "shioaji",
        "description": "shioaji",
        "isExtraImport": true,
        "detail": "shioaji",
        "documentation": {}
    },
    {
        "label": "TickSTKv1",
        "importPath": "shioaji",
        "description": "shioaji",
        "isExtraImport": true,
        "detail": "shioaji",
        "documentation": {}
    },
    {
        "label": "Exchange",
        "importPath": "shioaji",
        "description": "shioaji",
        "isExtraImport": true,
        "detail": "shioaji",
        "documentation": {}
    },
    {
        "label": "TickSTKv1",
        "importPath": "shioaji",
        "description": "shioaji",
        "isExtraImport": true,
        "detail": "shioaji",
        "documentation": {}
    },
    {
        "label": "talib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "talib",
        "description": "talib",
        "detail": "talib",
        "documentation": {}
    },
    {
        "label": "abstract",
        "importPath": "talib",
        "description": "talib",
        "isExtraImport": true,
        "detail": "talib",
        "documentation": {}
    },
    {
        "label": "abstract",
        "importPath": "talib",
        "description": "talib",
        "isExtraImport": true,
        "detail": "talib",
        "documentation": {}
    },
    {
        "label": "PaperTradingAlpaca",
        "importPath": "finrl.meta.paper_trading.alpaca",
        "description": "finrl.meta.paper_trading.alpaca",
        "isExtraImport": true,
        "detail": "finrl.meta.paper_trading.alpaca",
        "documentation": {}
    },
    {
        "label": "BDay",
        "importPath": "pandas.tseries.offsets",
        "description": "pandas.tseries.offsets",
        "isExtraImport": true,
        "detail": "pandas.tseries.offsets",
        "documentation": {}
    },
    {
        "label": "FuncAnimation",
        "importPath": "matplotlib.animation",
        "description": "matplotlib.animation",
        "isExtraImport": true,
        "detail": "matplotlib.animation",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "optimize",
        "importPath": "scipy",
        "description": "scipy",
        "isExtraImport": true,
        "detail": "scipy",
        "documentation": {}
    },
    {
        "label": "linprog",
        "importPath": "scipy.optimize",
        "description": "scipy.optimize",
        "isExtraImport": true,
        "detail": "scipy.optimize",
        "documentation": {}
    },
    {
        "label": "EfficientFrontier",
        "importPath": "pypfopt.efficient_frontier",
        "description": "pypfopt.efficient_frontier",
        "isExtraImport": true,
        "detail": "pypfopt.efficient_frontier",
        "documentation": {}
    },
    {
        "label": "pytest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytest",
        "description": "pytest",
        "detail": "pytest",
        "documentation": {}
    },
    {
        "label": "StockTradingEnvCashpenalty",
        "importPath": "finrl.meta.env_stock_trading.env_stocktrading_cashpenalty",
        "description": "finrl.meta.env_stock_trading.env_stocktrading_cashpenalty",
        "isExtraImport": true,
        "detail": "finrl.meta.env_stock_trading.env_stocktrading_cashpenalty",
        "documentation": {}
    },
    {
        "label": "getpass",
        "importPath": "getpass",
        "description": "getpass",
        "isExtraImport": true,
        "detail": "getpass",
        "documentation": {}
    },
    {
        "label": "OptionParser",
        "importPath": "optparse",
        "description": "optparse",
        "isExtraImport": true,
        "detail": "optparse",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "peewee",
        "description": "peewee",
        "isExtraImport": true,
        "detail": "peewee",
        "documentation": {}
    },
    {
        "label": "print_",
        "importPath": "peewee",
        "description": "peewee",
        "isExtraImport": true,
        "detail": "peewee",
        "documentation": {}
    },
    {
        "label": "__version__",
        "importPath": "peewee",
        "description": "peewee",
        "isExtraImport": true,
        "detail": "peewee",
        "documentation": {}
    },
    {
        "label": "CockroachDatabase",
        "importPath": "playhouse.cockroachdb",
        "description": "playhouse.cockroachdb",
        "isExtraImport": true,
        "detail": "playhouse.cockroachdb",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "playhouse.reflection",
        "description": "playhouse.reflection",
        "isExtraImport": true,
        "detail": "playhouse.reflection",
        "documentation": {}
    },
    {
        "label": "publish_cmdline",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "default_description",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "publish_cmdline",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "default_description",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "publish_cmdline",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "default_description",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "publish_cmdline",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "publish_cmdline",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "default_description",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "publish_cmdline_to_binary",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "default_description",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "publish_cmdline",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "default_description",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "publish_cmdline",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "default_description",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "publish_cmdline",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "publish_cmdline",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "default_description",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "publish_cmdline",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "default_description",
        "importPath": "docutils.core",
        "description": "docutils.core",
        "isExtraImport": true,
        "detail": "docutils.core",
        "documentation": {}
    },
    {
        "label": "locale",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "locale",
        "description": "locale",
        "detail": "locale",
        "documentation": {}
    },
    {
        "label": "manpage",
        "importPath": "docutils.writers",
        "description": "docutils.writers",
        "isExtraImport": true,
        "detail": "docutils.writers",
        "documentation": {}
    },
    {
        "label": "Writer",
        "importPath": "docutils.writers.odf_odt",
        "description": "docutils.writers.odf_odt",
        "isExtraImport": true,
        "detail": "docutils.writers.odf_odt",
        "documentation": {}
    },
    {
        "label": "Reader",
        "importPath": "docutils.writers.odf_odt",
        "description": "docutils.writers.odf_odt",
        "isExtraImport": true,
        "detail": "docutils.writers.odf_odt",
        "documentation": {}
    },
    {
        "label": "prepstyles",
        "importPath": "docutils.writers.odf_odt",
        "description": "docutils.writers.odf_odt",
        "isExtraImport": true,
        "detail": "docutils.writers.odf_odt",
        "documentation": {}
    },
    {
        "label": "find_packages",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "project",
        "kind": 5,
        "importPath": "docs.source.conf",
        "description": "docs.source.conf",
        "peekOfCode": "project = \"FinRL\"\ncopyright = \"2021, FinRL\"\nauthor = \"FinRL\"\n# The short X.Y version\nversion = \"\"\n# The full version, including alpha/beta/rc tags\nrelease = \"0.3.1\"\n# -- General configuration ---------------------------------------------------\n# If your documentation needs a minimal Sphinx version, state it here.\n#",
        "detail": "docs.source.conf",
        "documentation": {}
    },
    {
        "label": "copyright",
        "kind": 5,
        "importPath": "docs.source.conf",
        "description": "docs.source.conf",
        "peekOfCode": "copyright = \"2021, FinRL\"\nauthor = \"FinRL\"\n# The short X.Y version\nversion = \"\"\n# The full version, including alpha/beta/rc tags\nrelease = \"0.3.1\"\n# -- General configuration ---------------------------------------------------\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = '1.0'",
        "detail": "docs.source.conf",
        "documentation": {}
    },
    {
        "label": "author",
        "kind": 5,
        "importPath": "docs.source.conf",
        "description": "docs.source.conf",
        "peekOfCode": "author = \"FinRL\"\n# The short X.Y version\nversion = \"\"\n# The full version, including alpha/beta/rc tags\nrelease = \"0.3.1\"\n# -- General configuration ---------------------------------------------------\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = '1.0'\n# Add any Sphinx extension module names here, as strings. They can be",
        "detail": "docs.source.conf",
        "documentation": {}
    },
    {
        "label": "version",
        "kind": 5,
        "importPath": "docs.source.conf",
        "description": "docs.source.conf",
        "peekOfCode": "version = \"\"\n# The full version, including alpha/beta/rc tags\nrelease = \"0.3.1\"\n# -- General configuration ---------------------------------------------------\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = '1.0'\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom\n# ones.",
        "detail": "docs.source.conf",
        "documentation": {}
    },
    {
        "label": "release",
        "kind": 5,
        "importPath": "docs.source.conf",
        "description": "docs.source.conf",
        "peekOfCode": "release = \"0.3.1\"\n# -- General configuration ---------------------------------------------------\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = '1.0'\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom\n# ones.\nextensions = [\n    \"sphinx.ext.autodoc\",",
        "detail": "docs.source.conf",
        "documentation": {}
    },
    {
        "label": "extensions",
        "kind": 5,
        "importPath": "docs.source.conf",
        "description": "docs.source.conf",
        "peekOfCode": "extensions = [\n    \"sphinx.ext.autodoc\",\n    \"sphinx.ext.doctest\",\n    \"sphinx.ext.viewcode\",\n    \"sphinx.ext.githubpages\",\n    \"sphinx.ext.autosectionlabel\",\n    \"recommonmark\",  # for including markdown\n    #     'sphinx_markdown_tables'  # Support rendering tables in markdown\n]\nautodoc_mock_imports = [",
        "detail": "docs.source.conf",
        "documentation": {}
    },
    {
        "label": "autodoc_mock_imports",
        "kind": 5,
        "importPath": "docs.source.conf",
        "description": "docs.source.conf",
        "peekOfCode": "autodoc_mock_imports = [\n    \"gym\",\n    \"matplotlib\",\n    \"numpy\",\n    \"pybullet\",\n    \"torch\",\n    \"opencv-python\",\n]\npygments_style = \"sphinx\"\n# Add any paths that contain templates here, relative to this directory.",
        "detail": "docs.source.conf",
        "documentation": {}
    },
    {
        "label": "pygments_style",
        "kind": 5,
        "importPath": "docs.source.conf",
        "description": "docs.source.conf",
        "peekOfCode": "pygments_style = \"sphinx\"\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\"_templates\"]\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = ['.rst', '.md']\nsource_suffix = \".rst\"\n# The master toctree document.\nmaster_doc = \"index\"",
        "detail": "docs.source.conf",
        "documentation": {}
    },
    {
        "label": "templates_path",
        "kind": 5,
        "importPath": "docs.source.conf",
        "description": "docs.source.conf",
        "peekOfCode": "templates_path = [\"_templates\"]\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = ['.rst', '.md']\nsource_suffix = \".rst\"\n# The master toctree document.\nmaster_doc = \"index\"\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.",
        "detail": "docs.source.conf",
        "documentation": {}
    },
    {
        "label": "source_suffix",
        "kind": 5,
        "importPath": "docs.source.conf",
        "description": "docs.source.conf",
        "peekOfCode": "source_suffix = \".rst\"\n# The master toctree document.\nmaster_doc = \"index\"\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set \"language\" from the command line for these cases.\nlanguage = None\n# List of patterns, relative to source directory, that match files and",
        "detail": "docs.source.conf",
        "documentation": {}
    },
    {
        "label": "master_doc",
        "kind": 5,
        "importPath": "docs.source.conf",
        "description": "docs.source.conf",
        "peekOfCode": "master_doc = \"index\"\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set \"language\" from the command line for these cases.\nlanguage = None\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path.",
        "detail": "docs.source.conf",
        "documentation": {}
    },
    {
        "label": "language",
        "kind": 5,
        "importPath": "docs.source.conf",
        "description": "docs.source.conf",
        "peekOfCode": "language = None\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path.\nexclude_patterns = []\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = None\n# -- Options for HTML output -------------------------------------------------\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.",
        "detail": "docs.source.conf",
        "documentation": {}
    },
    {
        "label": "exclude_patterns",
        "kind": 5,
        "importPath": "docs.source.conf",
        "description": "docs.source.conf",
        "peekOfCode": "exclude_patterns = []\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = None\n# -- Options for HTML output -------------------------------------------------\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \"sphinx_rtd_theme\"\nhtml_theme_path = [sphinx_rtd_theme.get_html_theme_path()]\nhtml_logo = \"./image/logo_transparent_background.png\"",
        "detail": "docs.source.conf",
        "documentation": {}
    },
    {
        "label": "pygments_style",
        "kind": 5,
        "importPath": "docs.source.conf",
        "description": "docs.source.conf",
        "peekOfCode": "pygments_style = None\n# -- Options for HTML output -------------------------------------------------\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \"sphinx_rtd_theme\"\nhtml_theme_path = [sphinx_rtd_theme.get_html_theme_path()]\nhtml_logo = \"./image/logo_transparent_background.png\"\nhtml_theme_options = {\n    \"logo_only\": True,",
        "detail": "docs.source.conf",
        "documentation": {}
    },
    {
        "label": "html_theme",
        "kind": 5,
        "importPath": "docs.source.conf",
        "description": "docs.source.conf",
        "peekOfCode": "html_theme = \"sphinx_rtd_theme\"\nhtml_theme_path = [sphinx_rtd_theme.get_html_theme_path()]\nhtml_logo = \"./image/logo_transparent_background.png\"\nhtml_theme_options = {\n    \"logo_only\": True,\n    \"display_version\": False,\n}\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.",
        "detail": "docs.source.conf",
        "documentation": {}
    },
    {
        "label": "html_theme_path",
        "kind": 5,
        "importPath": "docs.source.conf",
        "description": "docs.source.conf",
        "peekOfCode": "html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]\nhtml_logo = \"./image/logo_transparent_background.png\"\nhtml_theme_options = {\n    \"logo_only\": True,\n    \"display_version\": False,\n}\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#",
        "detail": "docs.source.conf",
        "documentation": {}
    },
    {
        "label": "html_logo",
        "kind": 5,
        "importPath": "docs.source.conf",
        "description": "docs.source.conf",
        "peekOfCode": "html_logo = \"./image/logo_transparent_background.png\"\nhtml_theme_options = {\n    \"logo_only\": True,\n    \"display_version\": False,\n}\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\n# html_theme_options = {}",
        "detail": "docs.source.conf",
        "documentation": {}
    },
    {
        "label": "html_theme_options",
        "kind": 5,
        "importPath": "docs.source.conf",
        "description": "docs.source.conf",
        "peekOfCode": "html_theme_options = {\n    \"logo_only\": True,\n    \"display_version\": False,\n}\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\n# html_theme_options = {}\n# Add any paths that contain custom static files (such as style sheets) here,",
        "detail": "docs.source.conf",
        "documentation": {}
    },
    {
        "label": "html_static_path",
        "kind": 5,
        "importPath": "docs.source.conf",
        "description": "docs.source.conf",
        "peekOfCode": "html_static_path = [\"_static\"]\n# Custom sidebar templates, must be a dictionary that maps document names\n# to template names.\n#\n# The default sidebars (for documents that don't match any pattern) are\n# defined by theme itself.  Builtin themes are using these templates by\n# default: ``['localtoc.html', 'relations.html', 'sourcelink.html',\n# 'searchbox.html']``.\n#\n# html_sidebars = {}",
        "detail": "docs.source.conf",
        "documentation": {}
    },
    {
        "label": "htmlhelp_basename",
        "kind": 5,
        "importPath": "docs.source.conf",
        "description": "docs.source.conf",
        "peekOfCode": "htmlhelp_basename = \"FinRLdoc\"\n# -- Options for LaTeX output ------------------------------------------------\nlatex_elements = {\n    # The paper size ('letterpaper' or 'a4paper').\n    #\n    # 'papersize': 'letterpaper',\n    # The font size ('10pt', '11pt' or '12pt').\n    #\n    # 'pointsize': '10pt',\n    # Additional stuff for the LaTeX preamble.",
        "detail": "docs.source.conf",
        "documentation": {}
    },
    {
        "label": "latex_elements",
        "kind": 5,
        "importPath": "docs.source.conf",
        "description": "docs.source.conf",
        "peekOfCode": "latex_elements = {\n    # The paper size ('letterpaper' or 'a4paper').\n    #\n    # 'papersize': 'letterpaper',\n    # The font size ('10pt', '11pt' or '12pt').\n    #\n    # 'pointsize': '10pt',\n    # Additional stuff for the LaTeX preamble.\n    #\n    # 'preamble': '',",
        "detail": "docs.source.conf",
        "documentation": {}
    },
    {
        "label": "latex_documents",
        "kind": 5,
        "importPath": "docs.source.conf",
        "description": "docs.source.conf",
        "peekOfCode": "latex_documents = [\n    (master_doc, \"FinRL.tex\", \"FinRL Documentation\", \"FinRL\", \"manual\"),\n]\n# -- Options for manual page output ------------------------------------------\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [(master_doc, \"finrl\", \"FinRL Documentation\", [author], 1)]\n# -- Options for Texinfo output ----------------------------------------------\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,",
        "detail": "docs.source.conf",
        "documentation": {}
    },
    {
        "label": "man_pages",
        "kind": 5,
        "importPath": "docs.source.conf",
        "description": "docs.source.conf",
        "peekOfCode": "man_pages = [(master_doc, \"finrl\", \"FinRL Documentation\", [author], 1)]\n# -- Options for Texinfo output ----------------------------------------------\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (\n        master_doc,\n        \"FinRL\",\n        \"FinRL Documentation\",",
        "detail": "docs.source.conf",
        "documentation": {}
    },
    {
        "label": "texinfo_documents",
        "kind": 5,
        "importPath": "docs.source.conf",
        "description": "docs.source.conf",
        "peekOfCode": "texinfo_documents = [\n    (\n        master_doc,\n        \"FinRL\",\n        \"FinRL Documentation\",\n        author,\n        \"FinRL\",\n        \"One line description of project.\",\n        \"Miscellaneous\",\n    ),",
        "detail": "docs.source.conf",
        "documentation": {}
    },
    {
        "label": "epub_title",
        "kind": 5,
        "importPath": "docs.source.conf",
        "description": "docs.source.conf",
        "peekOfCode": "epub_title = project\n# The unique identifier of the text. This can be a ISBN number\n# or the project homepage.\n#\n# epub_identifier = ''\n# A unique identification for the text.\n#\n# epub_uid = ''\n# A list of files that should not be packed into the epub file.\nepub_exclude_files = [\"search.html\"]",
        "detail": "docs.source.conf",
        "documentation": {}
    },
    {
        "label": "epub_exclude_files",
        "kind": 5,
        "importPath": "docs.source.conf",
        "description": "docs.source.conf",
        "peekOfCode": "epub_exclude_files = [\"search.html\"]\n# -- Extension configuration -------------------------------------------------",
        "detail": "docs.source.conf",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.agents.elegantrl.models",
        "description": "examples.ExampleOFinrl.agents.elegantrl.models",
        "peekOfCode": "class DRLAgent:\n    \"\"\"Implementations of DRL algorithms\n    Attributes\n    ----------\n        env: gym environment class\n            user-defined class\n    Methods\n    -------\n        get_model()\n            setup DRL algorithms",
        "detail": "examples.ExampleOFinrl.agents.elegantrl.models",
        "documentation": {}
    },
    {
        "label": "MODELS",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.agents.elegantrl.models",
        "description": "examples.ExampleOFinrl.agents.elegantrl.models",
        "peekOfCode": "MODELS = {\n    \"ddpg\": AgentDDPG,\n    \"td3\": AgentTD3,\n    \"sac\": AgentSAC,\n    \"ppo\": AgentPPO,\n    \"a2c\": AgentA2C,\n}\nOFF_POLICY_MODELS = [\"ddpg\", \"td3\", \"sac\"]\nON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}",
        "detail": "examples.ExampleOFinrl.agents.elegantrl.models",
        "documentation": {}
    },
    {
        "label": "OFF_POLICY_MODELS",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.agents.elegantrl.models",
        "description": "examples.ExampleOFinrl.agents.elegantrl.models",
        "peekOfCode": "OFF_POLICY_MODELS = [\"ddpg\", \"td3\", \"sac\"]\nON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:\n    \"\"\"Implementations of DRL algorithms",
        "detail": "examples.ExampleOFinrl.agents.elegantrl.models",
        "documentation": {}
    },
    {
        "label": "ON_POLICY_MODELS",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.agents.elegantrl.models",
        "description": "examples.ExampleOFinrl.agents.elegantrl.models",
        "peekOfCode": "ON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:\n    \"\"\"Implementations of DRL algorithms\n    Attributes",
        "detail": "examples.ExampleOFinrl.agents.elegantrl.models",
        "documentation": {}
    },
    {
        "label": "PolicyGradient",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.agents.portfolio_optimization.algorithms",
        "description": "examples.ExampleOFinrl.agents.portfolio_optimization.algorithms",
        "peekOfCode": "class PolicyGradient:\n    \"\"\"Class implementing policy gradient algorithm to train portfolio\n    optimization agents.\n    Note:\n        During testing, the agent is optimized through online learning.\n        The parameters of the policy is updated repeatedly after a constant\n        period of time. To disable it, set learning rate to 0.\n    Attributes:\n        train_env: Environment used to train the agent\n        train_policy: Policy used in training.",
        "detail": "examples.ExampleOFinrl.agents.portfolio_optimization.algorithms",
        "documentation": {}
    },
    {
        "label": "EIIE",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.agents.portfolio_optimization.architectures",
        "description": "examples.ExampleOFinrl.agents.portfolio_optimization.architectures",
        "peekOfCode": "class EIIE(nn.Module):\n    def __init__(\n        self,\n        initial_features=3,\n        k_size=3,\n        conv_mid_features=2,\n        conv_final_features=20,\n        time_window=50,\n        device=\"cpu\",\n    ):",
        "detail": "examples.ExampleOFinrl.agents.portfolio_optimization.architectures",
        "documentation": {}
    },
    {
        "label": "EI3",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.agents.portfolio_optimization.architectures",
        "description": "examples.ExampleOFinrl.agents.portfolio_optimization.architectures",
        "peekOfCode": "class EI3(nn.Module):\n    def __init__(\n        self,\n        initial_features=3,\n        k_short=3,\n        k_medium=21,\n        conv_mid_features=3,\n        conv_final_features=20,\n        time_window=50,\n        device=\"cpu\",",
        "detail": "examples.ExampleOFinrl.agents.portfolio_optimization.architectures",
        "documentation": {}
    },
    {
        "label": "GPM",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.agents.portfolio_optimization.architectures",
        "description": "examples.ExampleOFinrl.agents.portfolio_optimization.architectures",
        "peekOfCode": "class GPM(nn.Module):\n    def __init__(\n        self,\n        edge_index,\n        edge_type,\n        nodes_to_select,\n        initial_features=3,\n        k_short=3,\n        k_medium=21,\n        conv_mid_features=3,",
        "detail": "examples.ExampleOFinrl.agents.portfolio_optimization.architectures",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.agents.portfolio_optimization.models",
        "description": "examples.ExampleOFinrl.agents.portfolio_optimization.models",
        "peekOfCode": "class DRLAgent:\n    \"\"\"Implementation for DRL algorithms for portfolio optimization.\n    Note:\n        During testing, the agent is optimized through online learning.\n        The parameters of the policy is updated repeatedly after a constant\n        period of time. To disable it, set learning rate to 0.\n    Attributes:\n        env: Gym environment class.\n    \"\"\"\n    def __init__(self, env):",
        "detail": "examples.ExampleOFinrl.agents.portfolio_optimization.models",
        "documentation": {}
    },
    {
        "label": "MODELS",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.agents.portfolio_optimization.models",
        "description": "examples.ExampleOFinrl.agents.portfolio_optimization.models",
        "peekOfCode": "MODELS = {\"pg\": PolicyGradient}\nclass DRLAgent:\n    \"\"\"Implementation for DRL algorithms for portfolio optimization.\n    Note:\n        During testing, the agent is optimized through online learning.\n        The parameters of the policy is updated repeatedly after a constant\n        period of time. To disable it, set learning rate to 0.\n    Attributes:\n        env: Gym environment class.\n    \"\"\"",
        "detail": "examples.ExampleOFinrl.agents.portfolio_optimization.models",
        "documentation": {}
    },
    {
        "label": "PVM",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.agents.portfolio_optimization.utils",
        "description": "examples.ExampleOFinrl.agents.portfolio_optimization.utils",
        "peekOfCode": "class PVM:\n    def __init__(self, capacity, portfolio_size):\n        \"\"\"Initializes portfolio vector memory.\n        Args:\n          capacity: Max capacity of memory.\n          portfolio_size: Portfolio size.\n        \"\"\"\n        # initially, memory will have the same actions\n        self.capacity = capacity\n        self.portfolio_size = portfolio_size",
        "detail": "examples.ExampleOFinrl.agents.portfolio_optimization.utils",
        "documentation": {}
    },
    {
        "label": "ReplayBuffer",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.agents.portfolio_optimization.utils",
        "description": "examples.ExampleOFinrl.agents.portfolio_optimization.utils",
        "peekOfCode": "class ReplayBuffer:\n    def __init__(self, capacity):\n        \"\"\"Initializes replay buffer.\n        Args:\n          capacity: Max capacity of buffer.\n        \"\"\"\n        self.buffer = deque(maxlen=capacity)\n    def __len__(self):\n        \"\"\"Represents the size of the buffer\n        Returns:",
        "detail": "examples.ExampleOFinrl.agents.portfolio_optimization.utils",
        "documentation": {}
    },
    {
        "label": "RLDataset",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.agents.portfolio_optimization.utils",
        "description": "examples.ExampleOFinrl.agents.portfolio_optimization.utils",
        "peekOfCode": "class RLDataset(IterableDataset):\n    def __init__(self, buffer):\n        \"\"\"Initializes reinforcement learning dataset.\n        Args:\n            buffer: replay buffer to become iterable dataset.\n        Note:\n            It's a subclass of pytorch's IterableDataset,\n            check https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset\n        \"\"\"\n        self.buffer = buffer",
        "detail": "examples.ExampleOFinrl.agents.portfolio_optimization.utils",
        "documentation": {}
    },
    {
        "label": "apply_portfolio_noise",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.agents.portfolio_optimization.utils",
        "description": "examples.ExampleOFinrl.agents.portfolio_optimization.utils",
        "peekOfCode": "def apply_portfolio_noise(portfolio, epsilon=0.0):\n    \"\"\"Apply noise to portfolio distribution considering its constrains.\n    Arg:\n        portfolio: initial portfolio distribution.\n        epsilon: maximum rebalancing.\n    Returns:\n        New portolio distribution with noise applied.\n    \"\"\"\n    portfolio_size = portfolio.shape[0]\n    new_portfolio = portfolio.copy()",
        "detail": "examples.ExampleOFinrl.agents.portfolio_optimization.utils",
        "documentation": {}
    },
    {
        "label": "DRLlibv2",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.agents.rllib.drllibv2",
        "description": "examples.ExampleOFinrl.agents.rllib.drllibv2",
        "peekOfCode": "class DRLlibv2:\n    \"\"\"\n    It instantiates RLlib model with Ray tune functionality\n    Params\n    -------------------------------------\n    trainable:\n        Any Trainable class that takes config as parameter\n    train_env:\n        Training environment instance\n    train_env_name: str",
        "detail": "examples.ExampleOFinrl.agents.rllib.drllibv2",
        "documentation": {}
    },
    {
        "label": "psutil_memory_in_bytes",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.agents.rllib.drllibv2",
        "description": "examples.ExampleOFinrl.agents.rllib.drllibv2",
        "peekOfCode": "psutil_memory_in_bytes = psutil.virtual_memory().total\nray._private.utils.get_system_memory = lambda: psutil_memory_in_bytes\nfrom typing import Dict, Optional, Any, List, Union\nclass DRLlibv2:\n    \"\"\"\n    It instantiates RLlib model with Ray tune functionality\n    Params\n    -------------------------------------\n    trainable:\n        Any Trainable class that takes config as parameter",
        "detail": "examples.ExampleOFinrl.agents.rllib.drllibv2",
        "documentation": {}
    },
    {
        "label": "ray._private.utils.get_system_memory",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.agents.rllib.drllibv2",
        "description": "examples.ExampleOFinrl.agents.rllib.drllibv2",
        "peekOfCode": "ray._private.utils.get_system_memory = lambda: psutil_memory_in_bytes\nfrom typing import Dict, Optional, Any, List, Union\nclass DRLlibv2:\n    \"\"\"\n    It instantiates RLlib model with Ray tune functionality\n    Params\n    -------------------------------------\n    trainable:\n        Any Trainable class that takes config as parameter\n    train_env:",
        "detail": "examples.ExampleOFinrl.agents.rllib.drllibv2",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.agents.rllib.models",
        "description": "examples.ExampleOFinrl.agents.rllib.models",
        "peekOfCode": "class DRLAgent:\n    \"\"\"Implementations for DRL algorithms\n    Attributes\n    ----------\n        env: gym environment class\n            user-defined class\n        price_array: numpy array\n            OHLC data\n        tech_array: numpy array\n            techical data",
        "detail": "examples.ExampleOFinrl.agents.rllib.models",
        "documentation": {}
    },
    {
        "label": "MODELS",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.agents.rllib.models",
        "description": "examples.ExampleOFinrl.agents.rllib.models",
        "peekOfCode": "MODELS = {\"a2c\": a2c, \"ddpg\": ddpg, \"td3\": td3, \"sac\": sac, \"ppo\": ppo}\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\nclass DRLAgent:\n    \"\"\"Implementations for DRL algorithms\n    Attributes\n    ----------\n        env: gym environment class\n            user-defined class\n        price_array: numpy array\n            OHLC data",
        "detail": "examples.ExampleOFinrl.agents.rllib.models",
        "documentation": {}
    },
    {
        "label": "sample_ppo_params",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "description": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_ppo_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for PPO hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64, 128, 256, 512])\n    n_steps = trial.suggest_categorical(\n        \"n_steps\", [8, 16, 32, 64, 128, 256, 512, 1024, 2048]\n    )",
        "detail": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_trpo_params",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "description": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_trpo_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for TRPO hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64, 128, 256, 512])\n    n_steps = trial.suggest_categorical(\n        \"n_steps\", [8, 16, 32, 64, 128, 256, 512, 1024, 2048]\n    )",
        "detail": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_a2c_params",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "description": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_a2c_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for A2C hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    gamma = trial.suggest_categorical(\n        \"gamma\", [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999]\n    )\n    normalize_advantage = trial.suggest_categorical(",
        "detail": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_sac_params",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "description": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_sac_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for SAC hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    gamma = trial.suggest_categorical(\n        \"gamma\", [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999]\n    )\n    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)",
        "detail": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_td3_params",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "description": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_td3_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for TD3 hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    gamma = trial.suggest_categorical(\n        \"gamma\", [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999]\n    )\n    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)",
        "detail": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_ddpg_params",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "description": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_ddpg_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for DDPG hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    gamma = trial.suggest_categorical(\n        \"gamma\", [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999]\n    )\n    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)",
        "detail": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_dqn_params",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "description": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_dqn_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for DQN hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    gamma = trial.suggest_categorical(\n        \"gamma\", [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999]\n    )\n    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)",
        "detail": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_her_params",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "description": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_her_params(\n    trial: optuna.Trial, hyperparams: dict[str, Any]\n) -> dict[str, Any]:\n    \"\"\"\n    Sampler for HerReplayBuffer hyperparams.\n    :param trial:\n    :parma hyperparams:\n    :return:\n    \"\"\"\n    her_kwargs = trial.her_kwargs.copy()",
        "detail": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_tqc_params",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "description": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_tqc_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for TQC hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    # TQC is SAC + Distributional RL\n    hyperparams = sample_sac_params(trial)\n    n_quantiles = trial.suggest_int(\"n_quantiles\", 5, 50)\n    top_quantiles_to_drop_per_net = trial.suggest_int(",
        "detail": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_qrdqn_params",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "description": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_qrdqn_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for QR-DQN hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    # TQC is DQN + Distributional RL\n    hyperparams = sample_dqn_params(trial)\n    n_quantiles = trial.suggest_int(\"n_quantiles\", 5, 200)\n    hyperparams[\"policy_kwargs\"].update({\"n_quantiles\": n_quantiles})",
        "detail": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "sample_ars_params",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "description": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "def sample_ars_params(trial: optuna.Trial) -> dict[str, Any]:\n    \"\"\"\n    Sampler for ARS hyperparams.\n    :param trial:\n    :return:\n    \"\"\"\n    # n_eval_episodes = trial.suggest_categorical(\"n_eval_episodes\", [1, 2])\n    n_delta = trial.suggest_categorical(\"n_delta\", [4, 8, 6, 32, 64])\n    # learning_rate = trial.suggest_categorical(\"learning_rate\", [0.01, 0.02, 0.025, 0.03])\n    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)",
        "detail": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "HYPERPARAMS_SAMPLER",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "description": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "peekOfCode": "HYPERPARAMS_SAMPLER = {\n    \"a2c\": sample_a2c_params,\n    \"ars\": sample_ars_params,\n    \"ddpg\": sample_ddpg_params,\n    \"dqn\": sample_dqn_params,\n    \"qrdqn\": sample_qrdqn_params,\n    \"sac\": sample_sac_params,\n    \"tqc\": sample_tqc_params,\n    \"ppo\": sample_ppo_params,\n    \"td3\": sample_td3_params,",
        "detail": "examples.ExampleOFinrl.agents.stablebaselines3.hyperparams_opt",
        "documentation": {}
    },
    {
        "label": "TensorboardCallback",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.agents.stablebaselines3.models",
        "description": "examples.ExampleOFinrl.agents.stablebaselines3.models",
        "peekOfCode": "class TensorboardCallback(BaseCallback):\n    \"\"\"\n    Custom callback for plotting additional values in tensorboard.\n    \"\"\"\n    def __init__(self, verbose=0):\n        super().__init__(verbose)\n    def _on_step(self) -> bool:\n        try:\n            self.logger.record(key=\"train/reward\", value=self.locals[\"rewards\"][0])\n        except BaseException as error:",
        "detail": "examples.ExampleOFinrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.agents.stablebaselines3.models",
        "description": "examples.ExampleOFinrl.agents.stablebaselines3.models",
        "peekOfCode": "class DRLAgent:\n    \"\"\"Provides implementations for DRL algorithms\n    Attributes\n    ----------\n        env: gym environment class\n            user-defined class\n    Methods\n    -------\n        get_model()\n            setup DRL algorithms",
        "detail": "examples.ExampleOFinrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "DRLEnsembleAgent",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.agents.stablebaselines3.models",
        "description": "examples.ExampleOFinrl.agents.stablebaselines3.models",
        "peekOfCode": "class DRLEnsembleAgent:\n    @staticmethod\n    def get_model(\n        model_name,\n        env,\n        policy=\"MlpPolicy\",\n        policy_kwargs=None,\n        model_kwargs=None,\n        seed=None,\n        verbose=1,",
        "detail": "examples.ExampleOFinrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "MODELS",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.agents.stablebaselines3.models",
        "description": "examples.ExampleOFinrl.agents.stablebaselines3.models",
        "peekOfCode": "MODELS = {\"a2c\": A2C, \"ddpg\": DDPG, \"td3\": TD3, \"sac\": SAC, \"ppo\": PPO}\nMODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\nNOISE = {\n    \"normal\": NormalActionNoise,\n    \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n}\nclass TensorboardCallback(BaseCallback):\n    \"\"\"\n    Custom callback for plotting additional values in tensorboard.\n    \"\"\"",
        "detail": "examples.ExampleOFinrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "MODEL_KWARGS",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.agents.stablebaselines3.models",
        "description": "examples.ExampleOFinrl.agents.stablebaselines3.models",
        "peekOfCode": "MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\nNOISE = {\n    \"normal\": NormalActionNoise,\n    \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n}\nclass TensorboardCallback(BaseCallback):\n    \"\"\"\n    Custom callback for plotting additional values in tensorboard.\n    \"\"\"\n    def __init__(self, verbose=0):",
        "detail": "examples.ExampleOFinrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "NOISE",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.agents.stablebaselines3.models",
        "description": "examples.ExampleOFinrl.agents.stablebaselines3.models",
        "peekOfCode": "NOISE = {\n    \"normal\": NormalActionNoise,\n    \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n}\nclass TensorboardCallback(BaseCallback):\n    \"\"\"\n    Custom callback for plotting additional values in tensorboard.\n    \"\"\"\n    def __init__(self, verbose=0):\n        super().__init__(verbose)",
        "detail": "examples.ExampleOFinrl.agents.stablebaselines3.models",
        "documentation": {}
    },
    {
        "label": "LoggingCallback",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.agents.stablebaselines3.tune_sb3",
        "description": "examples.ExampleOFinrl.agents.stablebaselines3.tune_sb3",
        "peekOfCode": "class LoggingCallback:\n    def __init__(self, threshold: int, trial_number: int, patience: int):\n        \"\"\"\n        threshold:int tolerance for increase in sharpe ratio\n        trial_number: int Prune after minimum number of trials\n        patience: int patience for the threshold\n        \"\"\"\n        self.threshold = threshold\n        self.trial_number = trial_number\n        self.patience = patience",
        "detail": "examples.ExampleOFinrl.agents.stablebaselines3.tune_sb3",
        "documentation": {}
    },
    {
        "label": "TuneSB3Optuna",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.agents.stablebaselines3.tune_sb3",
        "description": "examples.ExampleOFinrl.agents.stablebaselines3.tune_sb3",
        "peekOfCode": "class TuneSB3Optuna:\n    \"\"\"\n    Hyperparameter tuning of SB3 agents using Optuna\n    Attributes\n    ----------\n      env_train: Training environment for SB3\n      model_name: str\n      env_trade: testing environment\n      logging_callback: callback for tuning\n      total_timesteps: int",
        "detail": "examples.ExampleOFinrl.agents.stablebaselines3.tune_sb3",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.applications.stock_trading.ensemble_stock_trading",
        "description": "examples.ExampleOFinrl.applications.stock_trading.ensemble_stock_trading",
        "peekOfCode": "def main():\n    import warnings\n    warnings.filterwarnings(\"ignore\")\n    import pandas as pd\n    import numpy as np\n    import matplotlib\n    import matplotlib.pyplot as plt\n    # matplotlib.use('Agg')\n    import datetime\n    from finrl.config_tickers import DOW_30_TICKER",
        "detail": "examples.ExampleOFinrl.applications.stock_trading.ensemble_stock_trading",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.applications.stock_trading.fundamental_stock_trading",
        "description": "examples.ExampleOFinrl.applications.stock_trading.fundamental_stock_trading",
        "peekOfCode": "def main():\n    import pandas as pd\n    import numpy as np\n    import matplotlib\n    import matplotlib.pyplot as plt\n    # matplotlib.use('Agg')\n    import datetime\n    from finrl import config\n    from finrl import config_tickers\n    from finrl.meta.preprocessor.yahoodownloader import YahooDownloader",
        "detail": "examples.ExampleOFinrl.applications.stock_trading.fundamental_stock_trading",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.applications.stock_trading.s1",
        "description": "examples.ExampleOFinrl.applications.stock_trading.s1",
        "peekOfCode": "def main():\n    import warnings\n    warnings.filterwarnings(\"ignore\")\n    import pandas as pd\n    import numpy as np\n    import matplotlib\n    import matplotlib.pyplot as plt\n    # matplotlib.use('Agg')\n    import datetime\n    from finrl.config_tickers import DOW_30_TICKER",
        "detail": "examples.ExampleOFinrl.applications.stock_trading.s1",
        "documentation": {}
    },
    {
        "label": "stock_trading",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.applications.stock_trading.stock_trading",
        "description": "examples.ExampleOFinrl.applications.stock_trading.stock_trading",
        "peekOfCode": "def stock_trading(\n    train_start_date: str,\n    train_end_date: str,\n    trade_start_date: str,\n    trade_end_date: str,\n    if_store_actions: bool = True,\n    if_store_result: bool = True,\n    if_using_a2c: bool = True,\n    if_using_ddpg: bool = True,\n    if_using_ppo: bool = True,",
        "detail": "examples.ExampleOFinrl.applications.stock_trading.stock_trading",
        "documentation": {}
    },
    {
        "label": "stock_trading_rolling_window",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.applications.stock_trading.stock_trading_rolling_window",
        "description": "examples.ExampleOFinrl.applications.stock_trading.stock_trading_rolling_window",
        "peekOfCode": "def stock_trading_rolling_window(\n    train_start_date: str,\n    train_end_date: str,\n    trade_start_date: str,\n    trade_end_date: str,\n    rolling_window_length: int,\n    if_store_actions: bool = True,\n    if_store_result: bool = True,\n    if_using_a2c: bool = True,\n    if_using_ddpg: bool = True,",
        "detail": "examples.ExampleOFinrl.applications.stock_trading.stock_trading_rolling_window",
        "documentation": {}
    },
    {
        "label": "calc_stockname_from_filename",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.meta.data_processors.func",
        "description": "examples.ExampleOFinrl.meta.data_processors.func",
        "peekOfCode": "def calc_stockname_from_filename(filename):\n    return filename.split(\"/\")[-1].split(\".csv\")[0]\ndef calc_all_filenames(path):\n    dir_list = os.listdir(path)\n    dir_list.sort()\n    paths2 = []\n    for dir in dir_list:\n        filename = os.path.join(os.path.abspath(path), dir)\n        if \".csv\" in filename and \"#\" not in filename and \"~\" not in filename:\n            paths2.append(filename)",
        "detail": "examples.ExampleOFinrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "calc_all_filenames",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.meta.data_processors.func",
        "description": "examples.ExampleOFinrl.meta.data_processors.func",
        "peekOfCode": "def calc_all_filenames(path):\n    dir_list = os.listdir(path)\n    dir_list.sort()\n    paths2 = []\n    for dir in dir_list:\n        filename = os.path.join(os.path.abspath(path), dir)\n        if \".csv\" in filename and \"#\" not in filename and \"~\" not in filename:\n            paths2.append(filename)\n    return paths2\ndef calc_stocknames(path):",
        "detail": "examples.ExampleOFinrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "calc_stocknames",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.meta.data_processors.func",
        "description": "examples.ExampleOFinrl.meta.data_processors.func",
        "peekOfCode": "def calc_stocknames(path):\n    filenames = calc_all_filenames(path)\n    res = []\n    for filename in filenames:\n        stockname = calc_stockname_from_filename(filename)\n        res.append(stockname)\n    return res\ndef remove_all_files(remove, path_of_data):\n    assert remove in [0, 1]\n    if remove == 1:",
        "detail": "examples.ExampleOFinrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "remove_all_files",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.meta.data_processors.func",
        "description": "examples.ExampleOFinrl.meta.data_processors.func",
        "peekOfCode": "def remove_all_files(remove, path_of_data):\n    assert remove in [0, 1]\n    if remove == 1:\n        os.system(\"rm -f \" + path_of_data + \"/*\")\n    dir_list = os.listdir(path_of_data)\n    for file in dir_list:\n        if \"~\" in file:\n            os.system(\"rm -f \" + path_of_data + \"/\" + file)\n    dir_list = os.listdir(path_of_data)\n    if remove == 1:",
        "detail": "examples.ExampleOFinrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "date2str",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.meta.data_processors.func",
        "description": "examples.ExampleOFinrl.meta.data_processors.func",
        "peekOfCode": "def date2str(dat: datetime.date) -> str:\n    return datetime.date.strftime(dat, \"%Y-%m-%d\")\ndef str2date(dat: str) -> datetime.date:\n    return datetime.datetime.strptime(dat, \"%Y-%m-%d\").date()\n# include start_date, inclue end_date. step: delta\ndef calc_dates(\n    start_date: datetime.date, end_date: datetime.date, delta: datetime.timedelta\n) -> list[str]:\n    dates = []\n    dat = copy.deepcopy(start_date)",
        "detail": "examples.ExampleOFinrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "str2date",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.meta.data_processors.func",
        "description": "examples.ExampleOFinrl.meta.data_processors.func",
        "peekOfCode": "def str2date(dat: str) -> datetime.date:\n    return datetime.datetime.strptime(dat, \"%Y-%m-%d\").date()\n# include start_date, inclue end_date. step: delta\ndef calc_dates(\n    start_date: datetime.date, end_date: datetime.date, delta: datetime.timedelta\n) -> list[str]:\n    dates = []\n    dat = copy.deepcopy(start_date)\n    while dat <= end_date:\n        d = date2str(dat)",
        "detail": "examples.ExampleOFinrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "calc_dates",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.meta.data_processors.func",
        "description": "examples.ExampleOFinrl.meta.data_processors.func",
        "peekOfCode": "def calc_dates(\n    start_date: datetime.date, end_date: datetime.date, delta: datetime.timedelta\n) -> list[str]:\n    dates = []\n    dat = copy.deepcopy(start_date)\n    while dat <= end_date:\n        d = date2str(dat)\n        dates.append(d)\n        dat += delta\n    return dates",
        "detail": "examples.ExampleOFinrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "calc_train_trade_starts_ends_if_rolling",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.meta.data_processors.func",
        "description": "examples.ExampleOFinrl.meta.data_processors.func",
        "peekOfCode": "def calc_train_trade_starts_ends_if_rolling(\n    init_train_dates: list[str], init_trade_dates: list[str], rolling_window_length: int\n) -> tuple[list[str], list[str], list[str], list[str]]:\n    trade_dates_length = len(init_trade_dates)\n    train_window_length = len(init_train_dates)\n    trade_window_length = min(rolling_window_length, trade_dates_length)\n    num_subsets_if_rolling = int(np.ceil(trade_dates_length / trade_window_length))\n    print(\"num_subsets_if_rolling: \", num_subsets_if_rolling)\n    dates = np.concatenate((init_train_dates, init_trade_dates), axis=0)\n    train_starts = []",
        "detail": "examples.ExampleOFinrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "calc_train_trade_data",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.meta.data_processors.func",
        "description": "examples.ExampleOFinrl.meta.data_processors.func",
        "peekOfCode": "def calc_train_trade_data(\n    i: int,\n    train_starts: list[str],\n    train_ends: list[str],\n    trade_starts: list[str],\n    trade_ends: list[str],\n    init_train_data: pd.DataFrame(),\n    init_trade_data: pd.DataFrame(),\n    date_col: str,\n) -> tuple[pd.DataFrame(), pd.DataFrame()]:",
        "detail": "examples.ExampleOFinrl.meta.data_processors.func",
        "documentation": {}
    },
    {
        "label": "AlpacaProcessor",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.data_processors.processor_alpaca",
        "description": "examples.ExampleOFinrl.meta.data_processors.processor_alpaca",
        "peekOfCode": "class AlpacaProcessor:\n    def __init__(self, API_KEY=None, API_SECRET=None, API_BASE_URL=None, api=None):\n        if api is None:\n            try:\n                self.api = tradeapi.REST(API_KEY, API_SECRET, API_BASE_URL, \"v2\")\n            except BaseException:\n                raise ValueError(\"Wrong Account Info!\")\n        else:\n            self.api = api\n    def _fetch_data_for_ticker(self, ticker, start_date, end_date, time_interval):",
        "detail": "examples.ExampleOFinrl.meta.data_processors.processor_alpaca",
        "documentation": {}
    },
    {
        "label": "CCXTEngineer",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.data_processors.processor_ccxt",
        "description": "examples.ExampleOFinrl.meta.data_processors.processor_ccxt",
        "peekOfCode": "class CCXTEngineer:\n    def __init__(self):\n        self.binance = ccxt.binance()\n    def data_fetch(self, start, end, pair_list=[\"BTC/USDT\"], period=\"1m\"):\n        def min_ohlcv(dt, pair, limit):\n            since = calendar.timegm(dt.utctimetuple()) * 1000\n            ohlcv = self.binance.fetch_ohlcv(\n                symbol=pair, timeframe=\"1m\", since=since, limit=limit\n            )\n            return ohlcv",
        "detail": "examples.ExampleOFinrl.meta.data_processors.processor_ccxt",
        "documentation": {}
    },
    {
        "label": "JoinQuantEngineer",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.data_processors.processor_joinquant",
        "description": "examples.ExampleOFinrl.meta.data_processors.processor_joinquant",
        "peekOfCode": "class JoinQuantEngineer:\n    def __init__(self):\n        pass\n    def auth(self, username, password):\n        jq.auth(username, password)\n    def data_fetch(self, stock_list, num, unit, end_dt):\n        df = jq.get_bars(\n            security=stock_list,\n            count=num,\n            unit=unit,",
        "detail": "examples.ExampleOFinrl.meta.data_processors.processor_joinquant",
        "documentation": {}
    },
    {
        "label": "QuantConnectEngineer",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.data_processors.processor_quantconnect",
        "description": "examples.ExampleOFinrl.meta.data_processors.processor_quantconnect",
        "peekOfCode": "class QuantConnectEngineer:\n    def __init__(self):\n        pass\n    def data_fetch(start_time, end_time, stock_list, resolution=Resolution.Daily):\n        # resolution: Daily, Hour, Minute, Second\n        qb = QuantBook()\n        for stock in stock_list:\n            qb.AddEquity(stock)\n        history = qb.History(qb.Securities.Keys, start_time, end_time, resolution)\n        return history",
        "detail": "examples.ExampleOFinrl.meta.data_processors.processor_quantconnect",
        "documentation": {}
    },
    {
        "label": "WrdsProcessor",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.data_processors.processor_wrds",
        "description": "examples.ExampleOFinrl.meta.data_processors.processor_wrds",
        "peekOfCode": "class WrdsProcessor:\n    def __init__(self, if_offline=False):\n        if not if_offline:\n            self.db = wrds.Connection()\n    def download_data(\n        self,\n        start_date,\n        end_date,\n        ticker_list,\n        time_interval,",
        "detail": "examples.ExampleOFinrl.meta.data_processors.processor_wrds",
        "documentation": {}
    },
    {
        "label": "pd.options.mode.chained_assignment",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.meta.data_processors.processor_wrds",
        "description": "examples.ExampleOFinrl.meta.data_processors.processor_wrds",
        "peekOfCode": "pd.options.mode.chained_assignment = None\nclass WrdsProcessor:\n    def __init__(self, if_offline=False):\n        if not if_offline:\n            self.db = wrds.Connection()\n    def download_data(\n        self,\n        start_date,\n        end_date,\n        ticker_list,",
        "detail": "examples.ExampleOFinrl.meta.data_processors.processor_wrds",
        "documentation": {}
    },
    {
        "label": "YahooFinanceProcessor",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.data_processors.processor_yahoofinance",
        "description": "examples.ExampleOFinrl.meta.data_processors.processor_yahoofinance",
        "peekOfCode": "class YahooFinanceProcessor:\n    \"\"\"Provides methods for retrieving daily stock data from\n    Yahoo Finance API\n    \"\"\"\n    def __init__(self):\n        pass\n    \"\"\"\n    Param\n    ----------\n        start_date : str",
        "detail": "examples.ExampleOFinrl.meta.data_processors.processor_yahoofinance",
        "documentation": {}
    },
    {
        "label": "BitcoinEnv",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.env_cryptocurrency_trading.env_btc_ccxt",
        "description": "examples.ExampleOFinrl.meta.env_cryptocurrency_trading.env_btc_ccxt",
        "peekOfCode": "class BitcoinEnv:  # custom env\n    def __init__(\n        self,\n        data_cwd=None,\n        price_ary=None,\n        tech_ary=None,\n        time_frequency=15,\n        start=None,\n        mid1=172197,\n        mid2=216837,",
        "detail": "examples.ExampleOFinrl.meta.env_cryptocurrency_trading.env_btc_ccxt",
        "documentation": {}
    },
    {
        "label": "CryptoEnv",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.env_cryptocurrency_trading.env_multiple_crypto",
        "description": "examples.ExampleOFinrl.meta.env_cryptocurrency_trading.env_multiple_crypto",
        "peekOfCode": "class CryptoEnv:  # custom env\n    def __init__(\n        self,\n        config,\n        lookback=1,\n        initial_capital=1e6,\n        buy_cost_pct=1e-3,\n        sell_cost_pct=1e-3,\n        gamma=0.99,\n    ):",
        "detail": "examples.ExampleOFinrl.meta.env_cryptocurrency_trading.env_multiple_crypto",
        "documentation": {}
    },
    {
        "label": "StockPortfolioEnv",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.env_portfolio_allocation.env_portfolio",
        "description": "examples.ExampleOFinrl.meta.env_portfolio_allocation.env_portfolio",
        "peekOfCode": "class StockPortfolioEnv(gym.Env):\n    \"\"\"A single stock trading environment for OpenAI gym\n    Attributes\n    ----------\n        df: DataFrame\n            input data\n        stock_dim : int\n            number of unique stocks\n        hmax : int\n            maximum number of shares to trade",
        "detail": "examples.ExampleOFinrl.meta.env_portfolio_allocation.env_portfolio",
        "documentation": {}
    },
    {
        "label": "PortfolioOptimizationEnv",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.env_portfolio_optimization.env_portfolio_optimization",
        "description": "examples.ExampleOFinrl.meta.env_portfolio_optimization.env_portfolio_optimization",
        "peekOfCode": "class PortfolioOptimizationEnv(gym.Env):\n    \"\"\"A portfolio allocation environment for OpenAI gym.\n    This environment simulates the interactions between an agent and the financial market\n    based on data provided by a dataframe. The dataframe contains the time series of\n    features defined by the user (such as closing, high and low prices) and must have\n    a time and a tic column with a list of datetimes and ticker symbols respectively.\n    An example of dataframe is shown below::\n            date        high            low             close           tic\n        0   2020-12-23  0.157414        0.127420        0.136394        ADA-USD\n        1   2020-12-23  34.381519       30.074295       31.097898       BNB-USD",
        "detail": "examples.ExampleOFinrl.meta.env_portfolio_optimization.env_portfolio_optimization",
        "documentation": {}
    },
    {
        "label": "StockEnvNAS100",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.env_stock_trading.env_nas100_wrds",
        "description": "examples.ExampleOFinrl.meta.env_stock_trading.env_nas100_wrds",
        "peekOfCode": "class StockEnvNAS100:\n    def __init__(\n        self,\n        cwd=\"./data/nas100\",\n        price_ary=None,\n        tech_ary=None,\n        turbulence_ary=None,\n        gamma=0.999,\n        turbulence_thresh=30,\n        min_stock_rate=0.1,",
        "detail": "examples.ExampleOFinrl.meta.env_stock_trading.env_nas100_wrds",
        "documentation": {}
    },
    {
        "label": "AlpacaPaperTrading",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.env_stock_trading.env_stock_papertrading",
        "description": "examples.ExampleOFinrl.meta.env_stock_trading.env_stock_papertrading",
        "peekOfCode": "class AlpacaPaperTrading:\n    def __init__(\n        self,\n        ticker_list,\n        time_interval,\n        drl_lib,\n        agent,\n        cwd,\n        net_dim,\n        state_dim,",
        "detail": "examples.ExampleOFinrl.meta.env_stock_trading.env_stock_papertrading",
        "documentation": {}
    },
    {
        "label": "StockEnvEmpty",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.env_stock_trading.env_stock_papertrading",
        "description": "examples.ExampleOFinrl.meta.env_stock_trading.env_stock_papertrading",
        "peekOfCode": "class StockEnvEmpty(gym.Env):\n    # Empty Env used for loading rllib agent\n    def __init__(self, config):\n        state_dim = config[\"state_dim\"]\n        action_dim = config[\"action_dim\"]\n        self.env_num = 1\n        self.max_step = 10000\n        self.env_name = \"StockEnvEmpty\"\n        self.state_dim = state_dim\n        self.action_dim = action_dim",
        "detail": "examples.ExampleOFinrl.meta.env_stock_trading.env_stock_papertrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.env_stock_trading.env_stocktrading",
        "description": "examples.ExampleOFinrl.meta.env_stock_trading.env_stocktrading",
        "peekOfCode": "class StockTradingEnv(gym.Env):\n    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n    metadata = {\"render.modes\": [\"human\"]}\n    def __init__(\n        self,\n        df: pd.DataFrame,\n        stock_dim: int,\n        hmax: int,\n        initial_amount: int,\n        num_stock_shares: list[int],",
        "detail": "examples.ExampleOFinrl.meta.env_stock_trading.env_stocktrading",
        "documentation": {}
    },
    {
        "label": "StockTradingEnvCashpenalty",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.env_stock_trading.env_stocktrading_cashpenalty",
        "description": "examples.ExampleOFinrl.meta.env_stock_trading.env_stocktrading_cashpenalty",
        "peekOfCode": "class StockTradingEnvCashpenalty(gym.Env):\n    \"\"\"\n    A stock trading environment for OpenAI gym\n    This environment penalizes the model for not maintaining a reserve of cash.\n    This enables the model to manage cash reserves in addition to performing trading procedures.\n    Reward at any step is given as follows\n        r_i = (sum(cash, asset_value) - initial_cash - max(0, sum(cash, asset_value)*cash_penalty_proportion-cash))/(days_elapsed)\n        This reward function takes into account a liquidity requirement, as well as long-term accrued rewards.\n    Parameters:\n        df (pandas.DataFrame): Dataframe containing data",
        "detail": "examples.ExampleOFinrl.meta.env_stock_trading.env_stocktrading_cashpenalty",
        "documentation": {}
    },
    {
        "label": "StockTradingEnv",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.env_stock_trading.env_stocktrading_np",
        "description": "examples.ExampleOFinrl.meta.env_stock_trading.env_stocktrading_np",
        "peekOfCode": "class StockTradingEnv(gym.Env):\n    def __init__(\n        self,\n        config,\n        initial_account=1e6,\n        gamma=0.99,\n        turbulence_thresh=99,\n        min_stock_rate=0.1,\n        max_stock=1e2,\n        initial_capital=1e6,",
        "detail": "examples.ExampleOFinrl.meta.env_stock_trading.env_stocktrading_np",
        "documentation": {}
    },
    {
        "label": "StockTradingEnvStopLoss",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.env_stock_trading.env_stocktrading_stoploss",
        "description": "examples.ExampleOFinrl.meta.env_stock_trading.env_stocktrading_stoploss",
        "peekOfCode": "class StockTradingEnvStopLoss(gym.Env):\n    \"\"\"\n    A stock trading environment for OpenAI gym\n    This environment penalizes the model if excedeed the stop-loss threshold, selling assets with under expectation %profit, and also\n    for not maintaining a reserve of cash.\n    This enables the model to do trading with high confidence and manage cash reserves in addition to performing trading procedures.\n    Reward at any step is given as follows\n        r_i = (sum(cash, asset_value) + additional_reward - total_penalty - initial_cash) / initial_cash / days_elapsed\n        , where total_penalty = cash_penalty + stop_loss_penalty + low_profit_penalty\n                cash_penalty = max(0, sum(cash, asset_value)*cash_penalty_proportion-cash)",
        "detail": "examples.ExampleOFinrl.meta.env_stock_trading.env_stocktrading_stoploss",
        "documentation": {}
    },
    {
        "label": "PaperTradingAlpaca",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.paper_trading.alpaca",
        "description": "examples.ExampleOFinrl.meta.paper_trading.alpaca",
        "peekOfCode": "class PaperTradingAlpaca:\n    def __init__(\n        self,\n        ticker_list,\n        time_interval,\n        drl_lib,\n        agent,\n        cwd,\n        net_dim,\n        state_dim,",
        "detail": "examples.ExampleOFinrl.meta.paper_trading.alpaca",
        "documentation": {}
    },
    {
        "label": "StockEnvEmpty",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.paper_trading.alpaca",
        "description": "examples.ExampleOFinrl.meta.paper_trading.alpaca",
        "peekOfCode": "class StockEnvEmpty(gym.Env):\n    # Empty Env used for loading rllib agent\n    def __init__(self, config):\n        state_dim = config[\"state_dim\"]\n        action_dim = config[\"action_dim\"]\n        self.env_num = 1\n        self.max_step = 10000\n        self.env_name = \"StockEnvEmpty\"\n        self.state_dim = state_dim\n        self.action_dim = action_dim",
        "detail": "examples.ExampleOFinrl.meta.paper_trading.alpaca",
        "documentation": {}
    },
    {
        "label": "ActorPPO",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.paper_trading.common",
        "description": "examples.ExampleOFinrl.meta.paper_trading.common",
        "peekOfCode": "class ActorPPO(nn.Module):\n    def __init__(self, dims: [int], state_dim: int, action_dim: int):\n        super().__init__()\n        self.net = build_mlp(dims=[state_dim, *dims, action_dim])\n        self.action_std_log = nn.Parameter(\n            torch.zeros((1, action_dim)), requires_grad=True\n        )  # trainable parameter\n    def forward(self, state: Tensor) -> Tensor:\n        return self.net(state).tanh()  # action.tanh()\n    def get_action(self, state: Tensor) -> (Tensor, Tensor):  # for exploration",
        "detail": "examples.ExampleOFinrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "CriticPPO",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.paper_trading.common",
        "description": "examples.ExampleOFinrl.meta.paper_trading.common",
        "peekOfCode": "class CriticPPO(nn.Module):\n    def __init__(self, dims: [int], state_dim: int, _action_dim: int):\n        super().__init__()\n        self.net = build_mlp(dims=[state_dim, *dims, 1])\n    def forward(self, state: Tensor) -> Tensor:\n        return self.net(state)  # advantage value\ndef build_mlp(dims: [int]) -> nn.Sequential:  # MLP (MultiLayer Perceptron)\n    net_list = []\n    for i in range(len(dims) - 1):\n        net_list.extend([nn.Linear(dims[i], dims[i + 1]), nn.ReLU()])",
        "detail": "examples.ExampleOFinrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "Config",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.paper_trading.common",
        "description": "examples.ExampleOFinrl.meta.paper_trading.common",
        "peekOfCode": "class Config:\n    def __init__(self, agent_class=None, env_class=None, env_args=None):\n        self.env_class = env_class  # env = env_class(**env_args)\n        self.env_args = env_args  # env = env_class(**env_args)\n        if env_args is None:  # dummy env_args\n            env_args = {\n                \"env_name\": None,\n                \"state_dim\": None,\n                \"action_dim\": None,\n                \"if_discrete\": None,",
        "detail": "examples.ExampleOFinrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "AgentBase",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.paper_trading.common",
        "description": "examples.ExampleOFinrl.meta.paper_trading.common",
        "peekOfCode": "class AgentBase:\n    def __init__(\n        self,\n        net_dims: [int],\n        state_dim: int,\n        action_dim: int,\n        gpu_id: int = 0,\n        args: Config = Config(),\n    ):\n        self.state_dim = state_dim",
        "detail": "examples.ExampleOFinrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "AgentPPO",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.paper_trading.common",
        "description": "examples.ExampleOFinrl.meta.paper_trading.common",
        "peekOfCode": "class AgentPPO(AgentBase):\n    def __init__(\n        self,\n        net_dims: [int],\n        state_dim: int,\n        action_dim: int,\n        gpu_id: int = 0,\n        args: Config = Config(),\n    ):\n        self.if_off_policy = False",
        "detail": "examples.ExampleOFinrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "PendulumEnv",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.paper_trading.common",
        "description": "examples.ExampleOFinrl.meta.paper_trading.common",
        "peekOfCode": "class PendulumEnv(gym.Wrapper):  # a demo of custom gym env\n    def __init__(self):\n        gym.logger.set_level(40)  # Block warning\n        gym_env_name = \"Pendulum-v0\" if gym.__version__ < \"0.18.0\" else \"Pendulum-v1\"\n        super().__init__(env=gym.make(gym_env_name))\n        \"\"\"the necessary env information when you design a custom env\"\"\"\n        self.env_name = gym_env_name  # the name of this env.\n        self.state_dim = self.observation_space.shape[0]  # feature number of state\n        self.action_dim = self.action_space.shape[0]  # feature number of action\n        self.if_discrete = False  # discrete action or continuous action",
        "detail": "examples.ExampleOFinrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "Evaluator",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.paper_trading.common",
        "description": "examples.ExampleOFinrl.meta.paper_trading.common",
        "peekOfCode": "class Evaluator:\n    def __init__(\n        self, eval_env, eval_per_step: int = 1e4, eval_times: int = 8, cwd: str = \".\"\n    ):\n        self.cwd = cwd\n        self.env_eval = eval_env\n        self.eval_step = 0\n        self.total_step = 0\n        self.start_time = time.time()\n        self.eval_times = (",
        "detail": "examples.ExampleOFinrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.paper_trading.common",
        "description": "examples.ExampleOFinrl.meta.paper_trading.common",
        "peekOfCode": "class DRLAgent:\n    \"\"\"Implementations of DRL algorithms\n    Attributes\n    ----------\n        env: gym environment class\n            user-defined class\n    Methods\n    -------\n        get_model()\n            setup DRL algorithms",
        "detail": "examples.ExampleOFinrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "build_mlp",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.meta.paper_trading.common",
        "description": "examples.ExampleOFinrl.meta.paper_trading.common",
        "peekOfCode": "def build_mlp(dims: [int]) -> nn.Sequential:  # MLP (MultiLayer Perceptron)\n    net_list = []\n    for i in range(len(dims) - 1):\n        net_list.extend([nn.Linear(dims[i], dims[i + 1]), nn.ReLU()])\n    del net_list[-1]  # remove the activation of output layer\n    return nn.Sequential(*net_list)\nclass Config:\n    def __init__(self, agent_class=None, env_class=None, env_args=None):\n        self.env_class = env_class  # env = env_class(**env_args)\n        self.env_args = env_args  # env = env_class(**env_args)",
        "detail": "examples.ExampleOFinrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "get_gym_env_args",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.meta.paper_trading.common",
        "description": "examples.ExampleOFinrl.meta.paper_trading.common",
        "peekOfCode": "def get_gym_env_args(env, if_print: bool) -> dict:\n    if {\"unwrapped\", \"observation_space\", \"action_space\", \"spec\"}.issubset(\n        dir(env)\n    ):  # isinstance(env, gym.Env):\n        env_name = env.unwrapped.spec.id\n        state_shape = env.observation_space.shape\n        state_dim = (\n            state_shape[0] if len(state_shape) == 1 else state_shape\n        )  # sometimes state_dim is a list\n        if_discrete = isinstance(env.action_space, gym.spaces.Discrete)",
        "detail": "examples.ExampleOFinrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "kwargs_filter",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.meta.paper_trading.common",
        "description": "examples.ExampleOFinrl.meta.paper_trading.common",
        "peekOfCode": "def kwargs_filter(function, kwargs: dict) -> dict:\n    import inspect\n    sign = inspect.signature(function).parameters.values()\n    sign = {val.name for val in sign}\n    common_args = sign.intersection(kwargs.keys())\n    return {key: kwargs[key] for key in common_args}  # filtered kwargs\ndef build_env(env_class=None, env_args=None):\n    if env_class.__module__ == \"gym.envs.registration\":  # special rule\n        env = env_class(id=env_args[\"env_name\"])\n    else:",
        "detail": "examples.ExampleOFinrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "build_env",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.meta.paper_trading.common",
        "description": "examples.ExampleOFinrl.meta.paper_trading.common",
        "peekOfCode": "def build_env(env_class=None, env_args=None):\n    if env_class.__module__ == \"gym.envs.registration\":  # special rule\n        env = env_class(id=env_args[\"env_name\"])\n    else:\n        env = env_class(**kwargs_filter(env_class.__init__, env_args.copy()))\n    for attr_str in (\"env_name\", \"state_dim\", \"action_dim\", \"if_discrete\"):\n        setattr(env, attr_str, env_args[attr_str])\n    return env\nclass AgentBase:\n    def __init__(",
        "detail": "examples.ExampleOFinrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "train_agent",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.meta.paper_trading.common",
        "description": "examples.ExampleOFinrl.meta.paper_trading.common",
        "peekOfCode": "def train_agent(args: Config):\n    args.init_before_training()\n    env = build_env(args.env_class, args.env_args)\n    agent = args.agent_class(\n        args.net_dims, args.state_dim, args.action_dim, gpu_id=args.gpu_id, args=args\n    )\n    agent.states = env.reset()[np.newaxis, :]\n    evaluator = Evaluator(\n        eval_env=build_env(args.env_class, args.env_args),\n        eval_per_step=args.eval_per_step,",
        "detail": "examples.ExampleOFinrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "render_agent",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.meta.paper_trading.common",
        "description": "examples.ExampleOFinrl.meta.paper_trading.common",
        "peekOfCode": "def render_agent(\n    env_class,\n    env_args: dict,\n    net_dims: [int],\n    agent_class,\n    actor_path: str,\n    render_times: int = 8,\n):\n    env = build_env(env_class, env_args)\n    state_dim = env_args[\"state_dim\"]",
        "detail": "examples.ExampleOFinrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "get_rewards_and_steps",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.meta.paper_trading.common",
        "description": "examples.ExampleOFinrl.meta.paper_trading.common",
        "peekOfCode": "def get_rewards_and_steps(\n    env, actor, if_render: bool = False\n) -> (float, int):  # cumulative_rewards and episode_steps\n    device = next(actor.parameters()).device  # net.parameters() is a Python generator.\n    state = env.reset()\n    episode_steps = 0\n    cumulative_returns = 0.0  # sum of rewards in an episode\n    for episode_steps in range(12345):\n        tensor_state = torch.as_tensor(\n            state, dtype=torch.float32, device=device",
        "detail": "examples.ExampleOFinrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.meta.paper_trading.common",
        "description": "examples.ExampleOFinrl.meta.paper_trading.common",
        "peekOfCode": "def train(\n    start_date,\n    end_date,\n    ticker_list,\n    data_source,\n    time_interval,\n    technical_indicator_list,\n    drl_lib,\n    env,\n    model_name,",
        "detail": "examples.ExampleOFinrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.meta.paper_trading.common",
        "description": "examples.ExampleOFinrl.meta.paper_trading.common",
        "peekOfCode": "def test(\n    start_date,\n    end_date,\n    ticker_list,\n    data_source,\n    time_interval,\n    technical_indicator_list,\n    drl_lib,\n    env,\n    model_name,",
        "detail": "examples.ExampleOFinrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "get_trading_days",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.meta.paper_trading.common",
        "description": "examples.ExampleOFinrl.meta.paper_trading.common",
        "peekOfCode": "def get_trading_days(start, end):\n    nyse = tc.get_calendar(\"NYSE\")\n    df = nyse.sessions_in_range(\n        pd.Timestamp(start, tz=pytz.UTC), pd.Timestamp(end, tz=pytz.UTC)\n    )\n    trading_days = []\n    for day in df:\n        trading_days.append(str(day)[:10])\n    return trading_days\ndef alpaca_history(key, secret, url, start, end):",
        "detail": "examples.ExampleOFinrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "alpaca_history",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.meta.paper_trading.common",
        "description": "examples.ExampleOFinrl.meta.paper_trading.common",
        "peekOfCode": "def alpaca_history(key, secret, url, start, end):\n    api = tradeapi.REST(key, secret, url, \"v2\")\n    trading_days = get_trading_days(start, end)\n    df = pd.DataFrame()\n    for day in trading_days:\n        df = df.append(\n            api.get_portfolio_history(date_start=day, timeframe=\"5Min\").df.iloc[:78]\n        )\n    equities = df.equity.values\n    cumu_returns = equities / equities[0]",
        "detail": "examples.ExampleOFinrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "DIA_history",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.meta.paper_trading.common",
        "description": "examples.ExampleOFinrl.meta.paper_trading.common",
        "peekOfCode": "def DIA_history(start):\n    data_df = yf.download([\"^DJI\"], start=start, interval=\"5m\")\n    data_df = data_df.iloc[:]\n    baseline_returns = data_df[\"Adj Close\"].values / data_df[\"Adj Close\"].values[0]\n    return data_df, baseline_returns\n# -----------------------------------------------------------------------------------------------------------------------------------------",
        "detail": "examples.ExampleOFinrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "MODELS",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.meta.paper_trading.common",
        "description": "examples.ExampleOFinrl.meta.paper_trading.common",
        "peekOfCode": "MODELS = {\"ppo\": AgentPPO}\nOFF_POLICY_MODELS = [\"ddpg\", \"td3\", \"sac\"]\nON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:",
        "detail": "examples.ExampleOFinrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "OFF_POLICY_MODELS",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.meta.paper_trading.common",
        "description": "examples.ExampleOFinrl.meta.paper_trading.common",
        "peekOfCode": "OFF_POLICY_MODELS = [\"ddpg\", \"td3\", \"sac\"]\nON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:\n    \"\"\"Implementations of DRL algorithms",
        "detail": "examples.ExampleOFinrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "ON_POLICY_MODELS",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.meta.paper_trading.common",
        "description": "examples.ExampleOFinrl.meta.paper_trading.common",
        "peekOfCode": "ON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:\n    \"\"\"Implementations of DRL algorithms\n    Attributes",
        "detail": "examples.ExampleOFinrl.meta.paper_trading.common",
        "documentation": {}
    },
    {
        "label": "GroupByScaler",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.preprocessor.preprocessors",
        "description": "examples.ExampleOFinrl.meta.preprocessor.preprocessors",
        "peekOfCode": "class GroupByScaler(BaseEstimator, TransformerMixin):\n    \"\"\"Sklearn-like scaler that scales considering groups of data.\n    In the financial setting, this scale can be used to normalize a DataFrame\n    with time series of multiple tickers. The scaler will fit and transform\n    data for each ticker independently.\n    \"\"\"\n    def __init__(self, by, scaler=MaxAbsScaler, columns=None, scaler_kwargs=None):\n        \"\"\"Initializes GoupBy scaler.\n        Args:\n            by: Name of column that will be used to group.",
        "detail": "examples.ExampleOFinrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "FeatureEngineer",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.preprocessor.preprocessors",
        "description": "examples.ExampleOFinrl.meta.preprocessor.preprocessors",
        "peekOfCode": "class FeatureEngineer:\n    \"\"\"Provides methods for preprocessing the stock price data\n    Attributes\n    ----------\n        use_technical_indicator : boolean\n            we technical indicator or not\n        tech_indicator_list : list\n            a list of technical indicator names (modified from neofinrl_config.py)\n        use_turbulence : boolean\n            use turbulence index or not",
        "detail": "examples.ExampleOFinrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "load_dataset",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.meta.preprocessor.preprocessors",
        "description": "examples.ExampleOFinrl.meta.preprocessor.preprocessors",
        "peekOfCode": "def load_dataset(*, file_name: str) -> pd.DataFrame:\n    \"\"\"\n    load csv dataset from path\n    :return: (df) pandas dataframe\n    \"\"\"\n    # _data = pd.read_csv(f\"{config.DATASET_DIR}/{file_name}\")\n    _data = pd.read_csv(file_name)\n    return _data\ndef data_split(df, start, end, target_date_col=\"date\"):\n    \"\"\"",
        "detail": "examples.ExampleOFinrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "data_split",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.meta.preprocessor.preprocessors",
        "description": "examples.ExampleOFinrl.meta.preprocessor.preprocessors",
        "peekOfCode": "def data_split(df, start, end, target_date_col=\"date\"):\n    \"\"\"\n    split the dataset into training or testing using date\n    :param data: (df) pandas dataframe, start, end\n    :return: (df) pandas dataframe\n    \"\"\"\n    data = df[(df[target_date_col] >= start) & (df[target_date_col] < end)]\n    data = data.sort_values([target_date_col, \"tic\"], ignore_index=True)\n    data.index = data[target_date_col].factorize()[0]\n    return data",
        "detail": "examples.ExampleOFinrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "convert_to_datetime",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.meta.preprocessor.preprocessors",
        "description": "examples.ExampleOFinrl.meta.preprocessor.preprocessors",
        "peekOfCode": "def convert_to_datetime(time):\n    time_fmt = \"%Y-%m-%dT%H:%M:%S\"\n    if isinstance(time, str):\n        return datetime.datetime.strptime(time, time_fmt)\nclass GroupByScaler(BaseEstimator, TransformerMixin):\n    \"\"\"Sklearn-like scaler that scales considering groups of data.\n    In the financial setting, this scale can be used to normalize a DataFrame\n    with time series of multiple tickers. The scaler will fit and transform\n    data for each ticker independently.\n    \"\"\"",
        "detail": "examples.ExampleOFinrl.meta.preprocessor.preprocessors",
        "documentation": {}
    },
    {
        "label": "TushareDownloader",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.preprocessor.tusharedownloader",
        "description": "examples.ExampleOFinrl.meta.preprocessor.tusharedownloader",
        "peekOfCode": "class TushareDownloader:\n    \"\"\"Provides methods for retrieving daily stock data from\n    tushare API\n    Attributes\n    ----------\n        start_date : str\n            start date of the data (modified from config.py)\n        end_date : str\n            end date of the data (modified from config.py)\n        ticker_list : list",
        "detail": "examples.ExampleOFinrl.meta.preprocessor.tusharedownloader",
        "documentation": {}
    },
    {
        "label": "YahooDownloader",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.preprocessor.yahoodownloader",
        "description": "examples.ExampleOFinrl.meta.preprocessor.yahoodownloader",
        "peekOfCode": "class YahooDownloader:\n    \"\"\"Provides methods for retrieving daily stock data from\n    Yahoo Finance API\n    Attributes\n    ----------\n        start_date : str\n            start date of the data (modified from neofinrl_config.py)\n        end_date : str\n            end date of the data (modified from neofinrl_config.py)\n        ticker_list : list",
        "detail": "examples.ExampleOFinrl.meta.preprocessor.yahoodownloader",
        "documentation": {}
    },
    {
        "label": "DataProcessor",
        "kind": 6,
        "importPath": "examples.ExampleOFinrl.meta.data_processor",
        "description": "examples.ExampleOFinrl.meta.data_processor",
        "peekOfCode": "class DataProcessor:\n    def __init__(self, data_source, tech_indicator=None, vix=None, **kwargs):\n        if data_source == \"alpaca\":\n            try:\n                API_KEY = kwargs.get(\"API_KEY\")\n                API_SECRET = kwargs.get(\"API_SECRET\")\n                API_BASE_URL = kwargs.get(\"API_BASE_URL\")\n                self.processor = Alpaca(API_KEY, API_SECRET, API_BASE_URL)\n                print(\"Alpaca successfully connected\")\n            except BaseException:",
        "detail": "examples.ExampleOFinrl.meta.data_processor",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.meta.meta_config",
        "description": "examples.ExampleOFinrl.meta.meta_config",
        "peekOfCode": "TRAIN_START_DATE = \"2019-01-01\"\nTRAIN_END_DATE = \"2019-12-31\"\nTEST_START_DATE = \"2020-01-01\"\nTEST_END_DATE = \"2020-12-31\"\nTRADE_START_DATE = \"2021-01-01\"\nTRADE_END_DATE = \"2021-07-31\"\nPATH_OF_DATA = \"data\"\nREAD_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",",
        "detail": "examples.ExampleOFinrl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.meta.meta_config",
        "description": "examples.ExampleOFinrl.meta.meta_config",
        "peekOfCode": "TRAIN_END_DATE = \"2019-12-31\"\nTEST_START_DATE = \"2020-01-01\"\nTEST_END_DATE = \"2020-12-31\"\nTRADE_START_DATE = \"2021-01-01\"\nTRADE_END_DATE = \"2021-07-31\"\nPATH_OF_DATA = \"data\"\nREAD_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",",
        "detail": "examples.ExampleOFinrl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.meta.meta_config",
        "description": "examples.ExampleOFinrl.meta.meta_config",
        "peekOfCode": "TEST_START_DATE = \"2020-01-01\"\nTEST_END_DATE = \"2020-12-31\"\nTRADE_START_DATE = \"2021-01-01\"\nTRADE_END_DATE = \"2021-07-31\"\nPATH_OF_DATA = \"data\"\nREAD_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",",
        "detail": "examples.ExampleOFinrl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.meta.meta_config",
        "description": "examples.ExampleOFinrl.meta.meta_config",
        "peekOfCode": "TEST_END_DATE = \"2020-12-31\"\nTRADE_START_DATE = \"2021-01-01\"\nTRADE_END_DATE = \"2021-07-31\"\nPATH_OF_DATA = \"data\"\nREAD_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",",
        "detail": "examples.ExampleOFinrl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "TRADE_START_DATE",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.meta.meta_config",
        "description": "examples.ExampleOFinrl.meta.meta_config",
        "peekOfCode": "TRADE_START_DATE = \"2021-01-01\"\nTRADE_END_DATE = \"2021-07-31\"\nPATH_OF_DATA = \"data\"\nREAD_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"dx_30\",",
        "detail": "examples.ExampleOFinrl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "TRADE_END_DATE",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.meta.meta_config",
        "description": "examples.ExampleOFinrl.meta.meta_config",
        "peekOfCode": "TRADE_END_DATE = \"2021-07-31\"\nPATH_OF_DATA = \"data\"\nREAD_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"dx_30\",\n    \"close_30_sma\",",
        "detail": "examples.ExampleOFinrl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "PATH_OF_DATA",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.meta.meta_config",
        "description": "examples.ExampleOFinrl.meta.meta_config",
        "peekOfCode": "PATH_OF_DATA = \"data\"\nREAD_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"dx_30\",\n    \"close_30_sma\",\n    \"close_60_sma\",",
        "detail": "examples.ExampleOFinrl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "READ_DATA_FROM_LOCAL",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.meta.meta_config",
        "description": "examples.ExampleOFinrl.meta.meta_config",
        "peekOfCode": "READ_DATA_FROM_LOCAL = 1  # 0 or 1\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"dx_30\",\n    \"close_30_sma\",\n    \"close_60_sma\",\n]",
        "detail": "examples.ExampleOFinrl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.meta.meta_config",
        "description": "examples.ExampleOFinrl.meta.meta_config",
        "peekOfCode": "INDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"dx_30\",\n    \"close_30_sma\",\n    \"close_60_sma\",\n]\nFAANG_TICKER = [\"FB\", \"AMZN\", \"AAPL\", \"NFLX\", \"GOOG\"]",
        "detail": "examples.ExampleOFinrl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "FAANG_TICKER",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.meta.meta_config",
        "description": "examples.ExampleOFinrl.meta.meta_config",
        "peekOfCode": "FAANG_TICKER = [\"FB\", \"AMZN\", \"AAPL\", \"NFLX\", \"GOOG\"]\n# Dow 30 constituents at 2019/01\nDOW_30_TICKER = [\n    \"AAPL\",\n    \"MSFT\",\n    \"JPM\",\n    \"V\",\n    \"RTX\",\n    \"PG\",\n    \"GS\",",
        "detail": "examples.ExampleOFinrl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.meta.meta_config",
        "description": "examples.ExampleOFinrl.meta.meta_config",
        "peekOfCode": "DOW_30_TICKER = [\n    \"AAPL\",\n    \"MSFT\",\n    \"JPM\",\n    \"V\",\n    \"RTX\",\n    \"PG\",\n    \"GS\",\n    \"NKE\",\n    \"DIS\",",
        "detail": "examples.ExampleOFinrl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "NAS_100_TICKER",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.meta.meta_config",
        "description": "examples.ExampleOFinrl.meta.meta_config",
        "peekOfCode": "NAS_100_TICKER = [\n    \"AMGN\",\n    \"AAPL\",\n    \"AMAT\",\n    \"INTC\",\n    \"PCAR\",\n    \"PAYX\",\n    \"MSFT\",\n    \"ADBE\",\n    \"CSCO\",",
        "detail": "examples.ExampleOFinrl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "SP_500_TICKER",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.meta.meta_config",
        "description": "examples.ExampleOFinrl.meta.meta_config",
        "peekOfCode": "SP_500_TICKER = [\n    \"A\",\n    \"AAL\",\n    \"AAP\",\n    \"AAPL\",\n    \"ABBV\",\n    \"ABC\",\n    \"ABMD\",\n    \"ABT\",\n    \"ACN\",",
        "detail": "examples.ExampleOFinrl.meta.meta_config",
        "documentation": {}
    },
    {
        "label": "DATA_SAVE_DIR",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config",
        "description": "examples.ExampleOFinrl.config",
        "peekOfCode": "DATA_SAVE_DIR = \"datasets\"\nTRAINED_MODEL_DIR = \"trained_models\"\nTENSORBOARD_LOG_DIR = \"tensorboard_log\"\nRESULTS_DIR = \"results\"\n# date format: '%Y-%m-%d'\nTRAIN_START_DATE = \"2014-01-06\"  # bug fix: set Monday right, start date set 2014-01-01 ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1658 and the array at index 1 has size 1657\nTRAIN_END_DATE = \"2020-07-31\"\nTEST_START_DATE = \"2020-08-01\"\nTEST_END_DATE = \"2021-10-01\"\nTRADE_START_DATE = \"2021-11-01\"",
        "detail": "examples.ExampleOFinrl.config",
        "documentation": {}
    },
    {
        "label": "TRAINED_MODEL_DIR",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config",
        "description": "examples.ExampleOFinrl.config",
        "peekOfCode": "TRAINED_MODEL_DIR = \"trained_models\"\nTENSORBOARD_LOG_DIR = \"tensorboard_log\"\nRESULTS_DIR = \"results\"\n# date format: '%Y-%m-%d'\nTRAIN_START_DATE = \"2014-01-06\"  # bug fix: set Monday right, start date set 2014-01-01 ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1658 and the array at index 1 has size 1657\nTRAIN_END_DATE = \"2020-07-31\"\nTEST_START_DATE = \"2020-08-01\"\nTEST_END_DATE = \"2021-10-01\"\nTRADE_START_DATE = \"2021-11-01\"\nTRADE_END_DATE = \"2021-12-01\"",
        "detail": "examples.ExampleOFinrl.config",
        "documentation": {}
    },
    {
        "label": "TENSORBOARD_LOG_DIR",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config",
        "description": "examples.ExampleOFinrl.config",
        "peekOfCode": "TENSORBOARD_LOG_DIR = \"tensorboard_log\"\nRESULTS_DIR = \"results\"\n# date format: '%Y-%m-%d'\nTRAIN_START_DATE = \"2014-01-06\"  # bug fix: set Monday right, start date set 2014-01-01 ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1658 and the array at index 1 has size 1657\nTRAIN_END_DATE = \"2020-07-31\"\nTEST_START_DATE = \"2020-08-01\"\nTEST_END_DATE = \"2021-10-01\"\nTRADE_START_DATE = \"2021-11-01\"\nTRADE_END_DATE = \"2021-12-01\"\n# stockstats technical indicator column names",
        "detail": "examples.ExampleOFinrl.config",
        "documentation": {}
    },
    {
        "label": "RESULTS_DIR",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config",
        "description": "examples.ExampleOFinrl.config",
        "peekOfCode": "RESULTS_DIR = \"results\"\n# date format: '%Y-%m-%d'\nTRAIN_START_DATE = \"2014-01-06\"  # bug fix: set Monday right, start date set 2014-01-01 ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1658 and the array at index 1 has size 1657\nTRAIN_END_DATE = \"2020-07-31\"\nTEST_START_DATE = \"2020-08-01\"\nTEST_END_DATE = \"2021-10-01\"\nTRADE_START_DATE = \"2021-11-01\"\nTRADE_END_DATE = \"2021-12-01\"\n# stockstats technical indicator column names\n# check https://pypi.org/project/stockstats/ for different names",
        "detail": "examples.ExampleOFinrl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config",
        "description": "examples.ExampleOFinrl.config",
        "peekOfCode": "TRAIN_START_DATE = \"2014-01-06\"  # bug fix: set Monday right, start date set 2014-01-01 ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1658 and the array at index 1 has size 1657\nTRAIN_END_DATE = \"2020-07-31\"\nTEST_START_DATE = \"2020-08-01\"\nTEST_END_DATE = \"2021-10-01\"\nTRADE_START_DATE = \"2021-11-01\"\nTRADE_END_DATE = \"2021-12-01\"\n# stockstats technical indicator column names\n# check https://pypi.org/project/stockstats/ for different names\nINDICATORS = [\n    \"macd\",",
        "detail": "examples.ExampleOFinrl.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config",
        "description": "examples.ExampleOFinrl.config",
        "peekOfCode": "TRAIN_END_DATE = \"2020-07-31\"\nTEST_START_DATE = \"2020-08-01\"\nTEST_END_DATE = \"2021-10-01\"\nTRADE_START_DATE = \"2021-11-01\"\nTRADE_END_DATE = \"2021-12-01\"\n# stockstats technical indicator column names\n# check https://pypi.org/project/stockstats/ for different names\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",",
        "detail": "examples.ExampleOFinrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config",
        "description": "examples.ExampleOFinrl.config",
        "peekOfCode": "TEST_START_DATE = \"2020-08-01\"\nTEST_END_DATE = \"2021-10-01\"\nTRADE_START_DATE = \"2021-11-01\"\nTRADE_END_DATE = \"2021-12-01\"\n# stockstats technical indicator column names\n# check https://pypi.org/project/stockstats/ for different names\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",",
        "detail": "examples.ExampleOFinrl.config",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config",
        "description": "examples.ExampleOFinrl.config",
        "peekOfCode": "TEST_END_DATE = \"2021-10-01\"\nTRADE_START_DATE = \"2021-11-01\"\nTRADE_END_DATE = \"2021-12-01\"\n# stockstats technical indicator column names\n# check https://pypi.org/project/stockstats/ for different names\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",",
        "detail": "examples.ExampleOFinrl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_START_DATE",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config",
        "description": "examples.ExampleOFinrl.config",
        "peekOfCode": "TRADE_START_DATE = \"2021-11-01\"\nTRADE_END_DATE = \"2021-12-01\"\n# stockstats technical indicator column names\n# check https://pypi.org/project/stockstats/ for different names\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"cci_30\",",
        "detail": "examples.ExampleOFinrl.config",
        "documentation": {}
    },
    {
        "label": "TRADE_END_DATE",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config",
        "description": "examples.ExampleOFinrl.config",
        "peekOfCode": "TRADE_END_DATE = \"2021-12-01\"\n# stockstats technical indicator column names\n# check https://pypi.org/project/stockstats/ for different names\nINDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"cci_30\",\n    \"dx_30\",",
        "detail": "examples.ExampleOFinrl.config",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config",
        "description": "examples.ExampleOFinrl.config",
        "peekOfCode": "INDICATORS = [\n    \"macd\",\n    \"boll_ub\",\n    \"boll_lb\",\n    \"rsi_30\",\n    \"cci_30\",\n    \"dx_30\",\n    \"close_30_sma\",\n    \"close_60_sma\",\n]",
        "detail": "examples.ExampleOFinrl.config",
        "documentation": {}
    },
    {
        "label": "A2C_PARAMS",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config",
        "description": "examples.ExampleOFinrl.config",
        "peekOfCode": "A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.01, \"learning_rate\": 0.0007}\nPPO_PARAMS = {\n    \"n_steps\": 2048,\n    \"ent_coef\": 0.01,\n    \"learning_rate\": 0.00025,\n    \"batch_size\": 64,\n}\nDDPG_PARAMS = {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.001}\nTD3_PARAMS = {\"batch_size\": 100, \"buffer_size\": 1000000, \"learning_rate\": 0.001}\nSAC_PARAMS = {",
        "detail": "examples.ExampleOFinrl.config",
        "documentation": {}
    },
    {
        "label": "PPO_PARAMS",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config",
        "description": "examples.ExampleOFinrl.config",
        "peekOfCode": "PPO_PARAMS = {\n    \"n_steps\": 2048,\n    \"ent_coef\": 0.01,\n    \"learning_rate\": 0.00025,\n    \"batch_size\": 64,\n}\nDDPG_PARAMS = {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.001}\nTD3_PARAMS = {\"batch_size\": 100, \"buffer_size\": 1000000, \"learning_rate\": 0.001}\nSAC_PARAMS = {\n    \"batch_size\": 64,",
        "detail": "examples.ExampleOFinrl.config",
        "documentation": {}
    },
    {
        "label": "DDPG_PARAMS",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config",
        "description": "examples.ExampleOFinrl.config",
        "peekOfCode": "DDPG_PARAMS = {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.001}\nTD3_PARAMS = {\"batch_size\": 100, \"buffer_size\": 1000000, \"learning_rate\": 0.001}\nSAC_PARAMS = {\n    \"batch_size\": 64,\n    \"buffer_size\": 100000,\n    \"learning_rate\": 0.0001,\n    \"learning_starts\": 100,\n    \"ent_coef\": \"auto_0.1\",\n}\nERL_PARAMS = {",
        "detail": "examples.ExampleOFinrl.config",
        "documentation": {}
    },
    {
        "label": "TD3_PARAMS",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config",
        "description": "examples.ExampleOFinrl.config",
        "peekOfCode": "TD3_PARAMS = {\"batch_size\": 100, \"buffer_size\": 1000000, \"learning_rate\": 0.001}\nSAC_PARAMS = {\n    \"batch_size\": 64,\n    \"buffer_size\": 100000,\n    \"learning_rate\": 0.0001,\n    \"learning_starts\": 100,\n    \"ent_coef\": \"auto_0.1\",\n}\nERL_PARAMS = {\n    \"learning_rate\": 3e-5,",
        "detail": "examples.ExampleOFinrl.config",
        "documentation": {}
    },
    {
        "label": "SAC_PARAMS",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config",
        "description": "examples.ExampleOFinrl.config",
        "peekOfCode": "SAC_PARAMS = {\n    \"batch_size\": 64,\n    \"buffer_size\": 100000,\n    \"learning_rate\": 0.0001,\n    \"learning_starts\": 100,\n    \"ent_coef\": \"auto_0.1\",\n}\nERL_PARAMS = {\n    \"learning_rate\": 3e-5,\n    \"batch_size\": 2048,",
        "detail": "examples.ExampleOFinrl.config",
        "documentation": {}
    },
    {
        "label": "ERL_PARAMS",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config",
        "description": "examples.ExampleOFinrl.config",
        "peekOfCode": "ERL_PARAMS = {\n    \"learning_rate\": 3e-5,\n    \"batch_size\": 2048,\n    \"gamma\": 0.985,\n    \"seed\": 312,\n    \"net_dimension\": 512,\n    \"target_step\": 5000,\n    \"eval_gap\": 30,\n    \"eval_times\": 64,  # bug fix:KeyError: 'eval_times' line 68, in get_model model.eval_times = model_kwargs[\"eval_times\"]\n}",
        "detail": "examples.ExampleOFinrl.config",
        "documentation": {}
    },
    {
        "label": "RLlib_PARAMS",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config",
        "description": "examples.ExampleOFinrl.config",
        "peekOfCode": "RLlib_PARAMS = {\"lr\": 5e-5, \"train_batch_size\": 500, \"gamma\": 0.99}\n# Possible time zones\nTIME_ZONE_SHANGHAI = \"Asia/Shanghai\"  # Hang Seng HSI, SSE, CSI\nTIME_ZONE_USEASTERN = \"US/Eastern\"  # Dow, Nasdaq, SP\nTIME_ZONE_PARIS = \"Europe/Paris\"  # CAC,\nTIME_ZONE_BERLIN = \"Europe/Berlin\"  # DAX, TECDAX, MDAX, SDAX\nTIME_ZONE_JAKARTA = \"Asia/Jakarta\"  # LQ45\nTIME_ZONE_SELFDEFINED = \"xxx\"  # If neither of the above is your time zone, you should define it, and set USE_TIME_ZONE_SELFDEFINED 1.\nUSE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources",
        "detail": "examples.ExampleOFinrl.config",
        "documentation": {}
    },
    {
        "label": "TIME_ZONE_SHANGHAI",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config",
        "description": "examples.ExampleOFinrl.config",
        "peekOfCode": "TIME_ZONE_SHANGHAI = \"Asia/Shanghai\"  # Hang Seng HSI, SSE, CSI\nTIME_ZONE_USEASTERN = \"US/Eastern\"  # Dow, Nasdaq, SP\nTIME_ZONE_PARIS = \"Europe/Paris\"  # CAC,\nTIME_ZONE_BERLIN = \"Europe/Berlin\"  # DAX, TECDAX, MDAX, SDAX\nTIME_ZONE_JAKARTA = \"Asia/Jakarta\"  # LQ45\nTIME_ZONE_SELFDEFINED = \"xxx\"  # If neither of the above is your time zone, you should define it, and set USE_TIME_ZONE_SELFDEFINED 1.\nUSE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources\nALPACA_API_KEY = \"xxx\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"xxx\"  # your ALPACA_API_SECRET",
        "detail": "examples.ExampleOFinrl.config",
        "documentation": {}
    },
    {
        "label": "TIME_ZONE_USEASTERN",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config",
        "description": "examples.ExampleOFinrl.config",
        "peekOfCode": "TIME_ZONE_USEASTERN = \"US/Eastern\"  # Dow, Nasdaq, SP\nTIME_ZONE_PARIS = \"Europe/Paris\"  # CAC,\nTIME_ZONE_BERLIN = \"Europe/Berlin\"  # DAX, TECDAX, MDAX, SDAX\nTIME_ZONE_JAKARTA = \"Asia/Jakarta\"  # LQ45\nTIME_ZONE_SELFDEFINED = \"xxx\"  # If neither of the above is your time zone, you should define it, and set USE_TIME_ZONE_SELFDEFINED 1.\nUSE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources\nALPACA_API_KEY = \"xxx\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"xxx\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url",
        "detail": "examples.ExampleOFinrl.config",
        "documentation": {}
    },
    {
        "label": "TIME_ZONE_PARIS",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config",
        "description": "examples.ExampleOFinrl.config",
        "peekOfCode": "TIME_ZONE_PARIS = \"Europe/Paris\"  # CAC,\nTIME_ZONE_BERLIN = \"Europe/Berlin\"  # DAX, TECDAX, MDAX, SDAX\nTIME_ZONE_JAKARTA = \"Asia/Jakarta\"  # LQ45\nTIME_ZONE_SELFDEFINED = \"xxx\"  # If neither of the above is your time zone, you should define it, and set USE_TIME_ZONE_SELFDEFINED 1.\nUSE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources\nALPACA_API_KEY = \"xxx\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"xxx\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url",
        "detail": "examples.ExampleOFinrl.config",
        "documentation": {}
    },
    {
        "label": "TIME_ZONE_BERLIN",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config",
        "description": "examples.ExampleOFinrl.config",
        "peekOfCode": "TIME_ZONE_BERLIN = \"Europe/Berlin\"  # DAX, TECDAX, MDAX, SDAX\nTIME_ZONE_JAKARTA = \"Asia/Jakarta\"  # LQ45\nTIME_ZONE_SELFDEFINED = \"xxx\"  # If neither of the above is your time zone, you should define it, and set USE_TIME_ZONE_SELFDEFINED 1.\nUSE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources\nALPACA_API_KEY = \"xxx\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"xxx\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url",
        "detail": "examples.ExampleOFinrl.config",
        "documentation": {}
    },
    {
        "label": "TIME_ZONE_JAKARTA",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config",
        "description": "examples.ExampleOFinrl.config",
        "peekOfCode": "TIME_ZONE_JAKARTA = \"Asia/Jakarta\"  # LQ45\nTIME_ZONE_SELFDEFINED = \"xxx\"  # If neither of the above is your time zone, you should define it, and set USE_TIME_ZONE_SELFDEFINED 1.\nUSE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources\nALPACA_API_KEY = \"xxx\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"xxx\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url",
        "detail": "examples.ExampleOFinrl.config",
        "documentation": {}
    },
    {
        "label": "TIME_ZONE_SELFDEFINED",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config",
        "description": "examples.ExampleOFinrl.config",
        "peekOfCode": "TIME_ZONE_SELFDEFINED = \"xxx\"  # If neither of the above is your time zone, you should define it, and set USE_TIME_ZONE_SELFDEFINED 1.\nUSE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources\nALPACA_API_KEY = \"xxx\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"xxx\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url",
        "detail": "examples.ExampleOFinrl.config",
        "documentation": {}
    },
    {
        "label": "USE_TIME_ZONE_SELFDEFINED",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config",
        "description": "examples.ExampleOFinrl.config",
        "peekOfCode": "USE_TIME_ZONE_SELFDEFINED = 0  # 0 (default) or 1 (use the self defined)\n# parameters for data sources\nALPACA_API_KEY = \"xxx\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"xxx\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url",
        "detail": "examples.ExampleOFinrl.config",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config",
        "description": "examples.ExampleOFinrl.config",
        "peekOfCode": "ALPACA_API_KEY = \"xxx\"  # your ALPACA_API_KEY\nALPACA_API_SECRET = \"xxx\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url",
        "detail": "examples.ExampleOFinrl.config",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config",
        "description": "examples.ExampleOFinrl.config",
        "peekOfCode": "ALPACA_API_SECRET = \"xxx\"  # your ALPACA_API_SECRET\nALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url",
        "detail": "examples.ExampleOFinrl.config",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_BASE_URL",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config",
        "description": "examples.ExampleOFinrl.config",
        "peekOfCode": "ALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\"  # alpaca url\nBINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url",
        "detail": "examples.ExampleOFinrl.config",
        "documentation": {}
    },
    {
        "label": "BINANCE_BASE_URL",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config",
        "description": "examples.ExampleOFinrl.config",
        "peekOfCode": "BINANCE_BASE_URL = \"https://data.binance.vision/\"  # binance url",
        "detail": "examples.ExampleOFinrl.config",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_KEY",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config_private",
        "description": "examples.ExampleOFinrl.config_private",
        "peekOfCode": "ALPACA_API_KEY = \"xxx\"\nALPACA_API_SECRET = \"xxx\"",
        "detail": "examples.ExampleOFinrl.config_private",
        "documentation": {}
    },
    {
        "label": "ALPACA_API_SECRET",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config_private",
        "description": "examples.ExampleOFinrl.config_private",
        "peekOfCode": "ALPACA_API_SECRET = \"xxx\"",
        "detail": "examples.ExampleOFinrl.config_private",
        "documentation": {}
    },
    {
        "label": "SINGLE_TICKER",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config_tickers",
        "description": "examples.ExampleOFinrl.config_tickers",
        "peekOfCode": "SINGLE_TICKER = [\"AAPL\"]\n# Dow 30 constituents in 2021/10\n# check https://wrds-www.wharton.upenn.edu/ for U.S. index constituents\nDOW_30_TICKER = [\n    \"AXP\",\n    \"AMGN\",\n    \"AAPL\",\n    \"BA\",\n    \"CAT\",\n    \"CSCO\",",
        "detail": "examples.ExampleOFinrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DOW_30_TICKER",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config_tickers",
        "description": "examples.ExampleOFinrl.config_tickers",
        "peekOfCode": "DOW_30_TICKER = [\n    \"AXP\",\n    \"AMGN\",\n    \"AAPL\",\n    \"BA\",\n    \"CAT\",\n    \"CSCO\",\n    \"CVX\",\n    \"GS\",\n    \"HD\",",
        "detail": "examples.ExampleOFinrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "NAS_100_TICKER",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config_tickers",
        "description": "examples.ExampleOFinrl.config_tickers",
        "peekOfCode": "NAS_100_TICKER = [\n    \"AMGN\",\n    \"AAPL\",\n    \"AMAT\",\n    \"INTC\",\n    \"PCAR\",\n    \"PAYX\",\n    \"MSFT\",\n    \"ADBE\",\n    \"CSCO\",",
        "detail": "examples.ExampleOFinrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "SP_500_TICKER",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config_tickers",
        "description": "examples.ExampleOFinrl.config_tickers",
        "peekOfCode": "SP_500_TICKER = [\n    \"A\",\n    \"AAL\",\n    \"AAP\",\n    \"AAPL\",\n    \"ABBV\",\n    \"ABC\",\n    \"ABMD\",\n    \"ABT\",\n    \"ACN\",",
        "detail": "examples.ExampleOFinrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "HSI_50_TICKER",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config_tickers",
        "description": "examples.ExampleOFinrl.config_tickers",
        "peekOfCode": "HSI_50_TICKER = [\n    \"0011.HK\",\n    \"0005.HK\",\n    \"0012.HK\",\n    \"0006.HK\",\n    \"0003.HK\",\n    \"0016.HK\",\n    \"0019.HK\",\n    \"0002.HK\",\n    \"0001.HK\",",
        "detail": "examples.ExampleOFinrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "SSE_50_TICKER",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config_tickers",
        "description": "examples.ExampleOFinrl.config_tickers",
        "peekOfCode": "SSE_50_TICKER = [\n    \"600000.XSHG\",\n    \"600036.XSHG\",\n    \"600104.XSHG\",\n    \"600030.XSHG\",\n    \"601628.XSHG\",\n    \"601166.XSHG\",\n    \"601318.XSHG\",\n    \"601328.XSHG\",\n    \"601088.XSHG\",",
        "detail": "examples.ExampleOFinrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "CSI_300_TICKER",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config_tickers",
        "description": "examples.ExampleOFinrl.config_tickers",
        "peekOfCode": "CSI_300_TICKER = [\n    \"600000.XSHG\",\n    \"600004.XSHG\",\n    \"600009.XSHG\",\n    \"600010.XSHG\",\n    \"600011.XSHG\",\n    \"600015.XSHG\",\n    \"600016.XSHG\",\n    \"600018.XSHG\",\n    \"600019.XSHG\",",
        "detail": "examples.ExampleOFinrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "CAC_40_TICKER",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config_tickers",
        "description": "examples.ExampleOFinrl.config_tickers",
        "peekOfCode": "CAC_40_TICKER = [\n    \"AC.PA\",\n    \"AI.PA\",\n    \"AIR.PA\",\n    \"MT.AS\",\n    \"ATO.PA\",\n    \"CS.PA\",\n    \"BNP.PA\",\n    \"EN.PA\",\n    \"CAP.PA\",",
        "detail": "examples.ExampleOFinrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "DAX_30_TICKER",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config_tickers",
        "description": "examples.ExampleOFinrl.config_tickers",
        "peekOfCode": "DAX_30_TICKER = [\n    \"DHER.DE\",\n    \"RWE.DE\",\n    \"FRE.DE\",\n    \"MTX.DE\",\n    \"MRK.DE\",\n    \"LIN.DE\",\n    \"ALV.DE\",\n    \"VNA.DE\",\n    \"EOAN.DE\",",
        "detail": "examples.ExampleOFinrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "TECDAX_TICKER",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config_tickers",
        "description": "examples.ExampleOFinrl.config_tickers",
        "peekOfCode": "TECDAX_TICKER = [\n    \"ADV.DE\",\n    \"AFX.DE\",\n    \"AM3D.DE\",\n    \"BC8.DE\",\n    \"COK.DE\",\n    \"DLG.DE\",\n    \"DRI.DE\",\n    \"DRW3.DE\",\n    \"EVT.DE\",",
        "detail": "examples.ExampleOFinrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "MDAX_50_TICKER",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config_tickers",
        "description": "examples.ExampleOFinrl.config_tickers",
        "peekOfCode": "MDAX_50_TICKER = [\n    \"1COV.DE\",\n    \"AIR.DE\",\n    \"AOX.DE\",\n    \"ARL.DE\",\n    \"BNR.DE\",\n    \"BOSS.DE\",\n    \"DEQ.DE\",\n    \"DUE.DE\",\n    \"DWNI.DE\",",
        "detail": "examples.ExampleOFinrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "SDAX_50_TICKER",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config_tickers",
        "description": "examples.ExampleOFinrl.config_tickers",
        "peekOfCode": "SDAX_50_TICKER = [\n    \"AAD.DE\",\n    \"ACX.DE\",\n    \"ADJ.DE\",\n    \"ADL.DE\",\n    \"BDT.DE\",\n    \"BIO3.DE\",\n    \"BVB.DE\",\n    \"BYW6.DE\",\n    \"CWC.DE\",",
        "detail": "examples.ExampleOFinrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "LQ45_TICKER",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config_tickers",
        "description": "examples.ExampleOFinrl.config_tickers",
        "peekOfCode": "LQ45_TICKER = [\n    \"ACES.JK\",\n    \"ADRO.JK\",\n    \"AKRA.JK\",\n    \"ANTM.JK\",\n    \"ASII.JK\",\n    \"BBCA.JK\",\n    \"BBNI.JK\",\n    \"BBRI.JK\",\n    \"BBTN.JK\",",
        "detail": "examples.ExampleOFinrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "SRI_KEHATI_TICKER",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config_tickers",
        "description": "examples.ExampleOFinrl.config_tickers",
        "peekOfCode": "SRI_KEHATI_TICKER = [\n    \"AALI.JK\",\n    \"ADHI.JK\",\n    \"ASII.JK\",\n    \"BBCA.JK\",\n    \"BBNI.JK\",\n    \"BBRI.JK\",\n    \"BBTN.JK\",\n    \"BMRI.JK\",\n    \"BSDE.JK\",",
        "detail": "examples.ExampleOFinrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "FX_TICKER",
        "kind": 5,
        "importPath": "examples.ExampleOFinrl.config_tickers",
        "description": "examples.ExampleOFinrl.config_tickers",
        "peekOfCode": "FX_TICKER = [\n    \"AUDCAD=X\",\n    \"AUDCHF=X\",\n    \"AUDJPY=X\",\n    \"AUDNZD=X\",\n    \"AUDSGD=X\",\n    \"AUDUSD=X\",\n    \"AUDUSD=X\",\n    \"AUDUSD=X\",\n    \"AUDUSD=X\",",
        "detail": "examples.ExampleOFinrl.config_tickers",
        "documentation": {}
    },
    {
        "label": "build_parser",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.main",
        "description": "examples.ExampleOFinrl.main",
        "peekOfCode": "def build_parser():\n    parser = ArgumentParser()\n    parser.add_argument(\n        \"--mode\",\n        dest=\"mode\",\n        help=\"start mode, train, download_data\" \" backtest\",\n        metavar=\"MODE\",\n        default=\"train\",\n    )\n    return parser",
        "detail": "examples.ExampleOFinrl.main",
        "documentation": {}
    },
    {
        "label": "check_and_make_directories",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.main",
        "description": "examples.ExampleOFinrl.main",
        "peekOfCode": "def check_and_make_directories(directories: list[str]):\n    for directory in directories:\n        if not os.path.exists(\"./\" + directory):\n            os.makedirs(\"./\" + directory)\ndef main() -> int:\n    parser = build_parser()\n    options = parser.parse_args()\n    check_and_make_directories(\n        [DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR]\n    )",
        "detail": "examples.ExampleOFinrl.main",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.main",
        "description": "examples.ExampleOFinrl.main",
        "peekOfCode": "def main() -> int:\n    parser = build_parser()\n    options = parser.parse_args()\n    check_and_make_directories(\n        [DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR]\n    )\n    if options.mode == \"train\":\n        from finrl import train\n        env = StockTradingEnv\n        # demo for elegantrl",
        "detail": "examples.ExampleOFinrl.main",
        "documentation": {}
    },
    {
        "label": "get_daily_return",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.plot",
        "description": "examples.ExampleOFinrl.plot",
        "peekOfCode": "def get_daily_return(df, value_col_name=\"account_value\"):\n    df = deepcopy(df)\n    df[\"daily_return\"] = df[value_col_name].pct_change(1)\n    df[\"date\"] = pd.to_datetime(df[\"date\"])\n    df.set_index(\"date\", inplace=True, drop=True)\n    df.index = df.index.tz_localize(\"UTC\")\n    return pd.Series(df[\"daily_return\"], index=df.index)\ndef convert_daily_return_to_pyfolio_ts(df):\n    strategy_ret = df.copy()\n    strategy_ret[\"date\"] = pd.to_datetime(strategy_ret[\"date\"])",
        "detail": "examples.ExampleOFinrl.plot",
        "documentation": {}
    },
    {
        "label": "convert_daily_return_to_pyfolio_ts",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.plot",
        "description": "examples.ExampleOFinrl.plot",
        "peekOfCode": "def convert_daily_return_to_pyfolio_ts(df):\n    strategy_ret = df.copy()\n    strategy_ret[\"date\"] = pd.to_datetime(strategy_ret[\"date\"])\n    strategy_ret.set_index(\"date\", drop=False, inplace=True)\n    strategy_ret.index = strategy_ret.index.tz_localize(\"UTC\")\n    del strategy_ret[\"date\"]\n    return pd.Series(strategy_ret[\"daily_return\"].values, index=strategy_ret.index)\ndef backtest_stats(account_value, value_col_name=\"account_value\"):\n    dr_test = get_daily_return(account_value, value_col_name=value_col_name)\n    perf_stats_all = timeseries.perf_stats(",
        "detail": "examples.ExampleOFinrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_stats",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.plot",
        "description": "examples.ExampleOFinrl.plot",
        "peekOfCode": "def backtest_stats(account_value, value_col_name=\"account_value\"):\n    dr_test = get_daily_return(account_value, value_col_name=value_col_name)\n    perf_stats_all = timeseries.perf_stats(\n        returns=dr_test,\n        positions=None,\n        transactions=None,\n        turnover_denom=\"AGB\",\n    )\n    print(perf_stats_all)\n    return perf_stats_all",
        "detail": "examples.ExampleOFinrl.plot",
        "documentation": {}
    },
    {
        "label": "backtest_plot",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.plot",
        "description": "examples.ExampleOFinrl.plot",
        "peekOfCode": "def backtest_plot(\n    account_value,\n    baseline_start=config.TRADE_START_DATE,\n    baseline_end=config.TRADE_END_DATE,\n    baseline_ticker=\"^DJI\",\n    value_col_name=\"account_value\",\n):\n    df = deepcopy(account_value)\n    df[\"date\"] = pd.to_datetime(df[\"date\"])\n    test_returns = get_daily_return(df, value_col_name=value_col_name)",
        "detail": "examples.ExampleOFinrl.plot",
        "documentation": {}
    },
    {
        "label": "get_baseline",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.plot",
        "description": "examples.ExampleOFinrl.plot",
        "peekOfCode": "def get_baseline(ticker, start, end):\n    return YahooDownloader(\n        start_date=start, end_date=end, ticker_list=[ticker]\n    ).fetch_data()\ndef trx_plot(df_trade, df_actions, ticker_list):\n    df_trx = pd.DataFrame(np.array(df_actions[\"transactions\"].to_list()))\n    df_trx.columns = ticker_list\n    df_trx.index = df_actions[\"date\"]\n    df_trx.index.name = \"\"\n    for i in range(df_trx.shape[1]):",
        "detail": "examples.ExampleOFinrl.plot",
        "documentation": {}
    },
    {
        "label": "trx_plot",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.plot",
        "description": "examples.ExampleOFinrl.plot",
        "peekOfCode": "def trx_plot(df_trade, df_actions, ticker_list):\n    df_trx = pd.DataFrame(np.array(df_actions[\"transactions\"].to_list()))\n    df_trx.columns = ticker_list\n    df_trx.index = df_actions[\"date\"]\n    df_trx.index.name = \"\"\n    for i in range(df_trx.shape[1]):\n        df_trx_temp = df_trx.iloc[:, i]\n        df_trx_temp_sign = np.sign(df_trx_temp)\n        buying_signal = df_trx_temp_sign.apply(lambda x: x > 0)\n        selling_signal = df_trx_temp_sign.apply(lambda x: x < 0)",
        "detail": "examples.ExampleOFinrl.plot",
        "documentation": {}
    },
    {
        "label": "transfer_date",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.plot",
        "description": "examples.ExampleOFinrl.plot",
        "peekOfCode": "def transfer_date(str_dat):\n    return datetime.datetime.strptime(str_dat, \"%Y-%m-%d\").date().strftime(\"%m/%d/%Y\")\ndef plot_result_from_csv(\n    csv_file: str,\n    column_as_x: str,\n    savefig_filename: str = \"fig/result.png\",\n    xlabel: str = \"Date\",\n    ylabel: str = \"Result\",\n    num_days_xticks: int = 20,\n    xrotation: int = 0,",
        "detail": "examples.ExampleOFinrl.plot",
        "documentation": {}
    },
    {
        "label": "plot_result_from_csv",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.plot",
        "description": "examples.ExampleOFinrl.plot",
        "peekOfCode": "def plot_result_from_csv(\n    csv_file: str,\n    column_as_x: str,\n    savefig_filename: str = \"fig/result.png\",\n    xlabel: str = \"Date\",\n    ylabel: str = \"Result\",\n    num_days_xticks: int = 20,\n    xrotation: int = 0,\n):\n    result = pd.read_csv(csv_file)",
        "detail": "examples.ExampleOFinrl.plot",
        "documentation": {}
    },
    {
        "label": "plot_result",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.plot",
        "description": "examples.ExampleOFinrl.plot",
        "peekOfCode": "def plot_result(\n    result: pd.DataFrame(),\n    column_as_x: str,\n    savefig_filename: str = \"fig/result.png\",\n    xlabel: str = \"Date\",\n    ylabel: str = \"Result\",\n    num_days_xticks: int = 20,\n    xrotation: int = 0,\n):\n    columns = result.columns",
        "detail": "examples.ExampleOFinrl.plot",
        "documentation": {}
    },
    {
        "label": "get_if_overlap",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.plot",
        "description": "examples.ExampleOFinrl.plot",
        "peekOfCode": "def get_if_overlap(fig, ax):\n    fig.canvas.draw()\n    # \n    bboxes = [label.get_window_extent() for label in ax.get_xticklabels()]\n    # \n    distances = [bboxes[i + 1].x0 - bboxes[i].x1 for i in range(len(bboxes) - 1)]\n    # 0\n    if any(distance < 0 for distance in distances):\n        if_overlap = True\n    else:",
        "detail": "examples.ExampleOFinrl.plot",
        "documentation": {}
    },
    {
        "label": "plot_return",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.plot",
        "description": "examples.ExampleOFinrl.plot",
        "peekOfCode": "def plot_return(\n    result: pd.DataFrame(),\n    column_as_x: str,\n    if_need_calc_return: bool,\n    savefig_filename: str = \"fig/result.png\",\n    xlabel: str = \"Date\",\n    ylabel: str = \"Return\",\n    if_transfer_date: bool = True,\n    select_start_date: str = None,\n    select_end_date: str = None,",
        "detail": "examples.ExampleOFinrl.plot",
        "documentation": {}
    },
    {
        "label": "plot_return_from_csv",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.plot",
        "description": "examples.ExampleOFinrl.plot",
        "peekOfCode": "def plot_return_from_csv(\n    csv_file: str,\n    column_as_x: str,\n    if_need_calc_return: bool,\n    savefig_filename: str = \"fig/result.png\",\n    xlabel: str = \"Date\",\n    ylabel: str = \"Return\",\n    if_transfer_date: bool = True,\n    select_start_date: str = None,\n    select_end_date: str = None,",
        "detail": "examples.ExampleOFinrl.plot",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.test",
        "description": "examples.ExampleOFinrl.test",
        "peekOfCode": "def test(\n    start_date,\n    end_date,\n    ticker_list,\n    data_source,\n    time_interval,\n    technical_indicator_list,\n    drl_lib,\n    env,\n    model_name,",
        "detail": "examples.ExampleOFinrl.test",
        "documentation": {}
    },
    {
        "label": "trade",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.trade",
        "description": "examples.ExampleOFinrl.trade",
        "peekOfCode": "def trade(\n    start_date,\n    end_date,\n    ticker_list,\n    data_source,\n    time_interval,\n    technical_indicator_list,\n    drl_lib,\n    env,\n    model_name,",
        "detail": "examples.ExampleOFinrl.trade",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "examples.ExampleOFinrl.train",
        "description": "examples.ExampleOFinrl.train",
        "peekOfCode": "def train(\n    start_date,\n    end_date,\n    ticker_list,\n    data_source,\n    time_interval,\n    technical_indicator_list,\n    drl_lib,\n    env,\n    model_name,",
        "detail": "examples.ExampleOFinrl.train",
        "documentation": {}
    },
    {
        "label": "process_ticker_data",
        "kind": 2,
        "importPath": "examples.taiStock.example_of_shioaji_api",
        "description": "examples.taiStock.example_of_shioaji_api",
        "peekOfCode": "def process_ticker_data(ticker):\n    print(f\"Processing data for ticker: {ticker}\")\n    df_raw = SinopacDownloader(\n        start_date=TRAIN_START_DATE, end_date=TRADE_END_DATE, ticker_list=[ticker]\n    ).fetch_data()\n    df_raw.rename(\n        columns={\n            \"open\": \"Open\",\n            \"high\": \"High\",\n            \"low\": \"Low\",",
        "detail": "examples.taiStock.example_of_shioaji_api",
        "documentation": {}
    },
    {
        "label": "TAI_0050_TICKER",
        "kind": 5,
        "importPath": "examples.taiStock.example_of_shioaji_api",
        "description": "examples.taiStock.example_of_shioaji_api",
        "peekOfCode": "TAI_0050_TICKER = [\n    \"3008\",  # Largan Precision Co., Ltd.\n    \"1303\",  # Nan Ya Plastics Corporation\n    \"2412\",  # Chunghwa Telecom Co., Ltd.\n    \"1301\",  # Formosa Plastics Corporation\n    \"1216\",  # Uni-President Enterprises Corporation\n    \"2881\",  # Fubon Financial Holding Co., Ltd.\n    \"2882\",  # Cathay Financial Holding Co., Ltd.\n    \"5871\",  # China Development Financial Holding Corporation\n    \"2886\",  # Mega Financial Holding Co., Ltd.",
        "detail": "examples.taiStock.example_of_shioaji_api",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "kind": 5,
        "importPath": "examples.taiStock.example_of_shioaji_api",
        "description": "examples.taiStock.example_of_shioaji_api",
        "peekOfCode": "TRAIN_START_DATE = \"2023-04-13\"\nTRAIN_END_DATE = \"2024-04-13\"\nTRADE_START_DATE = \"2024-04-13\"\nTRADE_END_DATE = \"2024-07-31\"\ndef process_ticker_data(ticker):\n    print(f\"Processing data for ticker: {ticker}\")\n    df_raw = SinopacDownloader(\n        start_date=TRAIN_START_DATE, end_date=TRADE_END_DATE, ticker_list=[ticker]\n    ).fetch_data()\n    df_raw.rename(",
        "detail": "examples.taiStock.example_of_shioaji_api",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "kind": 5,
        "importPath": "examples.taiStock.example_of_shioaji_api",
        "description": "examples.taiStock.example_of_shioaji_api",
        "peekOfCode": "TRAIN_END_DATE = \"2024-04-13\"\nTRADE_START_DATE = \"2024-04-13\"\nTRADE_END_DATE = \"2024-07-31\"\ndef process_ticker_data(ticker):\n    print(f\"Processing data for ticker: {ticker}\")\n    df_raw = SinopacDownloader(\n        start_date=TRAIN_START_DATE, end_date=TRADE_END_DATE, ticker_list=[ticker]\n    ).fetch_data()\n    df_raw.rename(\n        columns={",
        "detail": "examples.taiStock.example_of_shioaji_api",
        "documentation": {}
    },
    {
        "label": "TRADE_START_DATE",
        "kind": 5,
        "importPath": "examples.taiStock.example_of_shioaji_api",
        "description": "examples.taiStock.example_of_shioaji_api",
        "peekOfCode": "TRADE_START_DATE = \"2024-04-13\"\nTRADE_END_DATE = \"2024-07-31\"\ndef process_ticker_data(ticker):\n    print(f\"Processing data for ticker: {ticker}\")\n    df_raw = SinopacDownloader(\n        start_date=TRAIN_START_DATE, end_date=TRADE_END_DATE, ticker_list=[ticker]\n    ).fetch_data()\n    df_raw.rename(\n        columns={\n            \"open\": \"Open\",",
        "detail": "examples.taiStock.example_of_shioaji_api",
        "documentation": {}
    },
    {
        "label": "TRADE_END_DATE",
        "kind": 5,
        "importPath": "examples.taiStock.example_of_shioaji_api",
        "description": "examples.taiStock.example_of_shioaji_api",
        "peekOfCode": "TRADE_END_DATE = \"2024-07-31\"\ndef process_ticker_data(ticker):\n    print(f\"Processing data for ticker: {ticker}\")\n    df_raw = SinopacDownloader(\n        start_date=TRAIN_START_DATE, end_date=TRADE_END_DATE, ticker_list=[ticker]\n    ).fetch_data()\n    df_raw.rename(\n        columns={\n            \"open\": \"Open\",\n            \"high\": \"High\",",
        "detail": "examples.taiStock.example_of_shioaji_api",
        "documentation": {}
    },
    {
        "label": "df_final",
        "kind": 5,
        "importPath": "examples.taiStock.example_of_shioaji_api",
        "description": "examples.taiStock.example_of_shioaji_api",
        "peekOfCode": "df_final = pd.DataFrame()\nfor ticker in TAI_0050_TICKER:\n    process_ticker_data(ticker)\n    # Load processed data from file and concatenate\n    df_ticker = pd.read_csv(f\"data_{ticker}.csv\")\n    df_final = pd.concat([df_final, df_ticker], ignore_index=True)\n    del df_ticker  # free up memory\n    gc.collect()\ntrain = data_split(df_final, TRAIN_START_DATE, TRAIN_END_DATE)\ntrade = data_split(df_final, TRADE_START_DATE, TRADE_END_DATE)",
        "detail": "examples.taiStock.example_of_shioaji_api",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 5,
        "importPath": "examples.taiStock.example_of_shioaji_api",
        "description": "examples.taiStock.example_of_shioaji_api",
        "peekOfCode": "train = data_split(df_final, TRAIN_START_DATE, TRAIN_END_DATE)\ntrade = data_split(df_final, TRADE_START_DATE, TRADE_END_DATE)\ntrain.to_csv(\"train_data.csv\")\ntrade.to_csv(\"trade_data.csv\")",
        "detail": "examples.taiStock.example_of_shioaji_api",
        "documentation": {}
    },
    {
        "label": "trade",
        "kind": 5,
        "importPath": "examples.taiStock.example_of_shioaji_api",
        "description": "examples.taiStock.example_of_shioaji_api",
        "peekOfCode": "trade = data_split(df_final, TRADE_START_DATE, TRADE_END_DATE)\ntrain.to_csv(\"train_data.csv\")\ntrade.to_csv(\"trade_data.csv\")",
        "detail": "examples.taiStock.example_of_shioaji_api",
        "documentation": {}
    },
    {
        "label": "SinopacProcessor",
        "kind": 6,
        "importPath": "examples.taiStock.processor_sinopac",
        "description": "examples.taiStock.processor_sinopac",
        "peekOfCode": "class SinopacProcessor:\n    def __init__(self, API_KEY=None, API_SECRET=None, api=None):\n        if api is None:\n            try:\n                self.api = sj.Shioaji()\n                self.api.login(\n                    api_key=API_KEY,\n                    secret_key=API_SECRET,\n                    contracts_cb=lambda security_type: print(\n                        f\"{repr(security_type)} fetch done.\"",
        "detail": "examples.taiStock.processor_sinopac",
        "documentation": {}
    },
    {
        "label": "SinopacDownloader",
        "kind": 6,
        "importPath": "examples.taiStock.shioajidownloader",
        "description": "examples.taiStock.shioajidownloader",
        "peekOfCode": "class SinopacDownloader:\n    def __init__(\n        self,\n        start_date: str,\n        end_date: str,\n        ticker_list: list = [],\n        api: sj.Shioaji = None,\n    ):\n        if api is None:\n            self.api = sj.Shioaji()",
        "detail": "examples.taiStock.shioajidownloader",
        "documentation": {}
    },
    {
        "label": "process_ticker_data",
        "kind": 2,
        "importPath": "examples.taiStock.t7",
        "description": "examples.taiStock.t7",
        "peekOfCode": "def process_ticker_data(ticker):\n    print(f\"Processing data for ticker: {ticker}\")\n    df_raw = SinopacDownloader(\n        start_date=TRAIN_START_DATE, end_date=TRADE_END_DATE, ticker_list=[ticker]\n    ).fetch_data()\n    df_raw.rename(\n        columns={\n            \"open\": \"Open\",\n            \"high\": \"High\",\n            \"low\": \"Low\",",
        "detail": "examples.taiStock.t7",
        "documentation": {}
    },
    {
        "label": "TAI_0050_TICKER",
        "kind": 5,
        "importPath": "examples.taiStock.t7",
        "description": "examples.taiStock.t7",
        "peekOfCode": "TAI_0050_TICKER = [\n    \"3008\",  # Largan Precision Co., Ltd.\n    \"1303\",  # Nan Ya Plastics Corporation\n    \"2412\",  # Chunghwa Telecom Co., Ltd.\n    \"1301\",  # Formosa Plastics Corporation\n    \"1216\",  # Uni-President Enterprises Corporation\n    \"2881\",  # Fubon Financial Holding Co., Ltd.\n    \"2882\",  # Cathay Financial Holding Co., Ltd.\n    \"5871\",  # China Development Financial Holding Corporation\n    \"2886\",  # Mega Financial Holding Co., Ltd.",
        "detail": "examples.taiStock.t7",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "kind": 5,
        "importPath": "examples.taiStock.t7",
        "description": "examples.taiStock.t7",
        "peekOfCode": "TRAIN_START_DATE = \"2023-04-13\"\nTRAIN_END_DATE = \"2024-04-13\"\nTRADE_START_DATE = \"2024-04-13\"\nTRADE_END_DATE = \"2024-07-31\"\ndef process_ticker_data(ticker):\n    print(f\"Processing data for ticker: {ticker}\")\n    df_raw = SinopacDownloader(\n        start_date=TRAIN_START_DATE, end_date=TRADE_END_DATE, ticker_list=[ticker]\n    ).fetch_data()\n    df_raw.rename(",
        "detail": "examples.taiStock.t7",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "kind": 5,
        "importPath": "examples.taiStock.t7",
        "description": "examples.taiStock.t7",
        "peekOfCode": "TRAIN_END_DATE = \"2024-04-13\"\nTRADE_START_DATE = \"2024-04-13\"\nTRADE_END_DATE = \"2024-07-31\"\ndef process_ticker_data(ticker):\n    print(f\"Processing data for ticker: {ticker}\")\n    df_raw = SinopacDownloader(\n        start_date=TRAIN_START_DATE, end_date=TRADE_END_DATE, ticker_list=[ticker]\n    ).fetch_data()\n    df_raw.rename(\n        columns={",
        "detail": "examples.taiStock.t7",
        "documentation": {}
    },
    {
        "label": "TRADE_START_DATE",
        "kind": 5,
        "importPath": "examples.taiStock.t7",
        "description": "examples.taiStock.t7",
        "peekOfCode": "TRADE_START_DATE = \"2024-04-13\"\nTRADE_END_DATE = \"2024-07-31\"\ndef process_ticker_data(ticker):\n    print(f\"Processing data for ticker: {ticker}\")\n    df_raw = SinopacDownloader(\n        start_date=TRAIN_START_DATE, end_date=TRADE_END_DATE, ticker_list=[ticker]\n    ).fetch_data()\n    df_raw.rename(\n        columns={\n            \"open\": \"Open\",",
        "detail": "examples.taiStock.t7",
        "documentation": {}
    },
    {
        "label": "TRADE_END_DATE",
        "kind": 5,
        "importPath": "examples.taiStock.t7",
        "description": "examples.taiStock.t7",
        "peekOfCode": "TRADE_END_DATE = \"2024-07-31\"\ndef process_ticker_data(ticker):\n    print(f\"Processing data for ticker: {ticker}\")\n    df_raw = SinopacDownloader(\n        start_date=TRAIN_START_DATE, end_date=TRADE_END_DATE, ticker_list=[ticker]\n    ).fetch_data()\n    df_raw.rename(\n        columns={\n            \"open\": \"Open\",\n            \"high\": \"High\",",
        "detail": "examples.taiStock.t7",
        "documentation": {}
    },
    {
        "label": "df_final",
        "kind": 5,
        "importPath": "examples.taiStock.t7",
        "description": "examples.taiStock.t7",
        "peekOfCode": "df_final = pd.DataFrame()\nfor ticker in TAI_0050_TICKER:\n    process_ticker_data(ticker)\n    # Load processed data from file and concatenate\n    df_ticker = pd.read_csv(f\"data_{ticker}.csv\")\n    df_final = pd.concat([df_final, df_ticker], ignore_index=True)\n    del df_ticker  # free up memory\n    gc.collect()\ntrain = data_split(df_final, TRAIN_START_DATE, TRAIN_END_DATE)\ntrade = data_split(df_final, TRADE_START_DATE, TRADE_END_DATE)",
        "detail": "examples.taiStock.t7",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 5,
        "importPath": "examples.taiStock.t7",
        "description": "examples.taiStock.t7",
        "peekOfCode": "train = data_split(df_final, TRAIN_START_DATE, TRAIN_END_DATE)\ntrade = data_split(df_final, TRADE_START_DATE, TRADE_END_DATE)\ntrain.to_csv(\"train_data.csv\")\ntrade.to_csv(\"trade_data.csv\")",
        "detail": "examples.taiStock.t7",
        "documentation": {}
    },
    {
        "label": "trade",
        "kind": 5,
        "importPath": "examples.taiStock.t7",
        "description": "examples.taiStock.t7",
        "peekOfCode": "trade = data_split(df_final, TRADE_START_DATE, TRADE_END_DATE)\ntrain.to_csv(\"train_data.csv\")\ntrade.to_csv(\"trade_data.csv\")",
        "detail": "examples.taiStock.t7",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "parser = argparse.ArgumentParser()\nparser.add_argument(\"data_key\", help=\"data source api key\")\nparser.add_argument(\"data_secret\", help=\"data source api secret\")\nparser.add_argument(\"data_url\", help=\"data source api base url\")\nparser.add_argument(\"trading_key\", help=\"trading api key\")\nparser.add_argument(\"trading_secret\", help=\"trading api secret\")\nparser.add_argument(\"trading_url\", help=\"trading api base url\")\nargs = parser.parse_args()\nDATA_API_KEY = args.data_key\nDATA_API_SECRET = args.data_secret",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "args",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "args = parser.parse_args()\nDATA_API_KEY = args.data_key\nDATA_API_SECRET = args.data_secret\nDATA_API_BASE_URL = args.data_url\nTRADING_API_KEY = args.trading_key\nTRADING_API_SECRET = args.trading_secret\nTRADING_API_BASE_URL = args.trading_url\nprint(\"DATA_API_KEY: \", DATA_API_KEY)\nprint(\"DATA_API_SECRET: \", DATA_API_SECRET)\nprint(\"DATA_API_BASE_URL: \", DATA_API_BASE_URL)",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "DATA_API_KEY",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "DATA_API_KEY = args.data_key\nDATA_API_SECRET = args.data_secret\nDATA_API_BASE_URL = args.data_url\nTRADING_API_KEY = args.trading_key\nTRADING_API_SECRET = args.trading_secret\nTRADING_API_BASE_URL = args.trading_url\nprint(\"DATA_API_KEY: \", DATA_API_KEY)\nprint(\"DATA_API_SECRET: \", DATA_API_SECRET)\nprint(\"DATA_API_BASE_URL: \", DATA_API_BASE_URL)\nprint(\"TRADING_API_KEY: \", TRADING_API_KEY)",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "DATA_API_SECRET",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "DATA_API_SECRET = args.data_secret\nDATA_API_BASE_URL = args.data_url\nTRADING_API_KEY = args.trading_key\nTRADING_API_SECRET = args.trading_secret\nTRADING_API_BASE_URL = args.trading_url\nprint(\"DATA_API_KEY: \", DATA_API_KEY)\nprint(\"DATA_API_SECRET: \", DATA_API_SECRET)\nprint(\"DATA_API_BASE_URL: \", DATA_API_BASE_URL)\nprint(\"TRADING_API_KEY: \", TRADING_API_KEY)\nprint(\"TRADING_API_SECRET: \", TRADING_API_SECRET)",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "DATA_API_BASE_URL",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "DATA_API_BASE_URL = args.data_url\nTRADING_API_KEY = args.trading_key\nTRADING_API_SECRET = args.trading_secret\nTRADING_API_BASE_URL = args.trading_url\nprint(\"DATA_API_KEY: \", DATA_API_KEY)\nprint(\"DATA_API_SECRET: \", DATA_API_SECRET)\nprint(\"DATA_API_BASE_URL: \", DATA_API_BASE_URL)\nprint(\"TRADING_API_KEY: \", TRADING_API_KEY)\nprint(\"TRADING_API_SECRET: \", TRADING_API_SECRET)\nprint(\"TRADING_API_BASE_URL: \", TRADING_API_BASE_URL)",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "TRADING_API_KEY",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "TRADING_API_KEY = args.trading_key\nTRADING_API_SECRET = args.trading_secret\nTRADING_API_BASE_URL = args.trading_url\nprint(\"DATA_API_KEY: \", DATA_API_KEY)\nprint(\"DATA_API_SECRET: \", DATA_API_SECRET)\nprint(\"DATA_API_BASE_URL: \", DATA_API_BASE_URL)\nprint(\"TRADING_API_KEY: \", TRADING_API_KEY)\nprint(\"TRADING_API_SECRET: \", TRADING_API_SECRET)\nprint(\"TRADING_API_BASE_URL: \", TRADING_API_BASE_URL)\nfrom finrl.meta.env_stock_trading.env_stocktrading_np import StockTradingEnv",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "TRADING_API_SECRET",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "TRADING_API_SECRET = args.trading_secret\nTRADING_API_BASE_URL = args.trading_url\nprint(\"DATA_API_KEY: \", DATA_API_KEY)\nprint(\"DATA_API_SECRET: \", DATA_API_SECRET)\nprint(\"DATA_API_BASE_URL: \", DATA_API_BASE_URL)\nprint(\"TRADING_API_KEY: \", TRADING_API_KEY)\nprint(\"TRADING_API_SECRET: \", TRADING_API_SECRET)\nprint(\"TRADING_API_BASE_URL: \", TRADING_API_BASE_URL)\nfrom finrl.meta.env_stock_trading.env_stocktrading_np import StockTradingEnv\nfrom finrl.meta.paper_trading.alpaca import PaperTradingAlpaca",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "TRADING_API_BASE_URL",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "TRADING_API_BASE_URL = args.trading_url\nprint(\"DATA_API_KEY: \", DATA_API_KEY)\nprint(\"DATA_API_SECRET: \", DATA_API_SECRET)\nprint(\"DATA_API_BASE_URL: \", DATA_API_BASE_URL)\nprint(\"TRADING_API_KEY: \", TRADING_API_KEY)\nprint(\"TRADING_API_SECRET: \", TRADING_API_SECRET)\nprint(\"TRADING_API_BASE_URL: \", TRADING_API_BASE_URL)\nfrom finrl.meta.env_stock_trading.env_stocktrading_np import StockTradingEnv\nfrom finrl.meta.paper_trading.alpaca import PaperTradingAlpaca\nfrom finrl.meta.paper_trading.common import train, test, alpaca_history, DIA_history",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "ticker_list",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "ticker_list = DOW_30_TICKER\nenv = StockTradingEnv\n# if you want to use larger datasets (change to longer period), and it raises error, please try to increase \"target_step\". It should be larger than the episode steps.\nERL_PARAMS = {\n    \"learning_rate\": 3e-6,\n    \"batch_size\": 2048,\n    \"gamma\": 0.985,\n    \"seed\": 312,\n    \"net_dimension\": [128, 64],\n    \"target_step\": 5000,",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "env",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "env = StockTradingEnv\n# if you want to use larger datasets (change to longer period), and it raises error, please try to increase \"target_step\". It should be larger than the episode steps.\nERL_PARAMS = {\n    \"learning_rate\": 3e-6,\n    \"batch_size\": 2048,\n    \"gamma\": 0.985,\n    \"seed\": 312,\n    \"net_dimension\": [128, 64],\n    \"target_step\": 5000,\n    \"eval_gap\": 30,",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "ERL_PARAMS",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "ERL_PARAMS = {\n    \"learning_rate\": 3e-6,\n    \"batch_size\": 2048,\n    \"gamma\": 0.985,\n    \"seed\": 312,\n    \"net_dimension\": [128, 64],\n    \"target_step\": 5000,\n    \"eval_gap\": 30,\n    \"eval_times\": 1,\n}",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "today",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "today = datetime.datetime.today()\nTEST_END_DATE = (today - BDay(1)).to_pydatetime().date()\nTEST_START_DATE = (TEST_END_DATE - BDay(1)).to_pydatetime().date()\nTRAIN_END_DATE = (TEST_START_DATE - BDay(1)).to_pydatetime().date()\nTRAIN_START_DATE = (TRAIN_END_DATE - BDay(5)).to_pydatetime().date()\nTRAINFULL_START_DATE = TRAIN_START_DATE\nTRAINFULL_END_DATE = TEST_END_DATE\nTRAIN_START_DATE = str(TRAIN_START_DATE)\nTRAIN_END_DATE = str(TRAIN_END_DATE)\nTEST_START_DATE = str(TEST_START_DATE)",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "TEST_END_DATE = (today - BDay(1)).to_pydatetime().date()\nTEST_START_DATE = (TEST_END_DATE - BDay(1)).to_pydatetime().date()\nTRAIN_END_DATE = (TEST_START_DATE - BDay(1)).to_pydatetime().date()\nTRAIN_START_DATE = (TRAIN_END_DATE - BDay(5)).to_pydatetime().date()\nTRAINFULL_START_DATE = TRAIN_START_DATE\nTRAINFULL_END_DATE = TEST_END_DATE\nTRAIN_START_DATE = str(TRAIN_START_DATE)\nTRAIN_END_DATE = str(TRAIN_END_DATE)\nTEST_START_DATE = str(TEST_START_DATE)\nTEST_END_DATE = str(TEST_END_DATE)",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "TEST_START_DATE = (TEST_END_DATE - BDay(1)).to_pydatetime().date()\nTRAIN_END_DATE = (TEST_START_DATE - BDay(1)).to_pydatetime().date()\nTRAIN_START_DATE = (TRAIN_END_DATE - BDay(5)).to_pydatetime().date()\nTRAINFULL_START_DATE = TRAIN_START_DATE\nTRAINFULL_END_DATE = TEST_END_DATE\nTRAIN_START_DATE = str(TRAIN_START_DATE)\nTRAIN_END_DATE = str(TRAIN_END_DATE)\nTEST_START_DATE = str(TEST_START_DATE)\nTEST_END_DATE = str(TEST_END_DATE)\nTRAINFULL_START_DATE = str(TRAINFULL_START_DATE)",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "TRAIN_END_DATE = (TEST_START_DATE - BDay(1)).to_pydatetime().date()\nTRAIN_START_DATE = (TRAIN_END_DATE - BDay(5)).to_pydatetime().date()\nTRAINFULL_START_DATE = TRAIN_START_DATE\nTRAINFULL_END_DATE = TEST_END_DATE\nTRAIN_START_DATE = str(TRAIN_START_DATE)\nTRAIN_END_DATE = str(TRAIN_END_DATE)\nTEST_START_DATE = str(TEST_START_DATE)\nTEST_END_DATE = str(TEST_END_DATE)\nTRAINFULL_START_DATE = str(TRAINFULL_START_DATE)\nTRAINFULL_END_DATE = str(TRAINFULL_END_DATE)",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "TRAIN_START_DATE = (TRAIN_END_DATE - BDay(5)).to_pydatetime().date()\nTRAINFULL_START_DATE = TRAIN_START_DATE\nTRAINFULL_END_DATE = TEST_END_DATE\nTRAIN_START_DATE = str(TRAIN_START_DATE)\nTRAIN_END_DATE = str(TRAIN_END_DATE)\nTEST_START_DATE = str(TEST_START_DATE)\nTEST_END_DATE = str(TEST_END_DATE)\nTRAINFULL_START_DATE = str(TRAINFULL_START_DATE)\nTRAINFULL_END_DATE = str(TRAINFULL_END_DATE)\nprint(\"TRAIN_START_DATE: \", TRAIN_START_DATE)",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "TRAINFULL_START_DATE",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "TRAINFULL_START_DATE = TRAIN_START_DATE\nTRAINFULL_END_DATE = TEST_END_DATE\nTRAIN_START_DATE = str(TRAIN_START_DATE)\nTRAIN_END_DATE = str(TRAIN_END_DATE)\nTEST_START_DATE = str(TEST_START_DATE)\nTEST_END_DATE = str(TEST_END_DATE)\nTRAINFULL_START_DATE = str(TRAINFULL_START_DATE)\nTRAINFULL_END_DATE = str(TRAINFULL_END_DATE)\nprint(\"TRAIN_START_DATE: \", TRAIN_START_DATE)\nprint(\"TRAIN_END_DATE: \", TRAIN_END_DATE)",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "TRAINFULL_END_DATE",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "TRAINFULL_END_DATE = TEST_END_DATE\nTRAIN_START_DATE = str(TRAIN_START_DATE)\nTRAIN_END_DATE = str(TRAIN_END_DATE)\nTEST_START_DATE = str(TEST_START_DATE)\nTEST_END_DATE = str(TEST_END_DATE)\nTRAINFULL_START_DATE = str(TRAINFULL_START_DATE)\nTRAINFULL_END_DATE = str(TRAINFULL_END_DATE)\nprint(\"TRAIN_START_DATE: \", TRAIN_START_DATE)\nprint(\"TRAIN_END_DATE: \", TRAIN_END_DATE)\nprint(\"TEST_START_DATE: \", TEST_START_DATE)",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "TRAIN_START_DATE = str(TRAIN_START_DATE)\nTRAIN_END_DATE = str(TRAIN_END_DATE)\nTEST_START_DATE = str(TEST_START_DATE)\nTEST_END_DATE = str(TEST_END_DATE)\nTRAINFULL_START_DATE = str(TRAINFULL_START_DATE)\nTRAINFULL_END_DATE = str(TRAINFULL_END_DATE)\nprint(\"TRAIN_START_DATE: \", TRAIN_START_DATE)\nprint(\"TRAIN_END_DATE: \", TRAIN_END_DATE)\nprint(\"TEST_START_DATE: \", TEST_START_DATE)\nprint(\"TEST_END_DATE: \", TEST_END_DATE)",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "TRAIN_END_DATE = str(TRAIN_END_DATE)\nTEST_START_DATE = str(TEST_START_DATE)\nTEST_END_DATE = str(TEST_END_DATE)\nTRAINFULL_START_DATE = str(TRAINFULL_START_DATE)\nTRAINFULL_END_DATE = str(TRAINFULL_END_DATE)\nprint(\"TRAIN_START_DATE: \", TRAIN_START_DATE)\nprint(\"TRAIN_END_DATE: \", TRAIN_END_DATE)\nprint(\"TEST_START_DATE: \", TEST_START_DATE)\nprint(\"TEST_END_DATE: \", TEST_END_DATE)\nprint(\"TRAINFULL_START_DATE: \", TRAINFULL_START_DATE)",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "TEST_START_DATE = str(TEST_START_DATE)\nTEST_END_DATE = str(TEST_END_DATE)\nTRAINFULL_START_DATE = str(TRAINFULL_START_DATE)\nTRAINFULL_END_DATE = str(TRAINFULL_END_DATE)\nprint(\"TRAIN_START_DATE: \", TRAIN_START_DATE)\nprint(\"TRAIN_END_DATE: \", TRAIN_END_DATE)\nprint(\"TEST_START_DATE: \", TEST_START_DATE)\nprint(\"TEST_END_DATE: \", TEST_END_DATE)\nprint(\"TRAINFULL_START_DATE: \", TRAINFULL_START_DATE)\nprint(\"TRAINFULL_END_DATE: \", TRAINFULL_END_DATE)",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "TEST_END_DATE = str(TEST_END_DATE)\nTRAINFULL_START_DATE = str(TRAINFULL_START_DATE)\nTRAINFULL_END_DATE = str(TRAINFULL_END_DATE)\nprint(\"TRAIN_START_DATE: \", TRAIN_START_DATE)\nprint(\"TRAIN_END_DATE: \", TRAIN_END_DATE)\nprint(\"TEST_START_DATE: \", TEST_START_DATE)\nprint(\"TEST_END_DATE: \", TEST_END_DATE)\nprint(\"TRAINFULL_START_DATE: \", TRAINFULL_START_DATE)\nprint(\"TRAINFULL_END_DATE: \", TRAINFULL_END_DATE)\ntrain(",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "TRAINFULL_START_DATE",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "TRAINFULL_START_DATE = str(TRAINFULL_START_DATE)\nTRAINFULL_END_DATE = str(TRAINFULL_END_DATE)\nprint(\"TRAIN_START_DATE: \", TRAIN_START_DATE)\nprint(\"TRAIN_END_DATE: \", TRAIN_END_DATE)\nprint(\"TEST_START_DATE: \", TEST_START_DATE)\nprint(\"TEST_END_DATE: \", TEST_END_DATE)\nprint(\"TRAINFULL_START_DATE: \", TRAINFULL_START_DATE)\nprint(\"TRAINFULL_END_DATE: \", TRAINFULL_END_DATE)\ntrain(\n    start_date=TRAIN_START_DATE,",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "TRAINFULL_END_DATE",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "TRAINFULL_END_DATE = str(TRAINFULL_END_DATE)\nprint(\"TRAIN_START_DATE: \", TRAIN_START_DATE)\nprint(\"TRAIN_END_DATE: \", TRAIN_END_DATE)\nprint(\"TEST_START_DATE: \", TEST_START_DATE)\nprint(\"TEST_END_DATE: \", TEST_END_DATE)\nprint(\"TRAINFULL_START_DATE: \", TRAINFULL_START_DATE)\nprint(\"TRAINFULL_END_DATE: \", TRAINFULL_END_DATE)\ntrain(\n    start_date=TRAIN_START_DATE,\n    end_date=TRAIN_END_DATE,",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "account_value_erl",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "account_value_erl = test(\n    start_date=TEST_START_DATE,\n    end_date=TEST_END_DATE,\n    ticker_list=ticker_list,\n    data_source=\"alpaca\",\n    time_interval=\"1Min\",\n    technical_indicator_list=INDICATORS,\n    drl_lib=\"elegantrl\",\n    env=env,\n    model_name=\"ppo\",",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "action_dim",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "action_dim = len(DOW_30_TICKER)\nstate_dim = (\n    1 + 2 + 3 * action_dim + len(INDICATORS) * action_dim\n)  # Calculate the DRL state dimension manually for paper trading. amount + (turbulence, turbulence_bool) + (price, shares, cd (holding time)) * stock_dim + tech_dim\npaper_trading_erl = PaperTradingAlpaca(\n    ticker_list=DOW_30_TICKER,\n    time_interval=\"1Min\",\n    drl_lib=\"elegantrl\",\n    agent=\"ppo\",\n    cwd=\"./papertrading_erl_retrain\",",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "state_dim",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "state_dim = (\n    1 + 2 + 3 * action_dim + len(INDICATORS) * action_dim\n)  # Calculate the DRL state dimension manually for paper trading. amount + (turbulence, turbulence_bool) + (price, shares, cd (holding time)) * stock_dim + tech_dim\npaper_trading_erl = PaperTradingAlpaca(\n    ticker_list=DOW_30_TICKER,\n    time_interval=\"1Min\",\n    drl_lib=\"elegantrl\",\n    agent=\"ppo\",\n    cwd=\"./papertrading_erl_retrain\",\n    net_dim=ERL_PARAMS[\"net_dimension\"],",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "paper_trading_erl",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "paper_trading_erl = PaperTradingAlpaca(\n    ticker_list=DOW_30_TICKER,\n    time_interval=\"1Min\",\n    drl_lib=\"elegantrl\",\n    agent=\"ppo\",\n    cwd=\"./papertrading_erl_retrain\",\n    net_dim=ERL_PARAMS[\"net_dimension\"],\n    state_dim=state_dim,\n    action_dim=action_dim,\n    API_KEY=TRADING_API_KEY,",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "returns_erl",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "returns_erl = cumu_erl - 1\nreturns_dia = cumu_djia - 1\nreturns_dia = returns_dia[: returns_erl.shape[0]]\n# plot and save\nimport matplotlib.pyplot as plt\nplt.figure(dpi=1000)\nplt.grid()\nplt.grid(which=\"minor\", axis=\"y\")\nplt.title(\"Stock Trading (Paper trading)\", fontsize=20)\nplt.plot(returns_erl, label=\"ElegantRL Agent\", color=\"red\")",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "returns_dia",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "returns_dia = cumu_djia - 1\nreturns_dia = returns_dia[: returns_erl.shape[0]]\n# plot and save\nimport matplotlib.pyplot as plt\nplt.figure(dpi=1000)\nplt.grid()\nplt.grid(which=\"minor\", axis=\"y\")\nplt.title(\"Stock Trading (Paper trading)\", fontsize=20)\nplt.plot(returns_erl, label=\"ElegantRL Agent\", color=\"red\")\n# plt.plot(returns_sb3, label = 'Stable-Baselines3 Agent', color = 'blue' )",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "returns_dia",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "returns_dia = returns_dia[: returns_erl.shape[0]]\n# plot and save\nimport matplotlib.pyplot as plt\nplt.figure(dpi=1000)\nplt.grid()\nplt.grid(which=\"minor\", axis=\"y\")\nplt.title(\"Stock Trading (Paper trading)\", fontsize=20)\nplt.plot(returns_erl, label=\"ElegantRL Agent\", color=\"red\")\n# plt.plot(returns_sb3, label = 'Stable-Baselines3 Agent', color = 'blue' )\n# plt.plot(returns_rllib, label = 'RLlib Agent', color = 'green')",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "ax",
        "kind": 5,
        "importPath": "examples.FinRL_PaperTrading_Demo_refactored",
        "description": "examples.FinRL_PaperTrading_Demo_refactored",
        "peekOfCode": "ax = plt.gca()\nax.xaxis.set_major_locator(ticker.MultipleLocator(78))\nax.xaxis.set_minor_locator(ticker.MultipleLocator(6))\nax.yaxis.set_minor_locator(ticker.MultipleLocator(0.005))\nax.yaxis.set_major_formatter(ticker.PercentFormatter(xmax=1, decimals=2))\nax.xaxis.set_major_formatter(\n    ticker.FixedFormatter([\"\", \"10-19\", \"\", \"10-20\", \"\", \"10-21\", \"\", \"10-22\"])\n)\nplt.legend(fontsize=10.5)\nplt.savefig(\"papertrading_stock.png\")",
        "detail": "examples.FinRL_PaperTrading_Demo_refactored",
        "documentation": {}
    },
    {
        "label": "API_KEY",
        "kind": 5,
        "importPath": "examples.p1",
        "description": "examples.p1",
        "peekOfCode": "API_KEY = \"PKA2OY3YK7Y4M6Q7LCLR\"\nAPI_SECRET = \"BxT64PIQtDBb*tnW\"\nAPI_BASE_URL = 'https://paper-api.alpaca.markets'\n# Initialize the Alpaca client\napi = tradeapi.REST(API_KEY, API_SECRET, API_BASE_URL, api_version='v2')\ntry:\n    # Get account information\n    account = api.get_account()\n    print(f\"Account status: {account.status}\")\n    # Define order parameters",
        "detail": "examples.p1",
        "documentation": {}
    },
    {
        "label": "API_SECRET",
        "kind": 5,
        "importPath": "examples.p1",
        "description": "examples.p1",
        "peekOfCode": "API_SECRET = \"BxT64PIQtDBb*tnW\"\nAPI_BASE_URL = 'https://paper-api.alpaca.markets'\n# Initialize the Alpaca client\napi = tradeapi.REST(API_KEY, API_SECRET, API_BASE_URL, api_version='v2')\ntry:\n    # Get account information\n    account = api.get_account()\n    print(f\"Account status: {account.status}\")\n    # Define order parameters\n    symbol = 'AAPL'",
        "detail": "examples.p1",
        "documentation": {}
    },
    {
        "label": "API_BASE_URL",
        "kind": 5,
        "importPath": "examples.p1",
        "description": "examples.p1",
        "peekOfCode": "API_BASE_URL = 'https://paper-api.alpaca.markets'\n# Initialize the Alpaca client\napi = tradeapi.REST(API_KEY, API_SECRET, API_BASE_URL, api_version='v2')\ntry:\n    # Get account information\n    account = api.get_account()\n    print(f\"Account status: {account.status}\")\n    # Define order parameters\n    symbol = 'AAPL'\n    qty = 1  # Quantity to buy",
        "detail": "examples.p1",
        "documentation": {}
    },
    {
        "label": "api",
        "kind": 5,
        "importPath": "examples.p1",
        "description": "examples.p1",
        "peekOfCode": "api = tradeapi.REST(API_KEY, API_SECRET, API_BASE_URL, api_version='v2')\ntry:\n    # Get account information\n    account = api.get_account()\n    print(f\"Account status: {account.status}\")\n    # Define order parameters\n    symbol = 'AAPL'\n    qty = 1  # Quantity to buy\n    # Place a buy order\n    buy_order = api.submit_order(",
        "detail": "examples.p1",
        "documentation": {}
    },
    {
        "label": "API_KEY",
        "kind": 5,
        "importPath": "examples.p2",
        "description": "examples.p2",
        "peekOfCode": "API_KEY = \"PKA2OY3YK7Y4M6Q7LCLR\"\nAPI_SECRET = \"BxT64PIQtDBb*tnW\"\nAPI_BASE_URL = 'https://paper-api.alpaca.markets/v2'\ndata_url = 'wss://data.alpaca.markets/v2'\nimport alpaca_trade_api as tradeapi\n# Step 2. Get ticker list, Set start date and end date, specify the data frequency\n# https://data.sandbox.alpaca.markets/v2\nfrom finrl.config_tickers import DOW_30_TICKER\nfrom finrl.config import INDICATORS\nfrom finrl.meta.env_stock_trading.env_stocktrading_np import StockTradingEnv",
        "detail": "examples.p2",
        "documentation": {}
    },
    {
        "label": "API_SECRET",
        "kind": 5,
        "importPath": "examples.p2",
        "description": "examples.p2",
        "peekOfCode": "API_SECRET = \"BxT64PIQtDBb*tnW\"\nAPI_BASE_URL = 'https://paper-api.alpaca.markets/v2'\ndata_url = 'wss://data.alpaca.markets/v2'\nimport alpaca_trade_api as tradeapi\n# Step 2. Get ticker list, Set start date and end date, specify the data frequency\n# https://data.sandbox.alpaca.markets/v2\nfrom finrl.config_tickers import DOW_30_TICKER\nfrom finrl.config import INDICATORS\nfrom finrl.meta.env_stock_trading.env_stocktrading_np import StockTradingEnv\nfrom finrl.meta.env_stock_trading.env_stock_papertrading import AlpacaPaperTrading",
        "detail": "examples.p2",
        "documentation": {}
    },
    {
        "label": "API_BASE_URL",
        "kind": 5,
        "importPath": "examples.p2",
        "description": "examples.p2",
        "peekOfCode": "API_BASE_URL = 'https://paper-api.alpaca.markets/v2'\ndata_url = 'wss://data.alpaca.markets/v2'\nimport alpaca_trade_api as tradeapi\n# Step 2. Get ticker list, Set start date and end date, specify the data frequency\n# https://data.sandbox.alpaca.markets/v2\nfrom finrl.config_tickers import DOW_30_TICKER\nfrom finrl.config import INDICATORS\nfrom finrl.meta.env_stock_trading.env_stocktrading_np import StockTradingEnv\nfrom finrl.meta.env_stock_trading.env_stock_papertrading import AlpacaPaperTrading\nfrom finrl.meta.data_processor import DataProcessor",
        "detail": "examples.p2",
        "documentation": {}
    },
    {
        "label": "data_url",
        "kind": 5,
        "importPath": "examples.p2",
        "description": "examples.p2",
        "peekOfCode": "data_url = 'wss://data.alpaca.markets/v2'\nimport alpaca_trade_api as tradeapi\n# Step 2. Get ticker list, Set start date and end date, specify the data frequency\n# https://data.sandbox.alpaca.markets/v2\nfrom finrl.config_tickers import DOW_30_TICKER\nfrom finrl.config import INDICATORS\nfrom finrl.meta.env_stock_trading.env_stocktrading_np import StockTradingEnv\nfrom finrl.meta.env_stock_trading.env_stock_papertrading import AlpacaPaperTrading\nfrom finrl.meta.data_processor import DataProcessor\nfrom finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline",
        "detail": "examples.p2",
        "documentation": {}
    },
    {
        "label": "api",
        "kind": 5,
        "importPath": "examples.p2",
        "description": "examples.p2",
        "peekOfCode": "api = tradeapi.REST(API_KEY, API_SECRET, API_BASE_URL, api_version='v2')",
        "detail": "examples.p2",
        "documentation": {}
    },
    {
        "label": "fetch_data",
        "kind": 2,
        "importPath": "examples.p3",
        "description": "examples.p3",
        "peekOfCode": "def fetch_data():\n    data = yf.download(SYMBOL, start=START_DATE, end=END_DATE, interval='1m')\n    # Filter data for 1:23 PM for each of the last 7 days\n    data = data.between_time('13:23', '13:23')\n    return data\ndef stock_grabber():\n    data = fetch_data()\n    # Extract the closing price for 1:23 PM each day\n    return data['Close']\n# Initialize variables for plotting",
        "detail": "examples.p3",
        "documentation": {}
    },
    {
        "label": "stock_grabber",
        "kind": 2,
        "importPath": "examples.p3",
        "description": "examples.p3",
        "peekOfCode": "def stock_grabber():\n    data = fetch_data()\n    # Extract the closing price for 1:23 PM each day\n    return data['Close']\n# Initialize variables for plotting\nx = []\ny = []\n# Function to update the animation\ndef animate(i):\n    global x, y",
        "detail": "examples.p3",
        "documentation": {}
    },
    {
        "label": "animate",
        "kind": 2,
        "importPath": "examples.p3",
        "description": "examples.p3",
        "peekOfCode": "def animate(i):\n    global x, y\n    y = stock_grabber()\n    x = [date.strftime('%Y-%m-%d') for date in y.index]\n    plt.cla()  # Clear the previous plot\n    plt.plot(x, y, marker='o', label='1:23 PM Close Price')\n    plt.xlabel('Date')\n    plt.ylabel('Price')\n    plt.title(f\"Apple (AAPL) Price at 1:23 PM for the Last 7 Days\")\n    plt.xticks(rotation=45)",
        "detail": "examples.p3",
        "documentation": {}
    },
    {
        "label": "SYMBOL",
        "kind": 5,
        "importPath": "examples.p3",
        "description": "examples.p3",
        "peekOfCode": "SYMBOL = 'AAPL'\nSTART_DATE = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')\nEND_DATE = datetime.now().strftime('%Y-%m-%d')\n# Function to fetch historical data from Yahoo Finance\ndef fetch_data():\n    data = yf.download(SYMBOL, start=START_DATE, end=END_DATE, interval='1m')\n    # Filter data for 1:23 PM for each of the last 7 days\n    data = data.between_time('13:23', '13:23')\n    return data\ndef stock_grabber():",
        "detail": "examples.p3",
        "documentation": {}
    },
    {
        "label": "START_DATE",
        "kind": 5,
        "importPath": "examples.p3",
        "description": "examples.p3",
        "peekOfCode": "START_DATE = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')\nEND_DATE = datetime.now().strftime('%Y-%m-%d')\n# Function to fetch historical data from Yahoo Finance\ndef fetch_data():\n    data = yf.download(SYMBOL, start=START_DATE, end=END_DATE, interval='1m')\n    # Filter data for 1:23 PM for each of the last 7 days\n    data = data.between_time('13:23', '13:23')\n    return data\ndef stock_grabber():\n    data = fetch_data()",
        "detail": "examples.p3",
        "documentation": {}
    },
    {
        "label": "END_DATE",
        "kind": 5,
        "importPath": "examples.p3",
        "description": "examples.p3",
        "peekOfCode": "END_DATE = datetime.now().strftime('%Y-%m-%d')\n# Function to fetch historical data from Yahoo Finance\ndef fetch_data():\n    data = yf.download(SYMBOL, start=START_DATE, end=END_DATE, interval='1m')\n    # Filter data for 1:23 PM for each of the last 7 days\n    data = data.between_time('13:23', '13:23')\n    return data\ndef stock_grabber():\n    data = fetch_data()\n    # Extract the closing price for 1:23 PM each day",
        "detail": "examples.p3",
        "documentation": {}
    },
    {
        "label": "x",
        "kind": 5,
        "importPath": "examples.p3",
        "description": "examples.p3",
        "peekOfCode": "x = []\ny = []\n# Function to update the animation\ndef animate(i):\n    global x, y\n    y = stock_grabber()\n    x = [date.strftime('%Y-%m-%d') for date in y.index]\n    plt.cla()  # Clear the previous plot\n    plt.plot(x, y, marker='o', label='1:23 PM Close Price')\n    plt.xlabel('Date')",
        "detail": "examples.p3",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": "examples.p3",
        "description": "examples.p3",
        "peekOfCode": "y = []\n# Function to update the animation\ndef animate(i):\n    global x, y\n    y = stock_grabber()\n    x = [date.strftime('%Y-%m-%d') for date in y.index]\n    plt.cla()  # Clear the previous plot\n    plt.plot(x, y, marker='o', label='1:23 PM Close Price')\n    plt.xlabel('Date')\n    plt.ylabel('Price')",
        "detail": "examples.p3",
        "documentation": {}
    },
    {
        "label": "ani",
        "kind": 5,
        "importPath": "examples.p3",
        "description": "examples.p3",
        "peekOfCode": "ani = FuncAnimation(plt.gcf(), animate, interval=1000)\nplt.show()",
        "detail": "examples.p3",
        "documentation": {}
    },
    {
        "label": "fetch_and_process_data",
        "kind": 2,
        "importPath": "examples.p5",
        "description": "examples.p5",
        "peekOfCode": "def fetch_and_process_data(ticker_list, start_date, end_date, technical_indicator_list, if_vix):\n    # Initialize an empty list to hold dataframes\n    data_frames = []\n    # Fetch data for each ticker\n    for ticker in ticker_list:\n        # Download historical data\n        data = yf.download(ticker, start=start_date, end=end_date)\n        # Add ticker column\n        data['Ticker'] = ticker\n        # Append the dataframe to the list",
        "detail": "examples.p5",
        "documentation": {}
    },
    {
        "label": "ticker_list",
        "kind": 5,
        "importPath": "examples.p5",
        "description": "examples.p5",
        "peekOfCode": "ticker_list = ['AAPL', 'MSFT']  # List of tickers\nstart_date = '2023-01-01'\nend_date = '2023-08-01'\ntechnical_indicator_list = ['SMA', 'EMA']\nif_vix = False\nprice_array, tech_array, turbulence_array = fetch_and_process_data(ticker_list, start_date, end_date, technical_indicator_list, if_vix)\nprint(\"Price Array:\", price_array)\nprint(\"Technical Indicators Array:\", tech_array)\nprint(\"Turbulence Array:\", turbulence_array)",
        "detail": "examples.p5",
        "documentation": {}
    },
    {
        "label": "start_date",
        "kind": 5,
        "importPath": "examples.p5",
        "description": "examples.p5",
        "peekOfCode": "start_date = '2023-01-01'\nend_date = '2023-08-01'\ntechnical_indicator_list = ['SMA', 'EMA']\nif_vix = False\nprice_array, tech_array, turbulence_array = fetch_and_process_data(ticker_list, start_date, end_date, technical_indicator_list, if_vix)\nprint(\"Price Array:\", price_array)\nprint(\"Technical Indicators Array:\", tech_array)\nprint(\"Turbulence Array:\", turbulence_array)",
        "detail": "examples.p5",
        "documentation": {}
    },
    {
        "label": "end_date",
        "kind": 5,
        "importPath": "examples.p5",
        "description": "examples.p5",
        "peekOfCode": "end_date = '2023-08-01'\ntechnical_indicator_list = ['SMA', 'EMA']\nif_vix = False\nprice_array, tech_array, turbulence_array = fetch_and_process_data(ticker_list, start_date, end_date, technical_indicator_list, if_vix)\nprint(\"Price Array:\", price_array)\nprint(\"Technical Indicators Array:\", tech_array)\nprint(\"Turbulence Array:\", turbulence_array)",
        "detail": "examples.p5",
        "documentation": {}
    },
    {
        "label": "technical_indicator_list",
        "kind": 5,
        "importPath": "examples.p5",
        "description": "examples.p5",
        "peekOfCode": "technical_indicator_list = ['SMA', 'EMA']\nif_vix = False\nprice_array, tech_array, turbulence_array = fetch_and_process_data(ticker_list, start_date, end_date, technical_indicator_list, if_vix)\nprint(\"Price Array:\", price_array)\nprint(\"Technical Indicators Array:\", tech_array)\nprint(\"Turbulence Array:\", turbulence_array)",
        "detail": "examples.p5",
        "documentation": {}
    },
    {
        "label": "if_vix",
        "kind": 5,
        "importPath": "examples.p5",
        "description": "examples.p5",
        "peekOfCode": "if_vix = False\nprice_array, tech_array, turbulence_array = fetch_and_process_data(ticker_list, start_date, end_date, technical_indicator_list, if_vix)\nprint(\"Price Array:\", price_array)\nprint(\"Technical Indicators Array:\", tech_array)\nprint(\"Turbulence Array:\", turbulence_array)",
        "detail": "examples.p5",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "examples.t1",
        "description": "examples.t1",
        "peekOfCode": "def main():\n    import warnings\n    warnings.filterwarnings(\"ignore\")\n    import pandas as pd\n    import numpy as np\n    import matplotlib\n    import matplotlib.pyplot as plt\n    # matplotlib.use('Agg')\n    import datetime\n    from finrl.config_tickers import DOW_30_TICKER",
        "detail": "examples.t1",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "TRAIN_START_DATE = '2010-01-01'\nTRAIN_END_DATE = '2021-10-01'\nTEST_START_DATE = '2021-10-01'\nTEST_END_DATE = '2023-03-01'\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\nINDICATORS = ['macd',\n               'rsi_30',\n               'cci_30',",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "TRAIN_END_DATE = '2021-10-01'\nTEST_START_DATE = '2021-10-01'\nTEST_END_DATE = '2023-03-01'\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\nINDICATORS = ['macd',\n               'rsi_30',\n               'cci_30',\n               'dx_30']",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "TEST_START_DATE = '2021-10-01'\nTEST_END_DATE = '2023-03-01'\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\nINDICATORS = ['macd',\n               'rsi_30',\n               'cci_30',\n               'dx_30']\nfrom finrl.meta.preprocessor.preprocessors import FeatureEngineer",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "TEST_END_DATE = '2023-03-01'\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\nINDICATORS = ['macd',\n               'rsi_30',\n               'cci_30',\n               'dx_30']\nfrom finrl.meta.preprocessor.preprocessors import FeatureEngineer\nfe = FeatureEngineer(use_technical_indicator=True,",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "df = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\nINDICATORS = ['macd',\n               'rsi_30',\n               'cci_30',\n               'dx_30']\nfrom finrl.meta.preprocessor.preprocessors import FeatureEngineer\nfe = FeatureEngineer(use_technical_indicator=True,\n                     tech_indicator_list = INDICATORS,",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "INDICATORS = ['macd',\n               'rsi_30',\n               'cci_30',\n               'dx_30']\nfrom finrl.meta.preprocessor.preprocessors import FeatureEngineer\nfe = FeatureEngineer(use_technical_indicator=True,\n                     tech_indicator_list = INDICATORS,\n                     use_turbulence=True,\n                     user_defined_feature = False)\nprocessed = fe.preprocess_data(df)",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "fe",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "fe = FeatureEngineer(use_technical_indicator=True,\n                     tech_indicator_list = INDICATORS,\n                     use_turbulence=True,\n                     user_defined_feature = False)\nprocessed = fe.preprocess_data(df)\nprocessed = processed.copy()\nprocessed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "processed = fe.preprocess_data(df)\nprocessed = processed.copy()\nprocessed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100,\n    \"initial_amount\": 1000000,",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "processed = processed.copy()\nprocessed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100,\n    \"initial_amount\": 1000000,\n    \"buy_cost_pct\": 0.001,",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "processed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100,\n    \"initial_amount\": 1000000,\n    \"buy_cost_pct\": 0.001,\n    \"sell_cost_pct\": 0.001,",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "processed = processed.replace(np.inf,0)\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100,\n    \"initial_amount\": 1000000,\n    \"buy_cost_pct\": 0.001,\n    \"sell_cost_pct\": 0.001,\n    \"state_space\": state_space,",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "stock_dimension",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "stock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100,\n    \"initial_amount\": 1000000,\n    \"buy_cost_pct\": 0.001,\n    \"sell_cost_pct\": 0.001,\n    \"state_space\": state_space,\n    \"stock_dim\": stock_dimension,",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "state_space",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100,\n    \"initial_amount\": 1000000,\n    \"buy_cost_pct\": 0.001,\n    \"sell_cost_pct\": 0.001,\n    \"state_space\": state_space,\n    \"stock_dim\": stock_dimension,\n    \"tech_indicator_list\": INDICATORS,",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "env_kwargs",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "env_kwargs = {\n    \"hmax\": 100,\n    \"initial_amount\": 1000000,\n    \"buy_cost_pct\": 0.001,\n    \"sell_cost_pct\": 0.001,\n    \"state_space\": state_space,\n    \"stock_dim\": stock_dimension,\n    \"tech_indicator_list\": INDICATORS,\n    \"action_space\": stock_dimension,\n    \"reward_scaling\": 1e-4,",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "rebalance_window",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "rebalance_window = 63 # rebalance_window is the number of days to retrain the model\nvalidation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\nensemble_agent = DRLEnsembleAgent(df=processed,\n                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n                 rebalance_window=rebalance_window,\n                 validation_window=validation_window,\n                 **env_kwargs)\n# e_train_gym = StockTradingEnv(df = processed, **env_kwargs)\n# agent = DRLAgent(e_train_gym)",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "validation_window",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "validation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\nensemble_agent = DRLEnsembleAgent(df=processed,\n                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n                 rebalance_window=rebalance_window,\n                 validation_window=validation_window,\n                 **env_kwargs)\n# e_train_gym = StockTradingEnv(df = processed, **env_kwargs)\n# agent = DRLAgent(e_train_gym)\n# if_using_a2c = True",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "ensemble_agent",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "ensemble_agent = DRLEnsembleAgent(df=processed,\n                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n                 rebalance_window=rebalance_window,\n                 validation_window=validation_window,\n                 **env_kwargs)\n# e_train_gym = StockTradingEnv(df = processed, **env_kwargs)\n# agent = DRLAgent(e_train_gym)\n# if_using_a2c = True\n# model_a2c = agent.get_model(\"a2c\")",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "A2C_model_kwargs",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "A2C_model_kwargs = {\n                    'n_steps': 5,\n                    'ent_coef': 0.005,\n                    'learning_rate': 0.0007\n                    }\nPPO_model_kwargs = {\n                    \"ent_coef\":0.01,\n                    \"n_steps\": 2048,\n                    \"learning_rate\": 0.00025,\n                    \"batch_size\": 128",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "PPO_model_kwargs",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "PPO_model_kwargs = {\n                    \"ent_coef\":0.01,\n                    \"n_steps\": 2048,\n                    \"learning_rate\": 0.00025,\n                    \"batch_size\": 128\n                    }\nDDPG_model_kwargs = {\n                      #\"action_noise\":\"ornstein_uhlenbeck\",\n                      \"buffer_size\": 10_000,\n                      \"learning_rate\": 0.0005,",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "DDPG_model_kwargs",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "DDPG_model_kwargs = {\n                      #\"action_noise\":\"ornstein_uhlenbeck\",\n                      \"buffer_size\": 10_000,\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64\n                    }\nSAC_model_kwargs = {\n    \"batch_size\": 64,\n    \"buffer_size\": 100000,\n    \"learning_rate\": 0.0001,",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "SAC_model_kwargs",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "SAC_model_kwargs = {\n    \"batch_size\": 64,\n    \"buffer_size\": 100000,\n    \"learning_rate\": 0.0001,\n    \"learning_starts\": 100,\n    \"ent_coef\": \"auto_0.1\",\n}\nTD3_model_kwargs = {\"batch_size\": 100, \"buffer_size\": 1000000, \"learning_rate\": 0.0001}\ntimesteps_dict = {'a2c' : 10_000,\n                 'ppo' : 10_000,",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "TD3_model_kwargs",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "TD3_model_kwargs = {\"batch_size\": 100, \"buffer_size\": 1000000, \"learning_rate\": 0.0001}\ntimesteps_dict = {'a2c' : 10_000,\n                 'ppo' : 10_000,\n                 'ddpg' : 10_000,\n                 'sac' : 10_000,\n                 'td3' : 10_000\n                 }\ndf_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n                                                 PPO_model_kwargs,\n                                                 DDPG_model_kwargs,",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "timesteps_dict",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "timesteps_dict = {'a2c' : 10_000,\n                 'ppo' : 10_000,\n                 'ddpg' : 10_000,\n                 'sac' : 10_000,\n                 'td3' : 10_000\n                 }\ndf_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n                                                 PPO_model_kwargs,\n                                                 DDPG_model_kwargs,\n                                                 SAC_model_kwargs,",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "df_summary",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n                                                 PPO_model_kwargs,\n                                                 DDPG_model_kwargs,\n                                                 SAC_model_kwargs,\n                                                 TD3_model_kwargs,\n                                                 timesteps_dict)\ndf_summary\nunique_trade_date = processed[(processed.date > TEST_START_DATE)&(processed.date <= TEST_END_DATE)].date.unique()\ndf_trade_date = pd.DataFrame({'datadate':unique_trade_date})\ndf_account_value=pd.DataFrame()",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "unique_trade_date",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "unique_trade_date = processed[(processed.date > TEST_START_DATE)&(processed.date <= TEST_END_DATE)].date.unique()\ndf_trade_date = pd.DataFrame({'datadate':unique_trade_date})\ndf_account_value=pd.DataFrame()\nfor i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n    df_account_value = df_account_value._append(temp,ignore_index=True)\nsharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\nprint('Sharpe Ratio: ',sharpe)\ndf_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))\ndf_account_value.head()",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "df_trade_date",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\ndf_account_value=pd.DataFrame()\nfor i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n    df_account_value = df_account_value._append(temp,ignore_index=True)\nsharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\nprint('Sharpe Ratio: ',sharpe)\ndf_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))\ndf_account_value.head()\n# %matplotlib inline",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "now",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\nperf_stats_all = backtest_stats(account_value=df_account_value)\nperf_stats_all = pd.DataFrame(perf_stats_all)\n#baseline stats\nprint(\"==============Get Baseline Stats===========\")\ndf_dji_ = get_baseline(\n        ticker=\"^DJI\",\n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(df_dji_, value_col_name = 'close')",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "perf_stats_all",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "perf_stats_all = backtest_stats(account_value=df_account_value)\nperf_stats_all = pd.DataFrame(perf_stats_all)\n#baseline stats\nprint(\"==============Get Baseline Stats===========\")\ndf_dji_ = get_baseline(\n        ticker=\"^DJI\",\n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(df_dji_, value_col_name = 'close')\ndf_dji = pd.DataFrame()",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "perf_stats_all",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "perf_stats_all = pd.DataFrame(perf_stats_all)\n#baseline stats\nprint(\"==============Get Baseline Stats===========\")\ndf_dji_ = get_baseline(\n        ticker=\"^DJI\",\n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(df_dji_, value_col_name = 'close')\ndf_dji = pd.DataFrame()\ndf_dji['date'] = df_account_value['date']",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "df_dji_",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "df_dji_ = get_baseline(\n        ticker=\"^DJI\",\n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(df_dji_, value_col_name = 'close')\ndf_dji = pd.DataFrame()\ndf_dji['date'] = df_account_value['date']\ndf_dji['dji'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\nprint(\"df_dji: \", df_dji)\ndf_dji.to_csv(\"df_dji.csv\")",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "stats",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "stats = backtest_stats(df_dji_, value_col_name = 'close')\ndf_dji = pd.DataFrame()\ndf_dji['date'] = df_account_value['date']\ndf_dji['dji'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\nprint(\"df_dji: \", df_dji)\ndf_dji.to_csv(\"df_dji.csv\")\ndf_dji = df_dji.set_index(df_dji.columns[0])\nprint(\"df_dji: \", df_dji)\ndf_dji.to_csv(\"df_dji+.csv\")\ndf_account_value.to_csv('df_account_value.csv')",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "df_dji",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "df_dji = pd.DataFrame()\ndf_dji['date'] = df_account_value['date']\ndf_dji['dji'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\nprint(\"df_dji: \", df_dji)\ndf_dji.to_csv(\"df_dji.csv\")\ndf_dji = df_dji.set_index(df_dji.columns[0])\nprint(\"df_dji: \", df_dji)\ndf_dji.to_csv(\"df_dji+.csv\")\ndf_account_value.to_csv('df_account_value.csv')\n# <a id='6.2'></a>",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "df_dji['date']",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "df_dji['date'] = df_account_value['date']\ndf_dji['dji'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\nprint(\"df_dji: \", df_dji)\ndf_dji.to_csv(\"df_dji.csv\")\ndf_dji = df_dji.set_index(df_dji.columns[0])\nprint(\"df_dji: \", df_dji)\ndf_dji.to_csv(\"df_dji+.csv\")\ndf_account_value.to_csv('df_account_value.csv')\n# <a id='6.2'></a>\n## 7.2 BackTestPlot",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "df_dji['dji']",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "df_dji['dji'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\nprint(\"df_dji: \", df_dji)\ndf_dji.to_csv(\"df_dji.csv\")\ndf_dji = df_dji.set_index(df_dji.columns[0])\nprint(\"df_dji: \", df_dji)\ndf_dji.to_csv(\"df_dji+.csv\")\ndf_account_value.to_csv('df_account_value.csv')\n# <a id='6.2'></a>\n## 7.2 BackTestPlot\n# print(\"==============Compare to DJIA===========\")",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "df_dji",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "df_dji = df_dji.set_index(df_dji.columns[0])\nprint(\"df_dji: \", df_dji)\ndf_dji.to_csv(\"df_dji+.csv\")\ndf_account_value.to_csv('df_account_value.csv')\n# <a id='6.2'></a>\n## 7.2 BackTestPlot\n# print(\"==============Compare to DJIA===========\")\n# %matplotlib inline\n# # S&P 500: ^GSPC\n# # Dow Jones Index: ^DJI",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "df_result_ensemble",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "df_result_ensemble = pd.DataFrame({'date': df_account_value['date'], 'ensemble': df_account_value['account_value']})\ndf_result_ensemble = df_result_ensemble.set_index('date')\nprint(\"df_result_ensemble.columns: \", df_result_ensemble.columns)\n# df_result_ensemble.drop(df_result_ensemble.columns[0], axis = 1)\nprint(\"df_trade_date: \", df_trade_date)\n# df_result_ensemble['date'] = df_trade_date['datadate']\n# df_result_ensemble['account_value'] = df_account_value['account_value']\ndf_result_ensemble.to_csv(\"df_result_ensemble.csv\")\nprint(\"df_result_ensemble: \", df_result_ensemble)\nprint(\"==============Compare to DJIA===========\")",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "df_result_ensemble",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "df_result_ensemble = df_result_ensemble.set_index('date')\nprint(\"df_result_ensemble.columns: \", df_result_ensemble.columns)\n# df_result_ensemble.drop(df_result_ensemble.columns[0], axis = 1)\nprint(\"df_trade_date: \", df_trade_date)\n# df_result_ensemble['date'] = df_trade_date['datadate']\n# df_result_ensemble['account_value'] = df_account_value['account_value']\ndf_result_ensemble.to_csv(\"df_result_ensemble.csv\")\nprint(\"df_result_ensemble: \", df_result_ensemble)\nprint(\"==============Compare to DJIA===========\")\nresult = pd.DataFrame()",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "result",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "result = pd.DataFrame()\n# result = pd.merge(result, df_result_ensemble, left_index=True, right_index=True)\n# result = pd.merge(result, df_dji, left_index=True, right_index=True)\nresult = pd.merge(df_result_ensemble, df_dji, left_index=True, right_index=True)\nprint(\"result: \", result)\nresult.to_csv(\"result.csv\")\nresult.columns = ['ensemble', 'dji']\n# %matplotlib inline\nplt.rcParams[\"figure.figsize\"] = (15,5)\nplt.figure();",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "result",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "result = pd.merge(df_result_ensemble, df_dji, left_index=True, right_index=True)\nprint(\"result: \", result)\nresult.to_csv(\"result.csv\")\nresult.columns = ['ensemble', 'dji']\n# %matplotlib inline\nplt.rcParams[\"figure.figsize\"] = (15,5)\nplt.figure();\nresult.plot();",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "result.columns",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "result.columns = ['ensemble', 'dji']\n# %matplotlib inline\nplt.rcParams[\"figure.figsize\"] = (15,5)\nplt.figure();\nresult.plot();",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "plt.rcParams[\"figure.figsize\"]",
        "kind": 5,
        "importPath": "examples.t2",
        "description": "examples.t2",
        "peekOfCode": "plt.rcParams[\"figure.figsize\"] = (15,5)\nplt.figure();\nresult.plot();",
        "detail": "examples.t2",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "TRAIN_START_DATE = '2010-01-01'\nTRAIN_END_DATE = '2021-10-01'\nTEST_START_DATE = '2021-10-01'\nTEST_END_DATE = '2023-03-01'\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\n# Part 4: Preprocess Data\n# Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n# * Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "TRAIN_END_DATE = '2021-10-01'\nTEST_START_DATE = '2021-10-01'\nTEST_END_DATE = '2023-03-01'\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\n# Part 4: Preprocess Data\n# Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n# * Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n# * Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 20072008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation.",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "TEST_START_DATE",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "TEST_START_DATE = '2021-10-01'\nTEST_END_DATE = '2023-03-01'\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\n# Part 4: Preprocess Data\n# Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n# * Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n# * Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 20072008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation.\nINDICATORS = ['macd',",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "TEST_END_DATE",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "TEST_END_DATE = '2023-03-01'\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\n# Part 4: Preprocess Data\n# Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n# * Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n# * Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 20072008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation.\nINDICATORS = ['macd',\n               'rsi_30',",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "df = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TEST_END_DATE,\n                     ticker_list = DOW_30_TICKER).fetch_data()\n# Part 4: Preprocess Data\n# Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n# * Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n# * Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 20072008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation.\nINDICATORS = ['macd',\n               'rsi_30',\n               'cci_30',",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "INDICATORS",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "INDICATORS = ['macd',\n               'rsi_30',\n               'cci_30',\n               'dx_30']\nfrom finrl.meta.preprocessor.preprocessors import FeatureEngineer\nfe = FeatureEngineer(use_technical_indicator=True,\n                     tech_indicator_list = INDICATORS,\n                     use_turbulence=True,\n                     user_defined_feature = False)\nprocessed = fe.preprocess_data(df)",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "fe",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "fe = FeatureEngineer(use_technical_indicator=True,\n                     tech_indicator_list = INDICATORS,\n                     use_turbulence=True,\n                     user_defined_feature = False)\nprocessed = fe.preprocess_data(df)\nprocessed = processed.copy()\nprocessed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\n# len(state), len(data)\n# <a id='4'></a>",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "processed = fe.preprocess_data(df)\nprocessed = processed.copy()\nprocessed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\n# len(state), len(data)\n# <a id='4'></a>\n# Part 5. Design Environment\n# Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n# Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n# The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,,-1, 0, 1,, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric.",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "processed = processed.copy()\nprocessed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\n# len(state), len(data)\n# <a id='4'></a>\n# Part 5. Design Environment\n# Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n# Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n# The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,,-1, 0, 1,, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric.\nstock_dimension = len(processed.tic.unique())",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "processed = processed.fillna(0)\nprocessed = processed.replace(np.inf,0)\n# len(state), len(data)\n# <a id='4'></a>\n# Part 5. Design Environment\n# Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n# Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n# The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,,-1, 0, 1,, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric.\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "processed = processed.replace(np.inf,0)\n# len(state), len(data)\n# <a id='4'></a>\n# Part 5. Design Environment\n# Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n# Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n# The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,,-1, 0, 1,, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric.\nstock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "stock_dimension",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "stock_dimension = len(processed.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100,\n    \"initial_amount\": 1000000,\n    \"buy_cost_pct\": 0.001,\n    \"sell_cost_pct\": 0.001,\n    \"state_space\": state_space,\n    \"stock_dim\": stock_dimension,",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "state_space",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nenv_kwargs = {\n    \"hmax\": 100,\n    \"initial_amount\": 1000000,\n    \"buy_cost_pct\": 0.001,\n    \"sell_cost_pct\": 0.001,\n    \"state_space\": state_space,\n    \"stock_dim\": stock_dimension,\n    \"tech_indicator_list\": INDICATORS,",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "env_kwargs",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "env_kwargs = {\n    \"hmax\": 100,\n    \"initial_amount\": 1000000,\n    \"buy_cost_pct\": 0.001,\n    \"sell_cost_pct\": 0.001,\n    \"state_space\": state_space,\n    \"stock_dim\": stock_dimension,\n    \"tech_indicator_list\": INDICATORS,\n    \"action_space\": stock_dimension,\n    \"reward_scaling\": 1e-4,",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "rebalance_window",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "rebalance_window = 63 # rebalance_window is the number of days to retrain the model\nvalidation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\nensemble_agent = DRLEnsembleAgent(df=processed,\n                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n                 rebalance_window=rebalance_window,\n                 validation_window=validation_window,\n                 **env_kwargs)\n# e_train_gym = StockTradingEnv(df = processed, **env_kwargs)\n# agent = DRLAgent(e_train_gym)",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "validation_window",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "validation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\nensemble_agent = DRLEnsembleAgent(df=processed,\n                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n                 rebalance_window=rebalance_window,\n                 validation_window=validation_window,\n                 **env_kwargs)\n# e_train_gym = StockTradingEnv(df = processed, **env_kwargs)\n# agent = DRLAgent(e_train_gym)\n# if_using_a2c = True",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "ensemble_agent",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "ensemble_agent = DRLEnsembleAgent(df=processed,\n                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n                 rebalance_window=rebalance_window,\n                 validation_window=validation_window,\n                 **env_kwargs)\n# e_train_gym = StockTradingEnv(df = processed, **env_kwargs)\n# agent = DRLAgent(e_train_gym)\n# if_using_a2c = True\n# model_a2c = agent.get_model(\"a2c\")",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "A2C_model_kwargs",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "A2C_model_kwargs = {\n                    'n_steps': 5,\n                    'ent_coef': 0.005,\n                    'learning_rate': 0.0007\n                    }\nPPO_model_kwargs = {\n                    \"ent_coef\":0.01,\n                    \"n_steps\": 2048,\n                    \"learning_rate\": 0.00025,\n                    \"batch_size\": 128",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "PPO_model_kwargs",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "PPO_model_kwargs = {\n                    \"ent_coef\":0.01,\n                    \"n_steps\": 2048,\n                    \"learning_rate\": 0.00025,\n                    \"batch_size\": 128\n                    }\nDDPG_model_kwargs = {\n                      #\"action_noise\":\"ornstein_uhlenbeck\",\n                      \"buffer_size\": 10_000,\n                      \"learning_rate\": 0.0005,",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "DDPG_model_kwargs",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "DDPG_model_kwargs = {\n                      #\"action_noise\":\"ornstein_uhlenbeck\",\n                      \"buffer_size\": 10_000,\n                      \"learning_rate\": 0.0005,\n                      \"batch_size\": 64\n                    }\nSAC_model_kwargs = {\n    \"batch_size\": 64,\n    \"buffer_size\": 100000,\n    \"learning_rate\": 0.0001,",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "SAC_model_kwargs",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "SAC_model_kwargs = {\n    \"batch_size\": 64,\n    \"buffer_size\": 100000,\n    \"learning_rate\": 0.0001,\n    \"learning_starts\": 100,\n    \"ent_coef\": \"auto_0.1\",\n}\nTD3_model_kwargs = {\"batch_size\": 100, \"buffer_size\": 1000000, \"learning_rate\": 0.0001}\ntimesteps_dict = {'a2c' : 10_000,\n                 'ppo' : 10_000,",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "TD3_model_kwargs",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "TD3_model_kwargs = {\"batch_size\": 100, \"buffer_size\": 1000000, \"learning_rate\": 0.0001}\ntimesteps_dict = {'a2c' : 10_000,\n                 'ppo' : 10_000,\n                 'ddpg' : 10_000,\n                 'sac' : 10_000,\n                 'td3' : 10_000\n                 }\ndf_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n                                                 PPO_model_kwargs,\n                                                 DDPG_model_kwargs,",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "timesteps_dict",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "timesteps_dict = {'a2c' : 10_000,\n                 'ppo' : 10_000,\n                 'ddpg' : 10_000,\n                 'sac' : 10_000,\n                 'td3' : 10_000\n                 }\ndf_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n                                                 PPO_model_kwargs,\n                                                 DDPG_model_kwargs,\n                                                 SAC_model_kwargs,",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "df_summary",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n                                                 PPO_model_kwargs,\n                                                 DDPG_model_kwargs,\n                                                 SAC_model_kwargs,\n                                                 TD3_model_kwargs,\n                                                 timesteps_dict)\ndf_summary\n# <a id='6'></a>\n# # Part 7: Backtest OurStrategy\n# Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy.",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "unique_trade_date",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "unique_trade_date = processed[(processed.date > TEST_START_DATE)&(processed.date <= TEST_END_DATE)].date.unique()\ndf_trade_date = pd.DataFrame({'datadate':unique_trade_date})\ndf_account_value=pd.DataFrame()\nfor i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n    df_account_value = df_account_value._append(temp,ignore_index=True)\nsharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\nprint('Sharpe Ratio: ',sharpe)\ndf_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))\ndf_account_value.head()",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "df_trade_date",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\ndf_account_value=pd.DataFrame()\nfor i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n    df_account_value = df_account_value._append(temp,ignore_index=True)\nsharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\nprint('Sharpe Ratio: ',sharpe)\ndf_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))\ndf_account_value.head()\n# %matplotlib inline",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "now",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\nperf_stats_all = backtest_stats(account_value=df_account_value)\nperf_stats_all = pd.DataFrame(perf_stats_all)\n#baseline stats\nprint(\"==============Get Baseline Stats===========\")\ndf_dji_ = get_baseline(\n        ticker=\"^DJI\",\n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(df_dji_, value_col_name = 'close')",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "perf_stats_all",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "perf_stats_all = backtest_stats(account_value=df_account_value)\nperf_stats_all = pd.DataFrame(perf_stats_all)\n#baseline stats\nprint(\"==============Get Baseline Stats===========\")\ndf_dji_ = get_baseline(\n        ticker=\"^DJI\",\n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(df_dji_, value_col_name = 'close')\ndf_dji = pd.DataFrame()",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "perf_stats_all",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "perf_stats_all = pd.DataFrame(perf_stats_all)\n#baseline stats\nprint(\"==============Get Baseline Stats===========\")\ndf_dji_ = get_baseline(\n        ticker=\"^DJI\",\n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(df_dji_, value_col_name = 'close')\ndf_dji = pd.DataFrame()\ndf_dji['date'] = df_account_value['date']",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "df_dji_",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "df_dji_ = get_baseline(\n        ticker=\"^DJI\",\n        start = df_account_value.loc[0,'date'],\n        end = df_account_value.loc[len(df_account_value)-1,'date'])\nstats = backtest_stats(df_dji_, value_col_name = 'close')\ndf_dji = pd.DataFrame()\ndf_dji['date'] = df_account_value['date']\ndf_dji['dji'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\nprint(\"df_dji: \", df_dji)\ndf_dji.to_csv(\"df_dji.csv\")",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "stats",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "stats = backtest_stats(df_dji_, value_col_name = 'close')\ndf_dji = pd.DataFrame()\ndf_dji['date'] = df_account_value['date']\ndf_dji['dji'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\nprint(\"df_dji: \", df_dji)\ndf_dji.to_csv(\"df_dji.csv\")\ndf_dji = df_dji.set_index(df_dji.columns[0])\nprint(\"df_dji: \", df_dji)\ndf_dji.to_csv(\"df_dji+.csv\")\ndf_account_value.to_csv('df_account_value.csv')",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "df_dji",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "df_dji = pd.DataFrame()\ndf_dji['date'] = df_account_value['date']\ndf_dji['dji'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\nprint(\"df_dji: \", df_dji)\ndf_dji.to_csv(\"df_dji.csv\")\ndf_dji = df_dji.set_index(df_dji.columns[0])\nprint(\"df_dji: \", df_dji)\ndf_dji.to_csv(\"df_dji+.csv\")\ndf_account_value.to_csv('df_account_value.csv')\n# <a id='6.2'></a>",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "df_dji['date']",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "df_dji['date'] = df_account_value['date']\ndf_dji['dji'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\nprint(\"df_dji: \", df_dji)\ndf_dji.to_csv(\"df_dji.csv\")\ndf_dji = df_dji.set_index(df_dji.columns[0])\nprint(\"df_dji: \", df_dji)\ndf_dji.to_csv(\"df_dji+.csv\")\ndf_account_value.to_csv('df_account_value.csv')\n# <a id='6.2'></a>\n## 7.2 BackTestPlot",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "df_dji['dji']",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "df_dji['dji'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\nprint(\"df_dji: \", df_dji)\ndf_dji.to_csv(\"df_dji.csv\")\ndf_dji = df_dji.set_index(df_dji.columns[0])\nprint(\"df_dji: \", df_dji)\ndf_dji.to_csv(\"df_dji+.csv\")\ndf_account_value.to_csv('df_account_value.csv')\n# <a id='6.2'></a>\n## 7.2 BackTestPlot\n# print(\"==============Compare to DJIA===========\")",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "df_dji",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "df_dji = df_dji.set_index(df_dji.columns[0])\nprint(\"df_dji: \", df_dji)\ndf_dji.to_csv(\"df_dji+.csv\")\ndf_account_value.to_csv('df_account_value.csv')\n# <a id='6.2'></a>\n## 7.2 BackTestPlot\n# print(\"==============Compare to DJIA===========\")\n# %matplotlib inline\n# # S&P 500: ^GSPC\n# # Dow Jones Index: ^DJI",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "df_result_ensemble",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "df_result_ensemble = pd.DataFrame({'date': df_account_value['date'], 'ensemble': df_account_value['account_value']})\ndf_result_ensemble = df_result_ensemble.set_index('date')\nprint(\"df_result_ensemble.columns: \", df_result_ensemble.columns)\n# df_result_ensemble.drop(df_result_ensemble.columns[0], axis = 1)\nprint(\"df_trade_date: \", df_trade_date)\n# df_result_ensemble['date'] = df_trade_date['datadate']\n# df_result_ensemble['account_value'] = df_account_value['account_value']\ndf_result_ensemble.to_csv(\"df_result_ensemble.csv\")\nprint(\"df_result_ensemble: \", df_result_ensemble)\nprint(\"==============Compare to DJIA===========\")",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "df_result_ensemble",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "df_result_ensemble = df_result_ensemble.set_index('date')\nprint(\"df_result_ensemble.columns: \", df_result_ensemble.columns)\n# df_result_ensemble.drop(df_result_ensemble.columns[0], axis = 1)\nprint(\"df_trade_date: \", df_trade_date)\n# df_result_ensemble['date'] = df_trade_date['datadate']\n# df_result_ensemble['account_value'] = df_account_value['account_value']\ndf_result_ensemble.to_csv(\"df_result_ensemble.csv\")\nprint(\"df_result_ensemble: \", df_result_ensemble)\nprint(\"==============Compare to DJIA===========\")\nresult = pd.DataFrame()",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "result",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "result = pd.DataFrame()\n# result = pd.merge(result, df_result_ensemble, left_index=True, right_index=True)\n# result = pd.merge(result, df_dji, left_index=True, right_index=True)\nresult = pd.merge(df_result_ensemble, df_dji, left_index=True, right_index=True)\nprint(\"result: \", result)\nresult.to_csv(\"result.csv\")\nresult.columns = ['ensemble', 'dji']\n# %matplotlib inline\nplt.rcParams[\"figure.figsize\"] = (15,5)\nplt.figure();",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "result",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "result = pd.merge(df_result_ensemble, df_dji, left_index=True, right_index=True)\nprint(\"result: \", result)\nresult.to_csv(\"result.csv\")\nresult.columns = ['ensemble', 'dji']\n# %matplotlib inline\nplt.rcParams[\"figure.figsize\"] = (15,5)\nplt.figure();\nresult.plot();",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "result.columns",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "result.columns = ['ensemble', 'dji']\n# %matplotlib inline\nplt.rcParams[\"figure.figsize\"] = (15,5)\nplt.figure();\nresult.plot();",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "plt.rcParams[\"figure.figsize\"]",
        "kind": 5,
        "importPath": "examples.t3",
        "description": "examples.t3",
        "peekOfCode": "plt.rcParams[\"figure.figsize\"] = (15,5)\nplt.figure();\nresult.plot();",
        "detail": "examples.t3",
        "documentation": {}
    },
    {
        "label": "ActorPPO",
        "kind": 6,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "class ActorPPO(nn.Module):\n    def __init__(self, dims: [int], state_dim: int, action_dim: int):\n        super().__init__()\n        self.net = build_mlp(dims=[state_dim, *dims, action_dim])\n        self.action_std_log = nn.Parameter(torch.zeros((1, action_dim)), requires_grad=True)  # trainable parameter\n    def forward(self, state: Tensor) -> Tensor:\n        return self.net(state).tanh()  # action.tanh()\n    def get_action(self, state: Tensor) -> (Tensor, Tensor):  # for exploration\n        action_avg = self.net(state)\n        action_std = self.action_std_log.exp()",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "CriticPPO",
        "kind": 6,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "class CriticPPO(nn.Module):\n    def __init__(self, dims: [int], state_dim: int, _action_dim: int):\n        super().__init__()\n        self.net = build_mlp(dims=[state_dim, *dims, 1])\n    def forward(self, state: Tensor) -> Tensor:\n        return self.net(state)  # advantage value\ndef build_mlp(dims: [int]) -> nn.Sequential:  # MLP (MultiLayer Perceptron)\n    net_list = []\n    for i in range(len(dims) - 1):\n        net_list.extend([nn.Linear(dims[i], dims[i + 1]), nn.ReLU()])",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "Config",
        "kind": 6,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "class Config:\n    def __init__(self, agent_class=None, env_class=None, env_args=None):\n        self.env_class = env_class  # env = env_class(**env_args)\n        self.env_args = env_args  # env = env_class(**env_args)\n        if env_args is None:  # dummy env_args\n            env_args = {'env_name': None, 'state_dim': None, 'action_dim': None, 'if_discrete': None}\n        self.env_name = env_args['env_name']  # the name of environment. Be used to set 'cwd'.\n        self.state_dim = env_args['state_dim']  # vector dimension (feature number) of state\n        self.action_dim = env_args['action_dim']  # vector dimension (feature number) of action\n        self.if_discrete = env_args['if_discrete']  # discrete or continuous action space",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "AgentBase",
        "kind": 6,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "class AgentBase:\n    def __init__(self, net_dims: [int], state_dim: int, action_dim: int, gpu_id: int = 0, args: Config = Config()):\n        self.state_dim = state_dim\n        self.action_dim = action_dim\n        self.gamma = args.gamma\n        self.batch_size = args.batch_size\n        self.repeat_times = args.repeat_times\n        self.reward_scale = args.reward_scale\n        self.soft_update_tau = args.soft_update_tau\n        self.states = None  # assert self.states == (1, state_dim)",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "AgentPPO",
        "kind": 6,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "class AgentPPO(AgentBase):\n    def __init__(self, net_dims: [int], state_dim: int, action_dim: int, gpu_id: int = 0, args: Config = Config()):\n        self.if_off_policy = False\n        self.act_class = getattr(self, \"act_class\", ActorPPO)\n        self.cri_class = getattr(self, \"cri_class\", CriticPPO)\n        AgentBase.__init__(self, net_dims, state_dim, action_dim, gpu_id, args)\n        self.ratio_clip = getattr(args, \"ratio_clip\", 0.25)  # `ratio.clamp(1 - clip, 1 + clip)`\n        self.lambda_gae_adv = getattr(args, \"lambda_gae_adv\", 0.95)  # could be 0.80~0.99\n        self.lambda_entropy = getattr(args, \"lambda_entropy\", 0.01)  # could be 0.00~0.10\n        self.lambda_entropy = torch.tensor(self.lambda_entropy, dtype=torch.float32, device=self.device)",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "PendulumEnv",
        "kind": 6,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "class PendulumEnv(gym.Wrapper):  # a demo of custom gym env\n    def __init__(self):\n        gym.logger.set_level(40)  # Block warning\n        gym_env_name = \"Pendulum-v0\" if gym.__version__ < '0.18.0' else \"Pendulum-v1\"\n        super().__init__(env=gym.make(gym_env_name))\n        '''the necessary env information when you design a custom env'''\n        self.env_name = gym_env_name  # the name of this env.\n        self.state_dim = self.observation_space.shape[0]  # feature number of state\n        self.action_dim = self.action_space.shape[0]  # feature number of action\n        self.if_discrete = False  # discrete action or continuous action",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "Evaluator",
        "kind": 6,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "class Evaluator:\n    def __init__(self, eval_env, eval_per_step: int = 1e4, eval_times: int = 8, cwd: str = '.'):\n        self.cwd = cwd\n        self.env_eval = eval_env\n        self.eval_step = 0\n        self.total_step = 0\n        self.start_time = time.time()\n        self.eval_times = eval_times  # number of times that get episodic cumulative return\n        self.eval_per_step = eval_per_step  # evaluate the agent per training steps\n        self.recorder = []",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "kind": 6,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "class DRLAgent:\n    \"\"\"Implementations of DRL algorithms\n    Attributes\n    ----------\n        env: gym environment class\n            user-defined class\n    Methods\n    -------\n        get_model()\n            setup DRL algorithms",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "AlpacaPaperTrading",
        "kind": 6,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "class AlpacaPaperTrading():\n    def __init__(self,ticker_list, time_interval, drl_lib, agent, cwd, net_dim, \n                 state_dim, action_dim, API_KEY, API_SECRET, \n                 API_BASE_URL, tech_indicator_list, turbulence_thresh=30, \n                 max_stock=1e2, latency = None):\n        #load agent\n        self.drl_lib = drl_lib\n        if agent =='ppo':\n            if drl_lib == 'elegantrl':              \n                agent_class = AgentPPO",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "StockEnvEmpty",
        "kind": 6,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "class StockEnvEmpty(gym.Env):\n    #Empty Env used for loading rllib agent\n    def __init__(self,config):\n      state_dim = config['state_dim']\n      action_dim = config['action_dim']\n      self.env_num = 1\n      self.max_step = 10000\n      self.env_name = 'StockEnvEmpty'\n      self.state_dim = state_dim  \n      self.action_dim = action_dim",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "build_mlp",
        "kind": 2,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "def build_mlp(dims: [int]) -> nn.Sequential:  # MLP (MultiLayer Perceptron)\n    net_list = []\n    for i in range(len(dims) - 1):\n        net_list.extend([nn.Linear(dims[i], dims[i + 1]), nn.ReLU()])\n    del net_list[-1]  # remove the activation of output layer\n    return nn.Sequential(*net_list)\nclass Config:\n    def __init__(self, agent_class=None, env_class=None, env_args=None):\n        self.env_class = env_class  # env = env_class(**env_args)\n        self.env_args = env_args  # env = env_class(**env_args)",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "get_gym_env_args",
        "kind": 2,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "def get_gym_env_args(env, if_print: bool) -> dict:\n    if {'unwrapped', 'observation_space', 'action_space', 'spec'}.issubset(dir(env)):  # isinstance(env, gym.Env):\n        env_name = env.unwrapped.spec.id\n        state_shape = env.observation_space.shape\n        state_dim = state_shape[0] if len(state_shape) == 1 else state_shape  # sometimes state_dim is a list\n        if_discrete = isinstance(env.action_space, gym.spaces.Discrete)\n        if if_discrete:  # make sure it is discrete action space\n            action_dim = env.action_space.n\n        elif isinstance(env.action_space, gym.spaces.Box):  # make sure it is continuous action space\n            action_dim = env.action_space.shape[0]",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "kwargs_filter",
        "kind": 2,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "def kwargs_filter(function, kwargs: dict) -> dict:\n    import inspect\n    sign = inspect.signature(function).parameters.values()\n    sign = {val.name for val in sign}\n    common_args = sign.intersection(kwargs.keys())\n    return {key: kwargs[key] for key in common_args}  # filtered kwargs\ndef build_env(env_class=None, env_args=None):\n    if env_class.__module__ == 'gym.envs.registration':  # special rule\n        env = env_class(id=env_args['env_name'])\n    else:",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "build_env",
        "kind": 2,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "def build_env(env_class=None, env_args=None):\n    if env_class.__module__ == 'gym.envs.registration':  # special rule\n        env = env_class(id=env_args['env_name'])\n    else:\n        env = env_class(**kwargs_filter(env_class.__init__, env_args.copy()))\n    for attr_str in ('env_name', 'state_dim', 'action_dim', 'if_discrete'):\n        setattr(env, attr_str, env_args[attr_str])\n    return env\nclass AgentBase:\n    def __init__(self, net_dims: [int], state_dim: int, action_dim: int, gpu_id: int = 0, args: Config = Config()):",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "train_agent",
        "kind": 2,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "def train_agent(args: Config):\n    args.init_before_training()\n    env = build_env(args.env_class, args.env_args)\n    agent = args.agent_class(args.net_dims, args.state_dim, args.action_dim, gpu_id=args.gpu_id, args=args)\n    new_env, _ = env.reset()\n    agent.states = new_env[np.newaxis, :]\n    evaluator = Evaluator(eval_env=build_env(args.env_class, args.env_args),\n                          eval_per_step=args.eval_per_step,\n                          eval_times=args.eval_times,\n                          cwd=args.cwd)",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "render_agent",
        "kind": 2,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "def render_agent(env_class, env_args: dict, net_dims: [int], agent_class, actor_path: str, render_times: int = 8):\n    env = build_env(env_class, env_args)\n    state_dim = env_args['state_dim']\n    action_dim = env_args['action_dim']\n    agent = agent_class(net_dims, state_dim, action_dim, gpu_id=-1)\n    actor = agent.act\n    print(f\"| render and load actor from: {actor_path}\")\n    actor.load_state_dict(torch.load(actor_path, map_location=lambda storage, loc: storage))\n    for i in range(render_times):\n        cumulative_reward, episode_step = get_rewards_and_steps(env, actor, if_render=True)",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "get_rewards_and_steps",
        "kind": 2,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "def get_rewards_and_steps(env, actor, if_render: bool = False) -> (float, int):  # cumulative_rewards and episode_steps\n    device = next(actor.parameters()).device  # net.parameters() is a Python generator.\n    state, _ = env.reset()\n    episode_steps = 0\n    cumulative_returns = 0.0  # sum of rewards in an episode\n    for episode_steps in range(12345):\n        tensor_state = torch.as_tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n        tensor_action = actor(tensor_state)\n        action = tensor_action.detach().cpu().numpy()[0]  # not need detach(), because using torch.no_grad() outside\n        state, reward, done, _, _ = env.step(action)",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "def train(\n    start_date,\n    end_date,\n    ticker_list,\n    data_source,\n    time_interval,\n    technical_indicator_list,\n    drl_lib,\n    env,\n    model_name,",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 2,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "def test(\n    start_date,\n    end_date,\n    ticker_list,\n    data_source,\n    time_interval,\n    technical_indicator_list,\n    drl_lib,\n    env,\n    model_name,",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "get_trading_days",
        "kind": 2,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "def get_trading_days(start, end):\n    nyse = tc.get_calendar('NYSE')\n    df = nyse.sessions_in_range(pd.Timestamp(start),\n                                pd.Timestamp(end))\n    trading_days = []\n    for day in df:\n        trading_days.append(str(day)[:10])\n    return trading_days\ndef alpaca_history(key, secret, url, start, end):\n    api = tradeapi.REST(key, secret, url, 'v2')",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "alpaca_history",
        "kind": 2,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "def alpaca_history(key, secret, url, start, end):\n    api = tradeapi.REST(key, secret, url, 'v2')\n    trading_days = get_trading_days(start, end)\n    df = pd.DataFrame()\n    for day in trading_days:\n        df = pd.concat([df, api.get_portfolio_history(date_start = day,timeframe='5Min').df.iloc[:78]])\n    equities = df.equity.values\n    cumu_returns = equities/equities[0]\n    cumu_returns = cumu_returns[~np.isnan(cumu_returns)]\n    return df, cumu_returns",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "DIA_history",
        "kind": 2,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "def DIA_history(start):\n    data_df = yf.download(['^DJI'],start=start, interval=\"5m\")\n    data_df = data_df.iloc[:]\n    baseline_returns = data_df['Adj Close'].values/data_df['Adj Close'].values[0]\n    return data_df, baseline_returns\n# Get cumulative return\nAPI_KEY = \"\"\nAPI_SECRET = \"\"\nAPI_BASE_URL = 'https://paper-api.alpaca.markets'\ndata_url = 'wss://data.alpaca.markets'",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "API_KEY",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "API_KEY = \"PKA2OY3YK7Y4M6Q7LCLR\"\nAPI_SECRET = \"BxT64PIQtDBb*tnW\"\nAPI_BASE_URL = 'https://paper-api.alpaca.markets'\nfrom finrl.config_tickers import DOW_30_TICKER\nfrom finrl.config import INDICATORS\nfrom finrl.meta.env_stock_trading.env_stocktrading_np import StockTradingEnv\nfrom finrl.meta.env_stock_trading.env_stock_papertrading import AlpacaPaperTrading\nfrom finrl.meta.data_processor import DataProcessor\nfrom finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\nimport numpy as np",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "API_SECRET",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "API_SECRET = \"BxT64PIQtDBb*tnW\"\nAPI_BASE_URL = 'https://paper-api.alpaca.markets'\nfrom finrl.config_tickers import DOW_30_TICKER\nfrom finrl.config import INDICATORS\nfrom finrl.meta.env_stock_trading.env_stocktrading_np import StockTradingEnv\nfrom finrl.meta.env_stock_trading.env_stock_papertrading import AlpacaPaperTrading\nfrom finrl.meta.data_processor import DataProcessor\nfrom finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\nimport numpy as np\nimport pandas as pd",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "API_BASE_URL",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "API_BASE_URL = 'https://paper-api.alpaca.markets'\nfrom finrl.config_tickers import DOW_30_TICKER\nfrom finrl.config import INDICATORS\nfrom finrl.meta.env_stock_trading.env_stocktrading_np import StockTradingEnv\nfrom finrl.meta.env_stock_trading.env_stock_papertrading import AlpacaPaperTrading\nfrom finrl.meta.data_processor import DataProcessor\nfrom finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\nimport numpy as np\nimport pandas as pd\n# PPO",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "MODELS",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "MODELS = {\"ppo\": AgentPPO}\nOFF_POLICY_MODELS = [\"ddpg\", \"td3\", \"sac\"]\nON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "OFF_POLICY_MODELS",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "OFF_POLICY_MODELS = [\"ddpg\", \"td3\", \"sac\"]\nON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:\n    \"\"\"Implementations of DRL algorithms",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "ON_POLICY_MODELS",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "ON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:\n    \"\"\"Implementations of DRL algorithms\n    Attributes",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "ticker_list",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "ticker_list = DOW_30_TICKER\naction_dim = len(DOW_30_TICKER)\nprint(ticker_list)\nprint(INDICATORS)\n# Calculate the DRL state dimension manually for paper trading\n# amount + (turbulence, turbulence_bool) + (price, shares, cd (holding time)) * stock_dim + tech_dim\nstate_dim = 1 + 2 + 3 * action_dim + len(INDICATORS) * action_dim\nstate_dim\n# Get the API Keys Ready\n# API_KEY = \"\"",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "action_dim",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "action_dim = len(DOW_30_TICKER)\nprint(ticker_list)\nprint(INDICATORS)\n# Calculate the DRL state dimension manually for paper trading\n# amount + (turbulence, turbulence_bool) + (price, shares, cd (holding time)) * stock_dim + tech_dim\nstate_dim = 1 + 2 + 3 * action_dim + len(INDICATORS) * action_dim\nstate_dim\n# Get the API Keys Ready\n# API_KEY = \"\"\n# API_SECRET = \"\"",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "state_dim",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "state_dim = 1 + 2 + 3 * action_dim + len(INDICATORS) * action_dim\nstate_dim\n# Get the API Keys Ready\n# API_KEY = \"\"\n# API_SECRET = \"\"\nAPI_BASE_URL = 'https://paper-api.alpaca.markets'\ndata_url = 'wss://data.alpaca.markets'\nenv = StockTradingEnv\n# Show the data\n# Step 1. Pick a data source",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "API_BASE_URL",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "API_BASE_URL = 'https://paper-api.alpaca.markets'\ndata_url = 'wss://data.alpaca.markets'\nenv = StockTradingEnv\n# Show the data\n# Step 1. Pick a data source\n#DP = DataProcessor(data_source = 'alpaca',\n#                  API_KEY = API_KEY, \n#                  API_SECRET = API_SECRET, \n#                  API_BASE_URL = API_BASE_URL\n#                  )",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "data_url",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "data_url = 'wss://data.alpaca.markets'\nenv = StockTradingEnv\n# Show the data\n# Step 1. Pick a data source\n#DP = DataProcessor(data_source = 'alpaca',\n#                  API_KEY = API_KEY, \n#                  API_SECRET = API_SECRET, \n#                  API_BASE_URL = API_BASE_URL\n#                  )\n# Step 2. Get ticker list, Set start date and end date, specify the data frequency",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "env",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "env = StockTradingEnv\n# Show the data\n# Step 1. Pick a data source\n#DP = DataProcessor(data_source = 'alpaca',\n#                  API_KEY = API_KEY, \n#                  API_SECRET = API_SECRET, \n#                  API_BASE_URL = API_BASE_URL\n#                  )\n# Step 2. Get ticker list, Set start date and end date, specify the data frequency\n#data = DP.download_data(start_date = '2021-10-04', ",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "#DP",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "#DP = DataProcessor(data_source = 'alpaca',\n#                  API_KEY = API_KEY, \n#                  API_SECRET = API_SECRET, \n#                  API_BASE_URL = API_BASE_URL\n#                  )\n# Step 2. Get ticker list, Set start date and end date, specify the data frequency\n#data = DP.download_data(start_date = '2021-10-04', \n#                        end_date = '2021-10-08',\n#                        ticker_list = ticker_list, \n#                        time_interval= '1Min')",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "#data",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "#data = DP.download_data(start_date = '2021-10-04', \n#                        end_date = '2021-10-08',\n#                        ticker_list = ticker_list, \n#                        time_interval= '1Min')\n#data['timestamp'].nunique()\n# Step 3. Data Cleaning & Feature Engineering\n#data = DP.clean_data(data)\n#data = DP.add_technical_indicator(data, INDICATORS)\n#data = DP.add_vix(data)\n#data.shape",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "#data",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "#data = DP.clean_data(data)\n#data = DP.add_technical_indicator(data, INDICATORS)\n#data = DP.add_vix(data)\n#data.shape\n# Step 4. Transform to numpy array\n#price_array, tech_array, turbulence_array = DP.df_to_array(data, if_vix=True)\n# price_array\n# Part 2: Train the agent\n# Train\nERL_PARAMS = {\"learning_rate\": 3e-6,\"batch_size\": 2048,\"gamma\":  0.985,",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "#data",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "#data = DP.add_technical_indicator(data, INDICATORS)\n#data = DP.add_vix(data)\n#data.shape\n# Step 4. Transform to numpy array\n#price_array, tech_array, turbulence_array = DP.df_to_array(data, if_vix=True)\n# price_array\n# Part 2: Train the agent\n# Train\nERL_PARAMS = {\"learning_rate\": 3e-6,\"batch_size\": 2048,\"gamma\":  0.985,\n        \"seed\":312,\"net_dimension\":[128,64], \"target_step\":5000, \"eval_gap\":30,",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "#data",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "#data = DP.add_vix(data)\n#data.shape\n# Step 4. Transform to numpy array\n#price_array, tech_array, turbulence_array = DP.df_to_array(data, if_vix=True)\n# price_array\n# Part 2: Train the agent\n# Train\nERL_PARAMS = {\"learning_rate\": 3e-6,\"batch_size\": 2048,\"gamma\":  0.985,\n        \"seed\":312,\"net_dimension\":[128,64], \"target_step\":5000, \"eval_gap\":30,\n        \"eval_times\":1} ",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "ERL_PARAMS",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "ERL_PARAMS = {\"learning_rate\": 3e-6,\"batch_size\": 2048,\"gamma\":  0.985,\n        \"seed\":312,\"net_dimension\":[128,64], \"target_step\":5000, \"eval_gap\":30,\n        \"eval_times\":1} \nenv = StockTradingEnv\n#if you want to use larger datasets (change to longer period), and it raises error, \n#please try to increase \"target_step\". It should be larger than the episode steps. \ntrain(start_date = '2022-08-25', \n      end_date = '2022-08-31',\n      ticker_list = ticker_list, \n      data_source = 'alpaca',",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "env",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "env = StockTradingEnv\n#if you want to use larger datasets (change to longer period), and it raises error, \n#please try to increase \"target_step\". It should be larger than the episode steps. \ntrain(start_date = '2022-08-25', \n      end_date = '2022-08-31',\n      ticker_list = ticker_list, \n      data_source = 'alpaca',\n      time_interval= '1Min', \n      technical_indicator_list= INDICATORS,\n      drl_lib='elegantrl', ",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "train(start_date",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "train(start_date = '2022-08-25', \n      end_date = '2022-08-31',\n      ticker_list = ticker_list, \n      data_source = 'alpaca',\n      time_interval= '1Min', \n      technical_indicator_list= INDICATORS,\n      drl_lib='elegantrl', \n      env=env,\n      model_name='ppo',\n      if_vix=True, ",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "account_value_erl=test(start_date",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "account_value_erl=test(start_date = '2022-09-01', \n                      end_date = '2022-09-02',\n                      ticker_list = ticker_list, \n                      data_source = 'alpaca',\n                      time_interval= '1Min', \n                      technical_indicator_list= INDICATORS,\n                      drl_lib='elegantrl', \n                      env=env, \n                      model_name='ppo',\n                      if_vix=True, ",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "train(start_date",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "train(start_date = '2022-08-25', \n      end_date = '2022-09-02',\n      ticker_list = ticker_list, \n      data_source = 'alpaca',\n      time_interval= '1Min', \n      technical_indicator_list= INDICATORS,\n      drl_lib='elegantrl', \n      env=env, \n      model_name='ppo',\n      if_vix=True, ",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "paper_trading_erl",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "paper_trading_erl = AlpacaPaperTrading(ticker_list = DOW_30_TICKER, \n                                       time_interval = '1Min', \n                                       drl_lib = 'elegantrl', \n                                       agent = 'ppo', \n                                       cwd = './papertrading_erl_retrain', \n                                       net_dim = ERL_PARAMS['net_dimension'], \n                                       state_dim = state_dim, \n                                       action_dim= action_dim, \n                                       API_KEY = API_KEY, \n                                       API_SECRET = API_SECRET, ",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "API_KEY",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "API_KEY = \"\"\nAPI_SECRET = \"\"\nAPI_BASE_URL = 'https://paper-api.alpaca.markets'\ndata_url = 'wss://data.alpaca.markets'\ndf_erl, cumu_erl = alpaca_history(key=API_KEY, \n                                  secret=API_SECRET, \n                                  url=API_BASE_URL, \n                                  start='2022-09-01', #must be within 1 month\n                                  end='2022-09-12') #change the date if error occurs\ndf_djia, cumu_djia = DIA_history(start='2022-09-01')",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "API_SECRET",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "API_SECRET = \"\"\nAPI_BASE_URL = 'https://paper-api.alpaca.markets'\ndata_url = 'wss://data.alpaca.markets'\ndf_erl, cumu_erl = alpaca_history(key=API_KEY, \n                                  secret=API_SECRET, \n                                  url=API_BASE_URL, \n                                  start='2022-09-01', #must be within 1 month\n                                  end='2022-09-12') #change the date if error occurs\ndf_djia, cumu_djia = DIA_history(start='2022-09-01')\ndf_erl.tail()",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "API_BASE_URL",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "API_BASE_URL = 'https://paper-api.alpaca.markets'\ndata_url = 'wss://data.alpaca.markets'\ndf_erl, cumu_erl = alpaca_history(key=API_KEY, \n                                  secret=API_SECRET, \n                                  url=API_BASE_URL, \n                                  start='2022-09-01', #must be within 1 month\n                                  end='2022-09-12') #change the date if error occurs\ndf_djia, cumu_djia = DIA_history(start='2022-09-01')\ndf_erl.tail()\nreturns_erl = cumu_erl -1 ",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "data_url",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "data_url = 'wss://data.alpaca.markets'\ndf_erl, cumu_erl = alpaca_history(key=API_KEY, \n                                  secret=API_SECRET, \n                                  url=API_BASE_URL, \n                                  start='2022-09-01', #must be within 1 month\n                                  end='2022-09-12') #change the date if error occurs\ndf_djia, cumu_djia = DIA_history(start='2022-09-01')\ndf_erl.tail()\nreturns_erl = cumu_erl -1 \nreturns_dia = cumu_djia - 1",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "returns_erl",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "returns_erl = cumu_erl -1 \nreturns_dia = cumu_djia - 1\nreturns_dia = returns_dia[:returns_erl.shape[0]]\nprint('len of erl return: ', returns_erl.shape[0])\nprint('len of dia return: ', returns_dia.shape[0])\nreturns_erl\nplot and save\nimport matplotlib.pyplot as plt\nplt.figure(dpi=1000)\nplt.grid()",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "returns_dia",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "returns_dia = cumu_djia - 1\nreturns_dia = returns_dia[:returns_erl.shape[0]]\nprint('len of erl return: ', returns_erl.shape[0])\nprint('len of dia return: ', returns_dia.shape[0])\nreturns_erl\nplot and save\nimport matplotlib.pyplot as plt\nplt.figure(dpi=1000)\nplt.grid()\nplt.grid(which='minor', axis='y')",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "returns_dia",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "returns_dia = returns_dia[:returns_erl.shape[0]]\nprint('len of erl return: ', returns_erl.shape[0])\nprint('len of dia return: ', returns_dia.shape[0])\nreturns_erl\nplot and save\nimport matplotlib.pyplot as plt\nplt.figure(dpi=1000)\nplt.grid()\nplt.grid(which='minor', axis='y')\nplt.title('Stock Trading (Paper trading)', fontsize=20)",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "plt.xticks(size",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "plt.xticks(size = 14)\nplt.yticks(size = 14)\nax = plt.gca()\nax.xaxis.set_major_locator(ticker.MultipleLocator(78))\nax.xaxis.set_minor_locator(ticker.MultipleLocator(6))\nax.yaxis.set_minor_locator(ticker.MultipleLocator(0.005))\nax.yaxis.set_major_formatter(ticker.PercentFormatter(xmax=1, decimals=2))\nax.xaxis.set_major_formatter(ticker.FixedFormatter(['','10-19','','10-20',\n                                                    '','10-21','','10-22']))\nplt.legend(fontsize=10.5)",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "plt.yticks(size",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "plt.yticks(size = 14)\nax = plt.gca()\nax.xaxis.set_major_locator(ticker.MultipleLocator(78))\nax.xaxis.set_minor_locator(ticker.MultipleLocator(6))\nax.yaxis.set_minor_locator(ticker.MultipleLocator(0.005))\nax.yaxis.set_major_formatter(ticker.PercentFormatter(xmax=1, decimals=2))\nax.xaxis.set_major_formatter(ticker.FixedFormatter(['','10-19','','10-20',\n                                                    '','10-21','','10-22']))\nplt.legend(fontsize=10.5)\nplt.savefig('papertrading_stock.png')",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "ax",
        "kind": 5,
        "importPath": "examples.t4",
        "description": "examples.t4",
        "peekOfCode": "ax = plt.gca()\nax.xaxis.set_major_locator(ticker.MultipleLocator(78))\nax.xaxis.set_minor_locator(ticker.MultipleLocator(6))\nax.yaxis.set_minor_locator(ticker.MultipleLocator(0.005))\nax.yaxis.set_major_formatter(ticker.PercentFormatter(xmax=1, decimals=2))\nax.xaxis.set_major_formatter(ticker.FixedFormatter(['','10-19','','10-20',\n                                                    '','10-21','','10-22']))\nplt.legend(fontsize=10.5)\nplt.savefig('papertrading_stock.png')",
        "detail": "examples.t4",
        "documentation": {}
    },
    {
        "label": "DRLAgent",
        "kind": 6,
        "importPath": "examples.t5",
        "description": "examples.t5",
        "peekOfCode": "class DRLAgent:\n    \"\"\"Implementations of DRL algorithms\n    Attributes\n    ----------\n        env: gym environment class\n            user-defined class\n    Methods\n    -------\n        get_model()\n            setup DRL algorithms",
        "detail": "examples.t5",
        "documentation": {}
    },
    {
        "label": "API_KEY",
        "kind": 5,
        "importPath": "examples.t5",
        "description": "examples.t5",
        "peekOfCode": "API_KEY = \"PKA2OY3YK7Y4M6Q7LCLR\"\nAPI_SECRET = \"BxT64PIQtDBb*tnW\"\nAPI_BASE_URL = 'https://paper-api.alpaca.markets/v2'\nfrom finrl.config_tickers import DOW_30_TICKER\nfrom finrl.config import INDICATORS\nfrom finrl.meta.env_stock_trading.env_stocktrading_np import StockTradingEnv\nfrom finrl.meta.env_stock_trading.env_stock_papertrading import AlpacaPaperTrading\nfrom finrl.meta.data_processor import DataProcessor\nfrom finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n# from finrl.meta.preprocessor.yahoodownloader import YahooDownloader",
        "detail": "examples.t5",
        "documentation": {}
    },
    {
        "label": "API_SECRET",
        "kind": 5,
        "importPath": "examples.t5",
        "description": "examples.t5",
        "peekOfCode": "API_SECRET = \"BxT64PIQtDBb*tnW\"\nAPI_BASE_URL = 'https://paper-api.alpaca.markets/v2'\nfrom finrl.config_tickers import DOW_30_TICKER\nfrom finrl.config import INDICATORS\nfrom finrl.meta.env_stock_trading.env_stocktrading_np import StockTradingEnv\nfrom finrl.meta.env_stock_trading.env_stock_papertrading import AlpacaPaperTrading\nfrom finrl.meta.data_processor import DataProcessor\nfrom finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n# from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\nimport numpy as np",
        "detail": "examples.t5",
        "documentation": {}
    },
    {
        "label": "API_BASE_URL",
        "kind": 5,
        "importPath": "examples.t5",
        "description": "examples.t5",
        "peekOfCode": "API_BASE_URL = 'https://paper-api.alpaca.markets/v2'\nfrom finrl.config_tickers import DOW_30_TICKER\nfrom finrl.config import INDICATORS\nfrom finrl.meta.env_stock_trading.env_stocktrading_np import StockTradingEnv\nfrom finrl.meta.env_stock_trading.env_stock_papertrading import AlpacaPaperTrading\nfrom finrl.meta.data_processor import DataProcessor\nfrom finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n# from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\nimport numpy as np\nimport pandas as pd",
        "detail": "examples.t5",
        "documentation": {}
    },
    {
        "label": "MODELS",
        "kind": 5,
        "importPath": "examples.t5",
        "description": "examples.t5",
        "peekOfCode": "MODELS = {\"ppo\": AgentPPO}\nOFF_POLICY_MODELS = [\"ddpg\", \"td3\", \"sac\"]\nON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:",
        "detail": "examples.t5",
        "documentation": {}
    },
    {
        "label": "OFF_POLICY_MODELS",
        "kind": 5,
        "importPath": "examples.t5",
        "description": "examples.t5",
        "peekOfCode": "OFF_POLICY_MODELS = [\"ddpg\", \"td3\", \"sac\"]\nON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:\n    \"\"\"Implementations of DRL algorithms",
        "detail": "examples.t5",
        "documentation": {}
    },
    {
        "label": "ON_POLICY_MODELS",
        "kind": 5,
        "importPath": "examples.t5",
        "description": "examples.t5",
        "peekOfCode": "ON_POLICY_MODELS = [\"ppo\"]\n# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n#\n# NOISE = {\n#     \"normal\": NormalActionNoise,\n#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n# }\nclass DRLAgent:\n    \"\"\"Implementations of DRL algorithms\n    Attributes",
        "detail": "examples.t5",
        "documentation": {}
    },
    {
        "label": "predict_with_models",
        "kind": 2,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "def predict_with_models(models, environment):\n    \"\"\"\n    Perform predictions using multiple trained models in the specified environment.\n    Parameters:\n    - models: A dictionary of trained models with names as keys.\n    - environment: The trading environment to be used for predictions.\n    Returns:\n    - results: A dictionary containing DataFrames of account values and actions for each model.\n    \"\"\"\n    results = {}",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "train_agent",
        "kind": 2,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "def train_agent(agent, model_name = \"a2c\", total_timesteps=50000):\n    \"\"\"\n    Train a model with the provided agent and model_name and total_timesteps \n    \"\"\"\n    # Get the model for A2C if applicable\n    __cached__model_ = agent.get_model(model_name)\n    # Set up logger\n    _tmp_path = RESULTS_DIR + '/' + model_name\n    _new_logger = configure(_tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n    # Set the new logger",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "MaximizeReturns",
        "kind": 2,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "def MaximizeReturns(MeanReturns, PortfolioSize):\n  #dependencies\n  c = (np.multiply(-1, MeanReturns))\n  A = np.ones([PortfolioSize,1]).T\n  b=[1]\n  res = linprog(c, A_ub = A, b_ub = b, bounds = (0,1), method = 'simplex') \n  return res\ndef MinimizeRisk(CovarReturns, PortfolioSize):\n  def f(x, CovarReturns):\n    func = np.matmul(np.matmul(x, CovarReturns), x.T) ",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "MinimizeRisk",
        "kind": 2,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "def MinimizeRisk(CovarReturns, PortfolioSize):\n  def f(x, CovarReturns):\n    func = np.matmul(np.matmul(x, CovarReturns), x.T) \n    return func\n  def constraintEq(x):\n    A=np.ones(x.shape)\n    b=1\n    constraintVal = np.matmul(A,x.T)-b \n    return constraintVal\n  xinit=np.repeat(0.1, PortfolioSize)",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "MinimizeRiskConstr",
        "kind": 2,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "def MinimizeRiskConstr(MeanReturns, CovarReturns, PortfolioSize, R):\n  def  f(x,CovarReturns):\n    func = np.matmul(np.matmul(x,CovarReturns ), x.T)\n    return func\n  def constraintEq(x):\n    AEq=np.ones(x.shape)\n    bEq=1\n    EqconstraintVal = np.matmul(AEq,x.T)-bEq \n    return EqconstraintVal\n  def constraintIneq(x, MeanReturns, R):",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "StockReturnsComputing",
        "kind": 2,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "def StockReturnsComputing(StockPrice, Rows, Columns): \n  import numpy as np \n  StockReturn = np.zeros([Rows-1, Columns]) \n  for j in range(Columns):        # j: Assets \n    for i in range(Rows-1):     # i: Daily Prices \n      StockReturn[i,j]=((StockPrice[i+1, j]-StockPrice[i,j])/StockPrice[i,j])* 100 \n  return StockReturn\n# Obtain optimal portfolio sets that maximize return and minimize risk\n#Dependencies\nimport numpy as np",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "API_KEY",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "API_KEY = \"PKA2OY3YK7Y4M6Q7LCLR\"\nAPI_SECRET = \"BxT64PIQtDBb*tnW\"\nAPI_BASE_URL = 'https://paper-api.alpaca.markets'\n# %matplotlib inline\nfrom finrl.meta.preprocessor.yahoodownloader import YahooDownloader\nfrom finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\nfrom finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\nfrom finrl.agents.stablebaselines3.models import DRLAgent\nfrom stable_baselines3.common.logger import configure\nfrom finrl.meta.data_processor import DataProcessor",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "API_SECRET",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "API_SECRET = \"BxT64PIQtDBb*tnW\"\nAPI_BASE_URL = 'https://paper-api.alpaca.markets'\n# %matplotlib inline\nfrom finrl.meta.preprocessor.yahoodownloader import YahooDownloader\nfrom finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\nfrom finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\nfrom finrl.agents.stablebaselines3.models import DRLAgent\nfrom stable_baselines3.common.logger import configure\nfrom finrl.meta.data_processor import DataProcessor\nfrom finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "API_BASE_URL",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "API_BASE_URL = 'https://paper-api.alpaca.markets'\n# %matplotlib inline\nfrom finrl.meta.preprocessor.yahoodownloader import YahooDownloader\nfrom finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\nfrom finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\nfrom finrl.agents.stablebaselines3.models import DRLAgent\nfrom stable_baselines3.common.logger import configure\nfrom finrl.meta.data_processor import DataProcessor\nfrom finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\nfrom pprint import pprint",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "TRAIN_START_DATE = '2010-01-01'\nTRAIN_END_DATE = '2021-10-01'\nTRADE_START_DATE = '2021-10-01'\nTRADE_END_DATE = '2023-03-01'\n# from config.py, TRADE_END_DATE is a string  \n\"\"\" Yahoo donloader for data collection \"\"\"\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TRADE_END_DATE,\n                     ticker_list = config_tickers.DOW_30_TICKER).fetch_data()\n# print(config_tickers.DOW_30_TICKER)",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "TRAIN_END_DATE = '2021-10-01'\nTRADE_START_DATE = '2021-10-01'\nTRADE_END_DATE = '2023-03-01'\n# from config.py, TRADE_END_DATE is a string  \n\"\"\" Yahoo donloader for data collection \"\"\"\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TRADE_END_DATE,\n                     ticker_list = config_tickers.DOW_30_TICKER).fetch_data()\n# print(config_tickers.DOW_30_TICKER)\ndf.shape",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "TRADE_START_DATE",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "TRADE_START_DATE = '2021-10-01'\nTRADE_END_DATE = '2023-03-01'\n# from config.py, TRADE_END_DATE is a string  \n\"\"\" Yahoo donloader for data collection \"\"\"\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TRADE_END_DATE,\n                     ticker_list = config_tickers.DOW_30_TICKER).fetch_data()\n# print(config_tickers.DOW_30_TICKER)\ndf.shape\ndf.sort_values(['date','tic'],ignore_index=True).head()",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "TRADE_END_DATE",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "TRADE_END_DATE = '2023-03-01'\n# from config.py, TRADE_END_DATE is a string  \n\"\"\" Yahoo donloader for data collection \"\"\"\ndf = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TRADE_END_DATE,\n                     ticker_list = config_tickers.DOW_30_TICKER).fetch_data()\n# print(config_tickers.DOW_30_TICKER)\ndf.shape\ndf.sort_values(['date','tic'],ignore_index=True).head()\nfe = FeatureEngineer(",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "df = YahooDownloader(start_date = TRAIN_START_DATE,\n                     end_date = TRADE_END_DATE,\n                     ticker_list = config_tickers.DOW_30_TICKER).fetch_data()\n# print(config_tickers.DOW_30_TICKER)\ndf.shape\ndf.sort_values(['date','tic'],ignore_index=True).head()\nfe = FeatureEngineer(\n                    use_technical_indicator=True,\n                    tech_indicator_list = INDICATORS,\n                    use_vix=True,",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "fe",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "fe = FeatureEngineer(\n                    use_technical_indicator=True,\n                    tech_indicator_list = INDICATORS,\n                    use_vix=True,\n                    use_turbulence=True,\n                    user_defined_feature = False)\nprocessed = fe.preprocess_data(df)\nlist_ticker = processed[\"tic\"].unique().tolist()\n# print(list_ticker)\nlist_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "processed",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "processed = fe.preprocess_data(df)\nlist_ticker = processed[\"tic\"].unique().tolist()\n# print(list_ticker)\nlist_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\ncombination = list(itertools.product(list_date,list_ticker))\n# print(combination)\nprocessed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\nprocessed_full = processed_full[processed_full['date'].isin(processed['date'])]\nprocessed_full = processed_full.sort_values(['date','tic'])\nprocessed_full = processed_full.fillna(0)",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "list_ticker",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "list_ticker = processed[\"tic\"].unique().tolist()\n# print(list_ticker)\nlist_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\ncombination = list(itertools.product(list_date,list_ticker))\n# print(combination)\nprocessed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\nprocessed_full = processed_full[processed_full['date'].isin(processed['date'])]\nprocessed_full = processed_full.sort_values(['date','tic'])\nprocessed_full = processed_full.fillna(0)\n# print(processed_full.sort_values(['date','tic'],ignore_index=True).head(10))",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "list_date",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\ncombination = list(itertools.product(list_date,list_ticker))\n# print(combination)\nprocessed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\nprocessed_full = processed_full[processed_full['date'].isin(processed['date'])]\nprocessed_full = processed_full.sort_values(['date','tic'])\nprocessed_full = processed_full.fillna(0)\n# print(processed_full.sort_values(['date','tic'],ignore_index=True).head(10))\ntrain = data_split(processed_full, TRAIN_START_DATE,TRAIN_END_DATE)\ntrade = data_split(processed_full, TRADE_START_DATE,TRADE_END_DATE)",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "combination",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "combination = list(itertools.product(list_date,list_ticker))\n# print(combination)\nprocessed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\nprocessed_full = processed_full[processed_full['date'].isin(processed['date'])]\nprocessed_full = processed_full.sort_values(['date','tic'])\nprocessed_full = processed_full.fillna(0)\n# print(processed_full.sort_values(['date','tic'],ignore_index=True).head(10))\ntrain = data_split(processed_full, TRAIN_START_DATE,TRAIN_END_DATE)\ntrade = data_split(processed_full, TRADE_START_DATE,TRADE_END_DATE)\nprint(len(train))",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "processed_full",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\nprocessed_full = processed_full[processed_full['date'].isin(processed['date'])]\nprocessed_full = processed_full.sort_values(['date','tic'])\nprocessed_full = processed_full.fillna(0)\n# print(processed_full.sort_values(['date','tic'],ignore_index=True).head(10))\ntrain = data_split(processed_full, TRAIN_START_DATE,TRAIN_END_DATE)\ntrade = data_split(processed_full, TRADE_START_DATE,TRADE_END_DATE)\nprint(len(train))\nprint(len(trade))\nprint(train.head())",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "processed_full",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\nprocessed_full = processed_full.sort_values(['date','tic'])\nprocessed_full = processed_full.fillna(0)\n# print(processed_full.sort_values(['date','tic'],ignore_index=True).head(10))\ntrain = data_split(processed_full, TRAIN_START_DATE,TRAIN_END_DATE)\ntrade = data_split(processed_full, TRADE_START_DATE,TRADE_END_DATE)\nprint(len(train))\nprint(len(trade))\nprint(train.head())\nprint(train.tail())",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "processed_full",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "processed_full = processed_full.sort_values(['date','tic'])\nprocessed_full = processed_full.fillna(0)\n# print(processed_full.sort_values(['date','tic'],ignore_index=True).head(10))\ntrain = data_split(processed_full, TRAIN_START_DATE,TRAIN_END_DATE)\ntrade = data_split(processed_full, TRADE_START_DATE,TRADE_END_DATE)\nprint(len(train))\nprint(len(trade))\nprint(train.head())\nprint(train.tail())\nmvo_df = processed_full.sort_values(['date','tic'],ignore_index=True)[['date','tic','close']]",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "processed_full",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "processed_full = processed_full.fillna(0)\n# print(processed_full.sort_values(['date','tic'],ignore_index=True).head(10))\ntrain = data_split(processed_full, TRAIN_START_DATE,TRAIN_END_DATE)\ntrade = data_split(processed_full, TRADE_START_DATE,TRADE_END_DATE)\nprint(len(train))\nprint(len(trade))\nprint(train.head())\nprint(train.tail())\nmvo_df = processed_full.sort_values(['date','tic'],ignore_index=True)[['date','tic','close']]\nstock_dimension = len(train.tic.unique())",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "train = data_split(processed_full, TRAIN_START_DATE,TRAIN_END_DATE)\ntrade = data_split(processed_full, TRADE_START_DATE,TRADE_END_DATE)\nprint(len(train))\nprint(len(trade))\nprint(train.head())\nprint(train.tail())\nmvo_df = processed_full.sort_values(['date','tic'],ignore_index=True)[['date','tic','close']]\nstock_dimension = len(train.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "trade",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "trade = data_split(processed_full, TRADE_START_DATE,TRADE_END_DATE)\nprint(len(train))\nprint(len(trade))\nprint(train.head())\nprint(train.tail())\nmvo_df = processed_full.sort_values(['date','tic'],ignore_index=True)[['date','tic','close']]\nstock_dimension = len(train.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nbuy_cost_list = sell_cost_list = [0.001] * stock_dimension",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "mvo_df",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "mvo_df = processed_full.sort_values(['date','tic'],ignore_index=True)[['date','tic','close']]\nstock_dimension = len(train.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nbuy_cost_list = sell_cost_list = [0.001] * stock_dimension\nnum_stock_shares = [0] * stock_dimension\nenv_kwargs = {\n    \"hmax\": 100,\n    \"initial_amount\": 1000000,\n    \"num_stock_shares\": num_stock_shares,",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "stock_dimension",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "stock_dimension = len(train.tic.unique())\nstate_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nbuy_cost_list = sell_cost_list = [0.001] * stock_dimension\nnum_stock_shares = [0] * stock_dimension\nenv_kwargs = {\n    \"hmax\": 100,\n    \"initial_amount\": 1000000,\n    \"num_stock_shares\": num_stock_shares,\n    \"buy_cost_pct\": buy_cost_list,",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "state_space",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\nprint(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\nbuy_cost_list = sell_cost_list = [0.001] * stock_dimension\nnum_stock_shares = [0] * stock_dimension\nenv_kwargs = {\n    \"hmax\": 100,\n    \"initial_amount\": 1000000,\n    \"num_stock_shares\": num_stock_shares,\n    \"buy_cost_pct\": buy_cost_list,\n    \"sell_cost_pct\": sell_cost_list,",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "buy_cost_list",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\nnum_stock_shares = [0] * stock_dimension\nenv_kwargs = {\n    \"hmax\": 100,\n    \"initial_amount\": 1000000,\n    \"num_stock_shares\": num_stock_shares,\n    \"buy_cost_pct\": buy_cost_list,\n    \"sell_cost_pct\": sell_cost_list,\n    \"state_space\": state_space,\n    \"stock_dim\": stock_dimension,",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "num_stock_shares",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "num_stock_shares = [0] * stock_dimension\nenv_kwargs = {\n    \"hmax\": 100,\n    \"initial_amount\": 1000000,\n    \"num_stock_shares\": num_stock_shares,\n    \"buy_cost_pct\": buy_cost_list,\n    \"sell_cost_pct\": sell_cost_list,\n    \"state_space\": state_space,\n    \"stock_dim\": stock_dimension,\n    \"tech_indicator_list\": INDICATORS,",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "env_kwargs",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "env_kwargs = {\n    \"hmax\": 100,\n    \"initial_amount\": 1000000,\n    \"num_stock_shares\": num_stock_shares,\n    \"buy_cost_pct\": buy_cost_list,\n    \"sell_cost_pct\": sell_cost_list,\n    \"state_space\": state_space,\n    \"stock_dim\": stock_dimension,\n    \"tech_indicator_list\": INDICATORS,\n    \"action_space\": stock_dimension,",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "e_train_gym",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "e_train_gym = StockTradingEnv(df = train, **env_kwargs)\nenv_train, _ = e_train_gym.get_sb_env()\nprint(type(env_train))\nagent = DRLAgent(env = env_train)\nif_using_a2c = True\nif_using_ddpg = True\nif_using_ppo = True\nif_using_td3 = True\nif_using_sac = True\ndef predict_with_models(models, environment):",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "agent",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "agent = DRLAgent(env = env_train)\nif_using_a2c = True\nif_using_ddpg = True\nif_using_ppo = True\nif_using_td3 = True\nif_using_sac = True\ndef predict_with_models(models, environment):\n    \"\"\"\n    Perform predictions using multiple trained models in the specified environment.\n    Parameters:",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "if_using_a2c",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "if_using_a2c = True\nif_using_ddpg = True\nif_using_ppo = True\nif_using_td3 = True\nif_using_sac = True\ndef predict_with_models(models, environment):\n    \"\"\"\n    Perform predictions using multiple trained models in the specified environment.\n    Parameters:\n    - models: A dictionary of trained models with names as keys.",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "if_using_ddpg",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "if_using_ddpg = True\nif_using_ppo = True\nif_using_td3 = True\nif_using_sac = True\ndef predict_with_models(models, environment):\n    \"\"\"\n    Perform predictions using multiple trained models in the specified environment.\n    Parameters:\n    - models: A dictionary of trained models with names as keys.\n    - environment: The trading environment to be used for predictions.",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "if_using_ppo",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "if_using_ppo = True\nif_using_td3 = True\nif_using_sac = True\ndef predict_with_models(models, environment):\n    \"\"\"\n    Perform predictions using multiple trained models in the specified environment.\n    Parameters:\n    - models: A dictionary of trained models with names as keys.\n    - environment: The trading environment to be used for predictions.\n    Returns:",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "if_using_td3",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "if_using_td3 = True\nif_using_sac = True\ndef predict_with_models(models, environment):\n    \"\"\"\n    Perform predictions using multiple trained models in the specified environment.\n    Parameters:\n    - models: A dictionary of trained models with names as keys.\n    - environment: The trading environment to be used for predictions.\n    Returns:\n    - results: A dictionary containing DataFrames of account values and actions for each model.",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "if_using_sac",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "if_using_sac = True\ndef predict_with_models(models, environment):\n    \"\"\"\n    Perform predictions using multiple trained models in the specified environment.\n    Parameters:\n    - models: A dictionary of trained models with names as keys.\n    - environment: The trading environment to be used for predictions.\n    Returns:\n    - results: A dictionary containing DataFrames of account values and actions for each model.\n    \"\"\"",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "trained_a2c",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "trained_a2c = train_agent(agent, \"a2c\", 5) if if_using_a2c else None\ntrained_ddpg = train_agent(agent, \"ddpg\", 5) if if_using_ddpg else None\ntrained_ppo = train_agent(agent, \"ppo\", 5) if if_using_ppo else None  \ntrained_td3 = train_agent(agent, \"td3\", 5) if if_using_td3 else None\ntrained_sac = train_agent(agent, \"sac\", 5) if if_using_sac else None\ndata_risk_indicator = processed_full[(processed_full.date<TRAIN_END_DATE) & (processed_full.date>=TRAIN_START_DATE)]\ninsample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])\n# print(insample_risk_indicator)\nprint(insample_risk_indicator.vix.quantile(0.996))\n# print(insample_risk_indicator.vix.describe())",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "trained_ddpg",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "trained_ddpg = train_agent(agent, \"ddpg\", 5) if if_using_ddpg else None\ntrained_ppo = train_agent(agent, \"ppo\", 5) if if_using_ppo else None  \ntrained_td3 = train_agent(agent, \"td3\", 5) if if_using_td3 else None\ntrained_sac = train_agent(agent, \"sac\", 5) if if_using_sac else None\ndata_risk_indicator = processed_full[(processed_full.date<TRAIN_END_DATE) & (processed_full.date>=TRAIN_START_DATE)]\ninsample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])\n# print(insample_risk_indicator)\nprint(insample_risk_indicator.vix.quantile(0.996))\n# print(insample_risk_indicator.vix.describe())\nprint(insample_risk_indicator.vix.describe())",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "trained_ppo",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "trained_ppo = train_agent(agent, \"ppo\", 5) if if_using_ppo else None  \ntrained_td3 = train_agent(agent, \"td3\", 5) if if_using_td3 else None\ntrained_sac = train_agent(agent, \"sac\", 5) if if_using_sac else None\ndata_risk_indicator = processed_full[(processed_full.date<TRAIN_END_DATE) & (processed_full.date>=TRAIN_START_DATE)]\ninsample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])\n# print(insample_risk_indicator)\nprint(insample_risk_indicator.vix.quantile(0.996))\n# print(insample_risk_indicator.vix.describe())\nprint(insample_risk_indicator.vix.describe())\nprint(insample_risk_indicator.turbulence.describe())",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "trained_td3",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "trained_td3 = train_agent(agent, \"td3\", 5) if if_using_td3 else None\ntrained_sac = train_agent(agent, \"sac\", 5) if if_using_sac else None\ndata_risk_indicator = processed_full[(processed_full.date<TRAIN_END_DATE) & (processed_full.date>=TRAIN_START_DATE)]\ninsample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])\n# print(insample_risk_indicator)\nprint(insample_risk_indicator.vix.quantile(0.996))\n# print(insample_risk_indicator.vix.describe())\nprint(insample_risk_indicator.vix.describe())\nprint(insample_risk_indicator.turbulence.describe())\nprint(insample_risk_indicator.turbulence.quantile(0.996))",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "trained_sac",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "trained_sac = train_agent(agent, \"sac\", 5) if if_using_sac else None\ndata_risk_indicator = processed_full[(processed_full.date<TRAIN_END_DATE) & (processed_full.date>=TRAIN_START_DATE)]\ninsample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])\n# print(insample_risk_indicator)\nprint(insample_risk_indicator.vix.quantile(0.996))\n# print(insample_risk_indicator.vix.describe())\nprint(insample_risk_indicator.vix.describe())\nprint(insample_risk_indicator.turbulence.describe())\nprint(insample_risk_indicator.turbulence.quantile(0.996))\ne_trade_gym = StockTradingEnv(df = trade, turbulence_threshold =70,  risk_indicator_col='vix', **env_kwargs)",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "data_risk_indicator",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "data_risk_indicator = processed_full[(processed_full.date<TRAIN_END_DATE) & (processed_full.date>=TRAIN_START_DATE)]\ninsample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])\n# print(insample_risk_indicator)\nprint(insample_risk_indicator.vix.quantile(0.996))\n# print(insample_risk_indicator.vix.describe())\nprint(insample_risk_indicator.vix.describe())\nprint(insample_risk_indicator.turbulence.describe())\nprint(insample_risk_indicator.turbulence.quantile(0.996))\ne_trade_gym = StockTradingEnv(df = trade, turbulence_threshold =70,  risk_indicator_col='vix', **env_kwargs)\n# env_trade, obs_trade = e_trade_gym.get_sb_env()",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "insample_risk_indicator",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "insample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])\n# print(insample_risk_indicator)\nprint(insample_risk_indicator.vix.quantile(0.996))\n# print(insample_risk_indicator.vix.describe())\nprint(insample_risk_indicator.vix.describe())\nprint(insample_risk_indicator.turbulence.describe())\nprint(insample_risk_indicator.turbulence.quantile(0.996))\ne_trade_gym = StockTradingEnv(df = trade, turbulence_threshold =70,  risk_indicator_col='vix', **env_kwargs)\n# env_trade, obs_trade = e_trade_gym.get_sb_env()\nprint(trade.head())",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "e_trade_gym",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold =70,  risk_indicator_col='vix', **env_kwargs)\n# env_trade, obs_trade = e_trade_gym.get_sb_env()\nprint(trade.head())\nprint(trade.tail())\n# Example usage:\nmodels = {\n    \"a2c\": trained_a2c,\n    \"ddpg\": trained_ddpg,\n    \"ppo\": trained_ppo,\n    \"td3\": trained_td3,",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "models",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "models = {\n    \"a2c\": trained_a2c,\n    \"ddpg\": trained_ddpg,\n    \"ppo\": trained_ppo,\n    \"td3\": trained_td3,\n    \"sac\": trained_sac\n}\nresults = predict_with_models(models, e_trade_gym)\n# Access results for each model\ndf_account_value_a2c = results[\"a2c\"][\"account_value\"]",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "results",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "results = predict_with_models(models, e_trade_gym)\n# Access results for each model\ndf_account_value_a2c = results[\"a2c\"][\"account_value\"]\ndf_actions_a2c = results[\"a2c\"][\"actions\"]\ndf_account_value_ddpg = results[\"ddpg\"][\"account_value\"]\ndf_actions_ddpg = results[\"ddpg\"][\"actions\"]\ndf_account_value_ppo = results[\"ppo\"][\"account_value\"]\ndf_actions_ppo = results[\"ppo\"][\"actions\"]\ndf_account_value_td3 = results[\"td3\"][\"account_value\"]\ndf_actions_td3 = results[\"td3\"][\"actions\"]",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "df_account_value_a2c",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "df_account_value_a2c = results[\"a2c\"][\"account_value\"]\ndf_actions_a2c = results[\"a2c\"][\"actions\"]\ndf_account_value_ddpg = results[\"ddpg\"][\"account_value\"]\ndf_actions_ddpg = results[\"ddpg\"][\"actions\"]\ndf_account_value_ppo = results[\"ppo\"][\"account_value\"]\ndf_actions_ppo = results[\"ppo\"][\"actions\"]\ndf_account_value_td3 = results[\"td3\"][\"account_value\"]\ndf_actions_td3 = results[\"td3\"][\"actions\"]\ndf_account_value_sac = results[\"sac\"][\"account_value\"]\ndf_actions_sac = results[\"sac\"][\"actions\"]",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "df_actions_a2c",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "df_actions_a2c = results[\"a2c\"][\"actions\"]\ndf_account_value_ddpg = results[\"ddpg\"][\"account_value\"]\ndf_actions_ddpg = results[\"ddpg\"][\"actions\"]\ndf_account_value_ppo = results[\"ppo\"][\"account_value\"]\ndf_actions_ppo = results[\"ppo\"][\"actions\"]\ndf_account_value_td3 = results[\"td3\"][\"account_value\"]\ndf_actions_td3 = results[\"td3\"][\"actions\"]\ndf_account_value_sac = results[\"sac\"][\"account_value\"]\ndf_actions_sac = results[\"sac\"][\"actions\"]\ndf_account_value_a2c.shape",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "df_account_value_ddpg",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "df_account_value_ddpg = results[\"ddpg\"][\"account_value\"]\ndf_actions_ddpg = results[\"ddpg\"][\"actions\"]\ndf_account_value_ppo = results[\"ppo\"][\"account_value\"]\ndf_actions_ppo = results[\"ppo\"][\"actions\"]\ndf_account_value_td3 = results[\"td3\"][\"account_value\"]\ndf_actions_td3 = results[\"td3\"][\"actions\"]\ndf_account_value_sac = results[\"sac\"][\"account_value\"]\ndf_actions_sac = results[\"sac\"][\"actions\"]\ndf_account_value_a2c.shape\nprint(df_account_value_a2c.shape)",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "df_actions_ddpg",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "df_actions_ddpg = results[\"ddpg\"][\"actions\"]\ndf_account_value_ppo = results[\"ppo\"][\"account_value\"]\ndf_actions_ppo = results[\"ppo\"][\"actions\"]\ndf_account_value_td3 = results[\"td3\"][\"account_value\"]\ndf_actions_td3 = results[\"td3\"][\"actions\"]\ndf_account_value_sac = results[\"sac\"][\"account_value\"]\ndf_actions_sac = results[\"sac\"][\"actions\"]\ndf_account_value_a2c.shape\nprint(df_account_value_a2c.shape)\nprint(df_account_value_a2c.head())",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "df_account_value_ppo",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "df_account_value_ppo = results[\"ppo\"][\"account_value\"]\ndf_actions_ppo = results[\"ppo\"][\"actions\"]\ndf_account_value_td3 = results[\"td3\"][\"account_value\"]\ndf_actions_td3 = results[\"td3\"][\"actions\"]\ndf_account_value_sac = results[\"sac\"][\"account_value\"]\ndf_actions_sac = results[\"sac\"][\"actions\"]\ndf_account_value_a2c.shape\nprint(df_account_value_a2c.shape)\nprint(df_account_value_a2c.head())\nprint(df_account_value_a2c.tail())",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "df_actions_ppo",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "df_actions_ppo = results[\"ppo\"][\"actions\"]\ndf_account_value_td3 = results[\"td3\"][\"account_value\"]\ndf_actions_td3 = results[\"td3\"][\"actions\"]\ndf_account_value_sac = results[\"sac\"][\"account_value\"]\ndf_actions_sac = results[\"sac\"][\"actions\"]\ndf_account_value_a2c.shape\nprint(df_account_value_a2c.shape)\nprint(df_account_value_a2c.head())\nprint(df_account_value_a2c.tail())\nprint(mvo_df.head)",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "df_account_value_td3",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "df_account_value_td3 = results[\"td3\"][\"account_value\"]\ndf_actions_td3 = results[\"td3\"][\"actions\"]\ndf_account_value_sac = results[\"sac\"][\"account_value\"]\ndf_actions_sac = results[\"sac\"][\"actions\"]\ndf_account_value_a2c.shape\nprint(df_account_value_a2c.shape)\nprint(df_account_value_a2c.head())\nprint(df_account_value_a2c.tail())\nprint(mvo_df.head)\nfst = mvo_df",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "df_actions_td3",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "df_actions_td3 = results[\"td3\"][\"actions\"]\ndf_account_value_sac = results[\"sac\"][\"account_value\"]\ndf_actions_sac = results[\"sac\"][\"actions\"]\ndf_account_value_a2c.shape\nprint(df_account_value_a2c.shape)\nprint(df_account_value_a2c.head())\nprint(df_account_value_a2c.tail())\nprint(mvo_df.head)\nfst = mvo_df\nfst = fst.iloc[0*29:0*29+29, :]",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "df_account_value_sac",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "df_account_value_sac = results[\"sac\"][\"account_value\"]\ndf_actions_sac = results[\"sac\"][\"actions\"]\ndf_account_value_a2c.shape\nprint(df_account_value_a2c.shape)\nprint(df_account_value_a2c.head())\nprint(df_account_value_a2c.tail())\nprint(mvo_df.head)\nfst = mvo_df\nfst = fst.iloc[0*29:0*29+29, :]\ntic = fst['tic'].tolist()",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "df_actions_sac",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "df_actions_sac = results[\"sac\"][\"actions\"]\ndf_account_value_a2c.shape\nprint(df_account_value_a2c.shape)\nprint(df_account_value_a2c.head())\nprint(df_account_value_a2c.tail())\nprint(mvo_df.head)\nfst = mvo_df\nfst = fst.iloc[0*29:0*29+29, :]\ntic = fst['tic'].tolist()\nmvo = pd.DataFrame()",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "fst",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "fst = mvo_df\nfst = fst.iloc[0*29:0*29+29, :]\ntic = fst['tic'].tolist()\nmvo = pd.DataFrame()\nfor k in range(len(tic)):\n  mvo[tic[k]] = 0\nfor i in range(mvo_df.shape[0]//29):\n  n = mvo_df\n  n = n.iloc[i*29:i*29+29, :]\n  date = n['date'][i*29]",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "fst",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "fst = fst.iloc[0*29:0*29+29, :]\ntic = fst['tic'].tolist()\nmvo = pd.DataFrame()\nfor k in range(len(tic)):\n  mvo[tic[k]] = 0\nfor i in range(mvo_df.shape[0]//29):\n  n = mvo_df\n  n = n.iloc[i*29:i*29+29, :]\n  date = n['date'][i*29]\n  mvo.loc[date] = n['close'].tolist()",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "tic",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "tic = fst['tic'].tolist()\nmvo = pd.DataFrame()\nfor k in range(len(tic)):\n  mvo[tic[k]] = 0\nfor i in range(mvo_df.shape[0]//29):\n  n = mvo_df\n  n = n.iloc[i*29:i*29+29, :]\n  date = n['date'][i*29]\n  mvo.loc[date] = n['close'].tolist()\nmvo.shape[0]  ",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "mvo",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "mvo = pd.DataFrame()\nfor k in range(len(tic)):\n  mvo[tic[k]] = 0\nfor i in range(mvo_df.shape[0]//29):\n  n = mvo_df\n  n = n.iloc[i*29:i*29+29, :]\n  date = n['date'][i*29]\n  mvo.loc[date] = n['close'].tolist()\nmvo.shape[0]  \nfrom scipy import optimize ",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "Rows",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "Rows = 1259  #excluding header\nColumns = 15  #excluding date\nportfolioSize = 29 #set portfolio size\n#read stock prices in a dataframe\n# df = pd.read_csv(StockFileName,  nrows= Rows)\n#extract asset labels\n# assetLabels = df.columns[1:Columns+1].tolist()\n# print(assetLabels)\n#extract asset prices\n# StockData = df.iloc[0:, 1:]",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "Columns",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "Columns = 15  #excluding date\nportfolioSize = 29 #set portfolio size\n#read stock prices in a dataframe\n# df = pd.read_csv(StockFileName,  nrows= Rows)\n#extract asset labels\n# assetLabels = df.columns[1:Columns+1].tolist()\n# print(assetLabels)\n#extract asset prices\n# StockData = df.iloc[0:, 1:]\nStockData = mvo.head(mvo.shape[0]-336)",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "portfolioSize",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "portfolioSize = 29 #set portfolio size\n#read stock prices in a dataframe\n# df = pd.read_csv(StockFileName,  nrows= Rows)\n#extract asset labels\n# assetLabels = df.columns[1:Columns+1].tolist()\n# print(assetLabels)\n#extract asset prices\n# StockData = df.iloc[0:, 1:]\nStockData = mvo.head(mvo.shape[0]-336)\nprint(StockData)",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "StockData",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "StockData = mvo.head(mvo.shape[0]-336)\nprint(StockData)\nTradeData = mvo.tail(336)\n# df.head()\nTradeData.to_numpy()\n#compute asset returns\narStockPrices = np.asarray(StockData)\n[Rows, Cols]=arStockPrices.shape\narReturns = StockReturnsComputing(arStockPrices, Rows, Cols)\n#compute mean returns and variance covariance matrix of returns",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "TradeData",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "TradeData = mvo.tail(336)\n# df.head()\nTradeData.to_numpy()\n#compute asset returns\narStockPrices = np.asarray(StockData)\n[Rows, Cols]=arStockPrices.shape\narReturns = StockReturnsComputing(arStockPrices, Rows, Cols)\n#compute mean returns and variance covariance matrix of returns\nmeanReturns = np.mean(arReturns, axis = 0)\ncovReturns = np.cov(arReturns, rowvar=False)",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "arStockPrices",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "arStockPrices = np.asarray(StockData)\n[Rows, Cols]=arStockPrices.shape\narReturns = StockReturnsComputing(arStockPrices, Rows, Cols)\n#compute mean returns and variance covariance matrix of returns\nmeanReturns = np.mean(arReturns, axis = 0)\ncovReturns = np.cov(arReturns, rowvar=False)\n#set precision for printing results\nnp.set_printoptions(precision=3, suppress = True)\n#display mean returns and variance-covariance matrix of returns\nprint('Mean returns of assets in k-portfolio 1\\n', meanReturns)",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "arReturns",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "arReturns = StockReturnsComputing(arStockPrices, Rows, Cols)\n#compute mean returns and variance covariance matrix of returns\nmeanReturns = np.mean(arReturns, axis = 0)\ncovReturns = np.cov(arReturns, rowvar=False)\n#set precision for printing results\nnp.set_printoptions(precision=3, suppress = True)\n#display mean returns and variance-covariance matrix of returns\nprint('Mean returns of assets in k-portfolio 1\\n', meanReturns)\nprint('Variance-Covariance matrix of returns\\n', covReturns)\nfrom pypfopt.efficient_frontier import EfficientFrontier",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "meanReturns",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "meanReturns = np.mean(arReturns, axis = 0)\ncovReturns = np.cov(arReturns, rowvar=False)\n#set precision for printing results\nnp.set_printoptions(precision=3, suppress = True)\n#display mean returns and variance-covariance matrix of returns\nprint('Mean returns of assets in k-portfolio 1\\n', meanReturns)\nprint('Variance-Covariance matrix of returns\\n', covReturns)\nfrom pypfopt.efficient_frontier import EfficientFrontier\nef_mean = EfficientFrontier(meanReturns, covReturns, weight_bounds=(0, 0.5))\nraw_weights_mean = ef_mean.max_sharpe()",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "covReturns",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "covReturns = np.cov(arReturns, rowvar=False)\n#set precision for printing results\nnp.set_printoptions(precision=3, suppress = True)\n#display mean returns and variance-covariance matrix of returns\nprint('Mean returns of assets in k-portfolio 1\\n', meanReturns)\nprint('Variance-Covariance matrix of returns\\n', covReturns)\nfrom pypfopt.efficient_frontier import EfficientFrontier\nef_mean = EfficientFrontier(meanReturns, covReturns, weight_bounds=(0, 0.5))\nraw_weights_mean = ef_mean.max_sharpe()\ncleaned_weights_mean = ef_mean.clean_weights()",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "ef_mean",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "ef_mean = EfficientFrontier(meanReturns, covReturns, weight_bounds=(0, 0.5))\nraw_weights_mean = ef_mean.max_sharpe()\ncleaned_weights_mean = ef_mean.clean_weights()\nmvo_weights = np.array([1000000 * cleaned_weights_mean[i] for i in range(29)])\nprint(mvo_weights)\nStockData.tail(1)\nPortfolio_Assets = TradeData # Initial_Portfolio\nMVO_result = pd.DataFrame(Portfolio_Assets, columns=[\"Mean Var\"])\nMVO_result\ndf_result_a2c = df_account_value_a2c.set_index(df_account_value_a2c.columns[0])",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "raw_weights_mean",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "raw_weights_mean = ef_mean.max_sharpe()\ncleaned_weights_mean = ef_mean.clean_weights()\nmvo_weights = np.array([1000000 * cleaned_weights_mean[i] for i in range(29)])\nprint(mvo_weights)\nStockData.tail(1)\nPortfolio_Assets = TradeData # Initial_Portfolio\nMVO_result = pd.DataFrame(Portfolio_Assets, columns=[\"Mean Var\"])\nMVO_result\ndf_result_a2c = df_account_value_a2c.set_index(df_account_value_a2c.columns[0])\ndf_result_ddpg = df_account_value_ddpg.set_index(df_account_value_ddpg.columns[0])",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "cleaned_weights_mean",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "cleaned_weights_mean = ef_mean.clean_weights()\nmvo_weights = np.array([1000000 * cleaned_weights_mean[i] for i in range(29)])\nprint(mvo_weights)\nStockData.tail(1)\nPortfolio_Assets = TradeData # Initial_Portfolio\nMVO_result = pd.DataFrame(Portfolio_Assets, columns=[\"Mean Var\"])\nMVO_result\ndf_result_a2c = df_account_value_a2c.set_index(df_account_value_a2c.columns[0])\ndf_result_ddpg = df_account_value_ddpg.set_index(df_account_value_ddpg.columns[0])\ndf_result_td3 = df_account_value_td3.set_index(df_account_value_td3.columns[0])",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "mvo_weights",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "mvo_weights = np.array([1000000 * cleaned_weights_mean[i] for i in range(29)])\nprint(mvo_weights)\nStockData.tail(1)\nPortfolio_Assets = TradeData # Initial_Portfolio\nMVO_result = pd.DataFrame(Portfolio_Assets, columns=[\"Mean Var\"])\nMVO_result\ndf_result_a2c = df_account_value_a2c.set_index(df_account_value_a2c.columns[0])\ndf_result_ddpg = df_account_value_ddpg.set_index(df_account_value_ddpg.columns[0])\ndf_result_td3 = df_account_value_td3.set_index(df_account_value_td3.columns[0])\ndf_result_ppo = df_account_value_ppo.set_index(df_account_value_ppo.columns[0])",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "Portfolio_Assets",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "Portfolio_Assets = TradeData # Initial_Portfolio\nMVO_result = pd.DataFrame(Portfolio_Assets, columns=[\"Mean Var\"])\nMVO_result\ndf_result_a2c = df_account_value_a2c.set_index(df_account_value_a2c.columns[0])\ndf_result_ddpg = df_account_value_ddpg.set_index(df_account_value_ddpg.columns[0])\ndf_result_td3 = df_account_value_td3.set_index(df_account_value_td3.columns[0])\ndf_result_ppo = df_account_value_ppo.set_index(df_account_value_ppo.columns[0])\ndf_result_sac = df_account_value_sac.set_index(df_account_value_sac.columns[0])\ndf_account_value_a2c.to_csv(\"df_account_value_a2c.csv\")\n#baseline stats",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "MVO_result",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "MVO_result = pd.DataFrame(Portfolio_Assets, columns=[\"Mean Var\"])\nMVO_result\ndf_result_a2c = df_account_value_a2c.set_index(df_account_value_a2c.columns[0])\ndf_result_ddpg = df_account_value_ddpg.set_index(df_account_value_ddpg.columns[0])\ndf_result_td3 = df_account_value_td3.set_index(df_account_value_td3.columns[0])\ndf_result_ppo = df_account_value_ppo.set_index(df_account_value_ppo.columns[0])\ndf_result_sac = df_account_value_sac.set_index(df_account_value_sac.columns[0])\ndf_account_value_a2c.to_csv(\"df_account_value_a2c.csv\")\n#baseline stats\nprint(\"==============Get Baseline Stats===========\")",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "df_result_a2c",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "df_result_a2c = df_account_value_a2c.set_index(df_account_value_a2c.columns[0])\ndf_result_ddpg = df_account_value_ddpg.set_index(df_account_value_ddpg.columns[0])\ndf_result_td3 = df_account_value_td3.set_index(df_account_value_td3.columns[0])\ndf_result_ppo = df_account_value_ppo.set_index(df_account_value_ppo.columns[0])\ndf_result_sac = df_account_value_sac.set_index(df_account_value_sac.columns[0])\ndf_account_value_a2c.to_csv(\"df_account_value_a2c.csv\")\n#baseline stats\nprint(\"==============Get Baseline Stats===========\")\ndf_dji_ = get_baseline(\n        ticker=\"^DJI\", ",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "df_result_ddpg",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "df_result_ddpg = df_account_value_ddpg.set_index(df_account_value_ddpg.columns[0])\ndf_result_td3 = df_account_value_td3.set_index(df_account_value_td3.columns[0])\ndf_result_ppo = df_account_value_ppo.set_index(df_account_value_ppo.columns[0])\ndf_result_sac = df_account_value_sac.set_index(df_account_value_sac.columns[0])\ndf_account_value_a2c.to_csv(\"df_account_value_a2c.csv\")\n#baseline stats\nprint(\"==============Get Baseline Stats===========\")\ndf_dji_ = get_baseline(\n        ticker=\"^DJI\", \n        start = TRADE_START_DATE,",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "df_result_td3",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "df_result_td3 = df_account_value_td3.set_index(df_account_value_td3.columns[0])\ndf_result_ppo = df_account_value_ppo.set_index(df_account_value_ppo.columns[0])\ndf_result_sac = df_account_value_sac.set_index(df_account_value_sac.columns[0])\ndf_account_value_a2c.to_csv(\"df_account_value_a2c.csv\")\n#baseline stats\nprint(\"==============Get Baseline Stats===========\")\ndf_dji_ = get_baseline(\n        ticker=\"^DJI\", \n        start = TRADE_START_DATE,\n        end = TRADE_END_DATE)",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "df_result_ppo",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "df_result_ppo = df_account_value_ppo.set_index(df_account_value_ppo.columns[0])\ndf_result_sac = df_account_value_sac.set_index(df_account_value_sac.columns[0])\ndf_account_value_a2c.to_csv(\"df_account_value_a2c.csv\")\n#baseline stats\nprint(\"==============Get Baseline Stats===========\")\ndf_dji_ = get_baseline(\n        ticker=\"^DJI\", \n        start = TRADE_START_DATE,\n        end = TRADE_END_DATE)\nstats = backtest_stats(df_dji_, value_col_name = 'close')",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "df_result_sac",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "df_result_sac = df_account_value_sac.set_index(df_account_value_sac.columns[0])\ndf_account_value_a2c.to_csv(\"df_account_value_a2c.csv\")\n#baseline stats\nprint(\"==============Get Baseline Stats===========\")\ndf_dji_ = get_baseline(\n        ticker=\"^DJI\", \n        start = TRADE_START_DATE,\n        end = TRADE_END_DATE)\nstats = backtest_stats(df_dji_, value_col_name = 'close')\ndf_dji = pd.DataFrame()",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "df_dji_",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "df_dji_ = get_baseline(\n        ticker=\"^DJI\", \n        start = TRADE_START_DATE,\n        end = TRADE_END_DATE)\nstats = backtest_stats(df_dji_, value_col_name = 'close')\ndf_dji = pd.DataFrame()\ndf_dji['date'] = df_account_value_a2c['date']\ndf_dji['account_value'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\ndf_dji.to_csv(\"df_dji.csv\")\ndf_dji = df_dji.set_index(df_dji.columns[0])",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "stats",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "stats = backtest_stats(df_dji_, value_col_name = 'close')\ndf_dji = pd.DataFrame()\ndf_dji['date'] = df_account_value_a2c['date']\ndf_dji['account_value'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\ndf_dji.to_csv(\"df_dji.csv\")\ndf_dji = df_dji.set_index(df_dji.columns[0])\ndf_dji.to_csv(\"df_dji+.csv\")\nresult = pd.merge(df_result_a2c, df_result_ddpg, left_index=True, right_index=True, suffixes=('_a2c', '_ddpg'))\nresult = pd.merge(result, df_result_td3, left_index=True, right_index=True, suffixes=('', '_td3'))\nresult = pd.merge(result, df_result_ppo, left_index=True, right_index=True, suffixes=('', '_ppo'))",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "df_dji",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "df_dji = pd.DataFrame()\ndf_dji['date'] = df_account_value_a2c['date']\ndf_dji['account_value'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\ndf_dji.to_csv(\"df_dji.csv\")\ndf_dji = df_dji.set_index(df_dji.columns[0])\ndf_dji.to_csv(\"df_dji+.csv\")\nresult = pd.merge(df_result_a2c, df_result_ddpg, left_index=True, right_index=True, suffixes=('_a2c', '_ddpg'))\nresult = pd.merge(result, df_result_td3, left_index=True, right_index=True, suffixes=('', '_td3'))\nresult = pd.merge(result, df_result_ppo, left_index=True, right_index=True, suffixes=('', '_ppo'))\nresult = pd.merge(result, df_result_sac, left_index=True, right_index=True, suffixes=('', '_sac'))",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "df_dji['date']",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "df_dji['date'] = df_account_value_a2c['date']\ndf_dji['account_value'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\ndf_dji.to_csv(\"df_dji.csv\")\ndf_dji = df_dji.set_index(df_dji.columns[0])\ndf_dji.to_csv(\"df_dji+.csv\")\nresult = pd.merge(df_result_a2c, df_result_ddpg, left_index=True, right_index=True, suffixes=('_a2c', '_ddpg'))\nresult = pd.merge(result, df_result_td3, left_index=True, right_index=True, suffixes=('', '_td3'))\nresult = pd.merge(result, df_result_ppo, left_index=True, right_index=True, suffixes=('', '_ppo'))\nresult = pd.merge(result, df_result_sac, left_index=True, right_index=True, suffixes=('', '_sac'))\nresult = pd.merge(result, MVO_result, left_index=True, right_index=True, suffixes=('', '_mvo'))",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "df_dji['account_value']",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "df_dji['account_value'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\ndf_dji.to_csv(\"df_dji.csv\")\ndf_dji = df_dji.set_index(df_dji.columns[0])\ndf_dji.to_csv(\"df_dji+.csv\")\nresult = pd.merge(df_result_a2c, df_result_ddpg, left_index=True, right_index=True, suffixes=('_a2c', '_ddpg'))\nresult = pd.merge(result, df_result_td3, left_index=True, right_index=True, suffixes=('', '_td3'))\nresult = pd.merge(result, df_result_ppo, left_index=True, right_index=True, suffixes=('', '_ppo'))\nresult = pd.merge(result, df_result_sac, left_index=True, right_index=True, suffixes=('', '_sac'))\nresult = pd.merge(result, MVO_result, left_index=True, right_index=True, suffixes=('', '_mvo'))\nresult = pd.merge(result, df_dji, left_index=True, right_index=True, suffixes=('', '_dji'))",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "df_dji",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "df_dji = df_dji.set_index(df_dji.columns[0])\ndf_dji.to_csv(\"df_dji+.csv\")\nresult = pd.merge(df_result_a2c, df_result_ddpg, left_index=True, right_index=True, suffixes=('_a2c', '_ddpg'))\nresult = pd.merge(result, df_result_td3, left_index=True, right_index=True, suffixes=('', '_td3'))\nresult = pd.merge(result, df_result_ppo, left_index=True, right_index=True, suffixes=('', '_ppo'))\nresult = pd.merge(result, df_result_sac, left_index=True, right_index=True, suffixes=('', '_sac'))\nresult = pd.merge(result, MVO_result, left_index=True, right_index=True, suffixes=('', '_mvo'))\nresult = pd.merge(result, df_dji, left_index=True, right_index=True, suffixes=('', '_dji'))\nresult.columns = ['a2c', 'ddpg', 'td3', 'ppo', 'sac', 'mean var', 'dji']\nprint(\"result: \", result)",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "result",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "result = pd.merge(df_result_a2c, df_result_ddpg, left_index=True, right_index=True, suffixes=('_a2c', '_ddpg'))\nresult = pd.merge(result, df_result_td3, left_index=True, right_index=True, suffixes=('', '_td3'))\nresult = pd.merge(result, df_result_ppo, left_index=True, right_index=True, suffixes=('', '_ppo'))\nresult = pd.merge(result, df_result_sac, left_index=True, right_index=True, suffixes=('', '_sac'))\nresult = pd.merge(result, MVO_result, left_index=True, right_index=True, suffixes=('', '_mvo'))\nresult = pd.merge(result, df_dji, left_index=True, right_index=True, suffixes=('', '_dji'))\nresult.columns = ['a2c', 'ddpg', 'td3', 'ppo', 'sac', 'mean var', 'dji']\nprint(\"result: \", result)\nresult.to_csv(\"result.csv\")\n# %matplotlib inline",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "result",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "result = pd.merge(result, df_result_td3, left_index=True, right_index=True, suffixes=('', '_td3'))\nresult = pd.merge(result, df_result_ppo, left_index=True, right_index=True, suffixes=('', '_ppo'))\nresult = pd.merge(result, df_result_sac, left_index=True, right_index=True, suffixes=('', '_sac'))\nresult = pd.merge(result, MVO_result, left_index=True, right_index=True, suffixes=('', '_mvo'))\nresult = pd.merge(result, df_dji, left_index=True, right_index=True, suffixes=('', '_dji'))\nresult.columns = ['a2c', 'ddpg', 'td3', 'ppo', 'sac', 'mean var', 'dji']\nprint(\"result: \", result)\nresult.to_csv(\"result.csv\")\n# %matplotlib inline\nplt.rcParams[\"figure.figsize\"] = (15,5)",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "result",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "result = pd.merge(result, df_result_ppo, left_index=True, right_index=True, suffixes=('', '_ppo'))\nresult = pd.merge(result, df_result_sac, left_index=True, right_index=True, suffixes=('', '_sac'))\nresult = pd.merge(result, MVO_result, left_index=True, right_index=True, suffixes=('', '_mvo'))\nresult = pd.merge(result, df_dji, left_index=True, right_index=True, suffixes=('', '_dji'))\nresult.columns = ['a2c', 'ddpg', 'td3', 'ppo', 'sac', 'mean var', 'dji']\nprint(\"result: \", result)\nresult.to_csv(\"result.csv\")\n# %matplotlib inline\nplt.rcParams[\"figure.figsize\"] = (15,5)\nplt.figure();",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "result",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "result = pd.merge(result, df_result_sac, left_index=True, right_index=True, suffixes=('', '_sac'))\nresult = pd.merge(result, MVO_result, left_index=True, right_index=True, suffixes=('', '_mvo'))\nresult = pd.merge(result, df_dji, left_index=True, right_index=True, suffixes=('', '_dji'))\nresult.columns = ['a2c', 'ddpg', 'td3', 'ppo', 'sac', 'mean var', 'dji']\nprint(\"result: \", result)\nresult.to_csv(\"result.csv\")\n# %matplotlib inline\nplt.rcParams[\"figure.figsize\"] = (15,5)\nplt.figure();\nresult.plot();",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "result",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "result = pd.merge(result, MVO_result, left_index=True, right_index=True, suffixes=('', '_mvo'))\nresult = pd.merge(result, df_dji, left_index=True, right_index=True, suffixes=('', '_dji'))\nresult.columns = ['a2c', 'ddpg', 'td3', 'ppo', 'sac', 'mean var', 'dji']\nprint(\"result: \", result)\nresult.to_csv(\"result.csv\")\n# %matplotlib inline\nplt.rcParams[\"figure.figsize\"] = (15,5)\nplt.figure();\nresult.plot();",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "result",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "result = pd.merge(result, df_dji, left_index=True, right_index=True, suffixes=('', '_dji'))\nresult.columns = ['a2c', 'ddpg', 'td3', 'ppo', 'sac', 'mean var', 'dji']\nprint(\"result: \", result)\nresult.to_csv(\"result.csv\")\n# %matplotlib inline\nplt.rcParams[\"figure.figsize\"] = (15,5)\nplt.figure();\nresult.plot();",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "result.columns",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "result.columns = ['a2c', 'ddpg', 'td3', 'ppo', 'sac', 'mean var', 'dji']\nprint(\"result: \", result)\nresult.to_csv(\"result.csv\")\n# %matplotlib inline\nplt.rcParams[\"figure.figsize\"] = (15,5)\nplt.figure();\nresult.plot();",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "plt.rcParams[\"figure.figsize\"]",
        "kind": 5,
        "importPath": "examples.t6",
        "description": "examples.t6",
        "peekOfCode": "plt.rcParams[\"figure.figsize\"] = (15,5)\nplt.figure();\nresult.plot();",
        "detail": "examples.t6",
        "documentation": {}
    },
    {
        "label": "process_ticker_data",
        "kind": 2,
        "importPath": "examples.t7",
        "description": "examples.t7",
        "peekOfCode": "def process_ticker_data(ticker):\n    print(f\"Processing data for ticker: {ticker}\")\n    df_raw = SinopacDownloader(\n        start_date=TRAIN_START_DATE, end_date=TRADE_END_DATE, ticker_list=[ticker]\n    ).fetch_data()\n    df_raw.rename(\n        columns={\n            \"open\": \"Open\",\n            \"high\": \"High\",\n            \"low\": \"Low\",",
        "detail": "examples.t7",
        "documentation": {}
    },
    {
        "label": "TAI_0050_TICKER",
        "kind": 5,
        "importPath": "examples.t7",
        "description": "examples.t7",
        "peekOfCode": "TAI_0050_TICKER = [\n    \"3008\",  # Largan Precision Co., Ltd.\n    \"1303\",  # Nan Ya Plastics Corporation\n    \"2412\",  # Chunghwa Telecom Co., Ltd.\n    \"1301\",  # Formosa Plastics Corporation\n    \"1216\",  # Uni-President Enterprises Corporation\n    \"2881\",  # Fubon Financial Holding Co., Ltd.\n    \"2882\",  # Cathay Financial Holding Co., Ltd.\n    \"5871\",  # China Development Financial Holding Corporation\n    \"2886\",  # Mega Financial Holding Co., Ltd.",
        "detail": "examples.t7",
        "documentation": {}
    },
    {
        "label": "TRAIN_START_DATE",
        "kind": 5,
        "importPath": "examples.t7",
        "description": "examples.t7",
        "peekOfCode": "TRAIN_START_DATE = \"2023-04-13\"\nTRAIN_END_DATE = \"2024-04-13\"\nTRADE_START_DATE = \"2024-04-13\"\nTRADE_END_DATE = \"2024-07-31\"\ndef process_ticker_data(ticker):\n    print(f\"Processing data for ticker: {ticker}\")\n    df_raw = SinopacDownloader(\n        start_date=TRAIN_START_DATE, end_date=TRADE_END_DATE, ticker_list=[ticker]\n    ).fetch_data()\n    df_raw.rename(",
        "detail": "examples.t7",
        "documentation": {}
    },
    {
        "label": "TRAIN_END_DATE",
        "kind": 5,
        "importPath": "examples.t7",
        "description": "examples.t7",
        "peekOfCode": "TRAIN_END_DATE = \"2024-04-13\"\nTRADE_START_DATE = \"2024-04-13\"\nTRADE_END_DATE = \"2024-07-31\"\ndef process_ticker_data(ticker):\n    print(f\"Processing data for ticker: {ticker}\")\n    df_raw = SinopacDownloader(\n        start_date=TRAIN_START_DATE, end_date=TRADE_END_DATE, ticker_list=[ticker]\n    ).fetch_data()\n    df_raw.rename(\n        columns={",
        "detail": "examples.t7",
        "documentation": {}
    },
    {
        "label": "TRADE_START_DATE",
        "kind": 5,
        "importPath": "examples.t7",
        "description": "examples.t7",
        "peekOfCode": "TRADE_START_DATE = \"2024-04-13\"\nTRADE_END_DATE = \"2024-07-31\"\ndef process_ticker_data(ticker):\n    print(f\"Processing data for ticker: {ticker}\")\n    df_raw = SinopacDownloader(\n        start_date=TRAIN_START_DATE, end_date=TRADE_END_DATE, ticker_list=[ticker]\n    ).fetch_data()\n    df_raw.rename(\n        columns={\n            \"open\": \"Open\",",
        "detail": "examples.t7",
        "documentation": {}
    },
    {
        "label": "TRADE_END_DATE",
        "kind": 5,
        "importPath": "examples.t7",
        "description": "examples.t7",
        "peekOfCode": "TRADE_END_DATE = \"2024-07-31\"\ndef process_ticker_data(ticker):\n    print(f\"Processing data for ticker: {ticker}\")\n    df_raw = SinopacDownloader(\n        start_date=TRAIN_START_DATE, end_date=TRADE_END_DATE, ticker_list=[ticker]\n    ).fetch_data()\n    df_raw.rename(\n        columns={\n            \"open\": \"Open\",\n            \"high\": \"High\",",
        "detail": "examples.t7",
        "documentation": {}
    },
    {
        "label": "df_final",
        "kind": 5,
        "importPath": "examples.t7",
        "description": "examples.t7",
        "peekOfCode": "df_final = pd.DataFrame()\nfor ticker in TAI_0050_TICKER:\n    process_ticker_data(ticker)\n    # Load processed data from file and concatenate\n    df_ticker = pd.read_csv(f\"data_{ticker}.csv\")\n    df_final = pd.concat([df_final, df_ticker], ignore_index=True)\n    del df_ticker  # free up memory\n    gc.collect()\ntrain = data_split(df_final, TRAIN_START_DATE, TRAIN_END_DATE)\ntrade = data_split(df_final, TRADE_START_DATE, TRADE_END_DATE)",
        "detail": "examples.t7",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 5,
        "importPath": "examples.t7",
        "description": "examples.t7",
        "peekOfCode": "train = data_split(df_final, TRAIN_START_DATE, TRAIN_END_DATE)\ntrade = data_split(df_final, TRADE_START_DATE, TRADE_END_DATE)\ntrain.to_csv(\"train_data.csv\")\ntrade.to_csv(\"trade_data.csv\")",
        "detail": "examples.t7",
        "documentation": {}
    },
    {
        "label": "trade",
        "kind": 5,
        "importPath": "examples.t7",
        "description": "examples.t7",
        "peekOfCode": "trade = data_split(df_final, TRADE_START_DATE, TRADE_END_DATE)\ntrain.to_csv(\"train_data.csv\")\ntrade.to_csv(\"trade_data.csv\")",
        "detail": "examples.t7",
        "documentation": {}
    },
    {
        "label": "ticker_list",
        "kind": 2,
        "importPath": "unit_tests.downloaders.test_alpaca_downloader",
        "description": "unit_tests.downloaders.test_alpaca_downloader",
        "peekOfCode": "def ticker_list():\n    return [\"AAPL\", \"GOOG\"]\ndef test_intraDayBar_download(ticker_list):\n    # Given\n    start_date = \"2021-07-29\"\n    end_date = \"2021-07-30\"\n    time_interval = \"1H\"\n    ticker_list = [\"AAPL\", \"GOOG\"]\n    # When\n    DP = AlpacaProcessor(",
        "detail": "unit_tests.downloaders.test_alpaca_downloader",
        "documentation": {}
    },
    {
        "label": "test_intraDayBar_download",
        "kind": 2,
        "importPath": "unit_tests.downloaders.test_alpaca_downloader",
        "description": "unit_tests.downloaders.test_alpaca_downloader",
        "peekOfCode": "def test_intraDayBar_download(ticker_list):\n    # Given\n    start_date = \"2021-07-29\"\n    end_date = \"2021-07-30\"\n    time_interval = \"1H\"\n    ticker_list = [\"AAPL\", \"GOOG\"]\n    # When\n    DP = AlpacaProcessor(\n        API_KEY=API_KEY, API_SECRET=API_SECRET, API_BASE_URL=API_BASE_URL\n    )",
        "detail": "unit_tests.downloaders.test_alpaca_downloader",
        "documentation": {}
    },
    {
        "label": "test_dayBar_download",
        "kind": 2,
        "importPath": "unit_tests.downloaders.test_alpaca_downloader",
        "description": "unit_tests.downloaders.test_alpaca_downloader",
        "peekOfCode": "def test_dayBar_download(ticker_list):\n    # Given\n    start_date = \"2021-07-29\"\n    end_date = \"2021-07-30\"\n    time_interval = \"1D\"\n    ticker_list = [\"AAPL\", \"GOOG\"]\n    # When\n    DP = AlpacaProcessor(\n        API_KEY=API_KEY, API_SECRET=API_SECRET, API_BASE_URL=API_BASE_URL\n    )",
        "detail": "unit_tests.downloaders.test_alpaca_downloader",
        "documentation": {}
    },
    {
        "label": "API_KEY",
        "kind": 5,
        "importPath": "unit_tests.downloaders.test_alpaca_downloader",
        "description": "unit_tests.downloaders.test_alpaca_downloader",
        "peekOfCode": "API_KEY = \"???\"\nAPI_SECRET = \"???\"\nAPI_BASE_URL = \"https://paper-api.alpaca.markets\"\ndata_url = \"wss://data.alpaca.markets\"\n@pytest.fixture(scope=\"session\")\ndef ticker_list():\n    return [\"AAPL\", \"GOOG\"]\ndef test_intraDayBar_download(ticker_list):\n    # Given\n    start_date = \"2021-07-29\"",
        "detail": "unit_tests.downloaders.test_alpaca_downloader",
        "documentation": {}
    },
    {
        "label": "API_SECRET",
        "kind": 5,
        "importPath": "unit_tests.downloaders.test_alpaca_downloader",
        "description": "unit_tests.downloaders.test_alpaca_downloader",
        "peekOfCode": "API_SECRET = \"???\"\nAPI_BASE_URL = \"https://paper-api.alpaca.markets\"\ndata_url = \"wss://data.alpaca.markets\"\n@pytest.fixture(scope=\"session\")\ndef ticker_list():\n    return [\"AAPL\", \"GOOG\"]\ndef test_intraDayBar_download(ticker_list):\n    # Given\n    start_date = \"2021-07-29\"\n    end_date = \"2021-07-30\"",
        "detail": "unit_tests.downloaders.test_alpaca_downloader",
        "documentation": {}
    },
    {
        "label": "API_BASE_URL",
        "kind": 5,
        "importPath": "unit_tests.downloaders.test_alpaca_downloader",
        "description": "unit_tests.downloaders.test_alpaca_downloader",
        "peekOfCode": "API_BASE_URL = \"https://paper-api.alpaca.markets\"\ndata_url = \"wss://data.alpaca.markets\"\n@pytest.fixture(scope=\"session\")\ndef ticker_list():\n    return [\"AAPL\", \"GOOG\"]\ndef test_intraDayBar_download(ticker_list):\n    # Given\n    start_date = \"2021-07-29\"\n    end_date = \"2021-07-30\"\n    time_interval = \"1H\"",
        "detail": "unit_tests.downloaders.test_alpaca_downloader",
        "documentation": {}
    },
    {
        "label": "data_url",
        "kind": 5,
        "importPath": "unit_tests.downloaders.test_alpaca_downloader",
        "description": "unit_tests.downloaders.test_alpaca_downloader",
        "peekOfCode": "data_url = \"wss://data.alpaca.markets\"\n@pytest.fixture(scope=\"session\")\ndef ticker_list():\n    return [\"AAPL\", \"GOOG\"]\ndef test_intraDayBar_download(ticker_list):\n    # Given\n    start_date = \"2021-07-29\"\n    end_date = \"2021-07-30\"\n    time_interval = \"1H\"\n    ticker_list = [\"AAPL\", \"GOOG\"]",
        "detail": "unit_tests.downloaders.test_alpaca_downloader",
        "documentation": {}
    },
    {
        "label": "ticker_list",
        "kind": 2,
        "importPath": "unit_tests.downloaders.test_yahoo_downloader",
        "description": "unit_tests.downloaders.test_yahoo_downloader",
        "peekOfCode": "def ticker_list():\n    return [\"AAPL\", \"GOOG\"]\ndef test_download(ticker_list):\n    df = YahooDownloader(\n        start_date=\"2019-01-01\", end_date=\"2019-02-01\", ticker_list=ticker_list\n    ).fetch_data()\n    assert isinstance(df, pd.DataFrame)",
        "detail": "unit_tests.downloaders.test_yahoo_downloader",
        "documentation": {}
    },
    {
        "label": "test_download",
        "kind": 2,
        "importPath": "unit_tests.downloaders.test_yahoo_downloader",
        "description": "unit_tests.downloaders.test_yahoo_downloader",
        "peekOfCode": "def test_download(ticker_list):\n    df = YahooDownloader(\n        start_date=\"2019-01-01\", end_date=\"2019-02-01\", ticker_list=ticker_list\n    ).fetch_data()\n    assert isinstance(df, pd.DataFrame)",
        "detail": "unit_tests.downloaders.test_yahoo_downloader",
        "documentation": {}
    },
    {
        "label": "ticker_list",
        "kind": 2,
        "importPath": "unit_tests.environments.test_cash_penalty",
        "description": "unit_tests.environments.test_cash_penalty",
        "peekOfCode": "def ticker_list():\n    return [\"AAPL\", \"GOOG\"]\n@pytest.fixture(scope=\"session\")\ndef indicator_list():\n    return [\"open\", \"close\", \"high\", \"low\", \"volume\"]\n@pytest.fixture(scope=\"session\")\ndef data(ticker_list):\n    return YahooDownloader(\n        start_date=\"2019-01-01\", end_date=\"2019-02-01\", ticker_list=ticker_list\n    ).fetch_data()",
        "detail": "unit_tests.environments.test_cash_penalty",
        "documentation": {}
    },
    {
        "label": "indicator_list",
        "kind": 2,
        "importPath": "unit_tests.environments.test_cash_penalty",
        "description": "unit_tests.environments.test_cash_penalty",
        "peekOfCode": "def indicator_list():\n    return [\"open\", \"close\", \"high\", \"low\", \"volume\"]\n@pytest.fixture(scope=\"session\")\ndef data(ticker_list):\n    return YahooDownloader(\n        start_date=\"2019-01-01\", end_date=\"2019-02-01\", ticker_list=ticker_list\n    ).fetch_data()\ndef test_zero_step(data, ticker_list):\n    # Prove that zero actions results in zero stock buys, and no price changes\n    init_amt = 1e6",
        "detail": "unit_tests.environments.test_cash_penalty",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 2,
        "importPath": "unit_tests.environments.test_cash_penalty",
        "description": "unit_tests.environments.test_cash_penalty",
        "peekOfCode": "def data(ticker_list):\n    return YahooDownloader(\n        start_date=\"2019-01-01\", end_date=\"2019-02-01\", ticker_list=ticker_list\n    ).fetch_data()\ndef test_zero_step(data, ticker_list):\n    # Prove that zero actions results in zero stock buys, and no price changes\n    init_amt = 1e6\n    env = StockTradingEnvCashpenalty(\n        df=data, initial_amount=init_amt, cache_indicator_data=False\n    )",
        "detail": "unit_tests.environments.test_cash_penalty",
        "documentation": {}
    },
    {
        "label": "test_zero_step",
        "kind": 2,
        "importPath": "unit_tests.environments.test_cash_penalty",
        "description": "unit_tests.environments.test_cash_penalty",
        "peekOfCode": "def test_zero_step(data, ticker_list):\n    # Prove that zero actions results in zero stock buys, and no price changes\n    init_amt = 1e6\n    env = StockTradingEnvCashpenalty(\n        df=data, initial_amount=init_amt, cache_indicator_data=False\n    )\n    _ = env.reset()\n    # step with all zeros\n    for i in range(2):\n        actions = np.zeros(len(ticker_list))",
        "detail": "unit_tests.environments.test_cash_penalty",
        "documentation": {}
    },
    {
        "label": "test_patient",
        "kind": 2,
        "importPath": "unit_tests.environments.test_cash_penalty",
        "description": "unit_tests.environments.test_cash_penalty",
        "peekOfCode": "def test_patient(data, ticker_list):\n    # Prove that we just not buying any new assets if running out of cash and the cycle is not ended\n    aapl_first_close = data[data[\"tic\"] == \"AAPL\"].head(1)[\"close\"].values[0]\n    init_amt = aapl_first_close\n    hmax = aapl_first_close * 100\n    env = StockTradingEnvCashpenalty(\n        df=data,\n        initial_amount=init_amt,\n        hmax=hmax,\n        cache_indicator_data=False,",
        "detail": "unit_tests.environments.test_cash_penalty",
        "documentation": {}
    },
    {
        "label": "test_cost_penalties",
        "kind": 2,
        "importPath": "unit_tests.environments.test_cash_penalty",
        "description": "unit_tests.environments.test_cash_penalty",
        "peekOfCode": "def test_cost_penalties():\n    raise NotImplementedError\n@pytest.mark.xfail(reason=\"Not implemented\")\ndef test_purchases():\n    raise NotImplementedError\n@pytest.mark.xfail(reason=\"Not implemented\")\ndef test_gains():\n    raise NotImplementedError\n@pytest.mark.skip(reason=\"this test is not working correctly\")\ndef test_validate_caching(data):",
        "detail": "unit_tests.environments.test_cash_penalty",
        "documentation": {}
    },
    {
        "label": "test_purchases",
        "kind": 2,
        "importPath": "unit_tests.environments.test_cash_penalty",
        "description": "unit_tests.environments.test_cash_penalty",
        "peekOfCode": "def test_purchases():\n    raise NotImplementedError\n@pytest.mark.xfail(reason=\"Not implemented\")\ndef test_gains():\n    raise NotImplementedError\n@pytest.mark.skip(reason=\"this test is not working correctly\")\ndef test_validate_caching(data):\n    # prove that results with or without caching don't change anything\n    init_amt = 1e6\n    env_uncached = StockTradingEnvCashpenalty(",
        "detail": "unit_tests.environments.test_cash_penalty",
        "documentation": {}
    },
    {
        "label": "test_gains",
        "kind": 2,
        "importPath": "unit_tests.environments.test_cash_penalty",
        "description": "unit_tests.environments.test_cash_penalty",
        "peekOfCode": "def test_gains():\n    raise NotImplementedError\n@pytest.mark.skip(reason=\"this test is not working correctly\")\ndef test_validate_caching(data):\n    # prove that results with or without caching don't change anything\n    init_amt = 1e6\n    env_uncached = StockTradingEnvCashpenalty(\n        df=data, initial_amount=init_amt, cache_indicator_data=False\n    )\n    env_cached = StockTradingEnvCashpenalty(",
        "detail": "unit_tests.environments.test_cash_penalty",
        "documentation": {}
    },
    {
        "label": "test_validate_caching",
        "kind": 2,
        "importPath": "unit_tests.environments.test_cash_penalty",
        "description": "unit_tests.environments.test_cash_penalty",
        "peekOfCode": "def test_validate_caching(data):\n    # prove that results with or without caching don't change anything\n    init_amt = 1e6\n    env_uncached = StockTradingEnvCashpenalty(\n        df=data, initial_amount=init_amt, cache_indicator_data=False\n    )\n    env_cached = StockTradingEnvCashpenalty(\n        df=data, initial_amount=init_amt, cache_indicator_data=True\n    )\n    _ = env_uncached.reset()",
        "detail": "unit_tests.environments.test_cash_penalty",
        "documentation": {}
    },
    {
        "label": "test_fit_transform",
        "kind": 2,
        "importPath": "unit_tests.preprocessors.test_groupby_scaler",
        "description": "unit_tests.preprocessors.test_groupby_scaler",
        "peekOfCode": "def test_fit_transform():\n    scaler = GroupByScaler(by=\"tic\")\n    transformed_df = scaler.fit_transform(test_dataframe)\n    assert pytest.approx(transformed_df[\"feature_1\"].tolist()) == [\n        5 / 9,\n        1 / 4,\n        1.0,\n        1.0,\n        0.0,\n        5 / 12,",
        "detail": "unit_tests.preprocessors.test_groupby_scaler",
        "documentation": {}
    },
    {
        "label": "test_fit_transform_specific_column",
        "kind": 2,
        "importPath": "unit_tests.preprocessors.test_groupby_scaler",
        "description": "unit_tests.preprocessors.test_groupby_scaler",
        "peekOfCode": "def test_fit_transform_specific_column():\n    scaler = GroupByScaler(by=\"tic\", columns=[\"feature_1\"])\n    transformed_df = scaler.fit_transform(test_dataframe)\n    assert pytest.approx(transformed_df[\"feature_1\"].tolist()) == [\n        5 / 9,\n        1 / 4,\n        1.0,\n        1.0,\n        0.0,\n        5 / 12,",
        "detail": "unit_tests.preprocessors.test_groupby_scaler",
        "documentation": {}
    },
    {
        "label": "test_fit_transform_other_df",
        "kind": 2,
        "importPath": "unit_tests.preprocessors.test_groupby_scaler",
        "description": "unit_tests.preprocessors.test_groupby_scaler",
        "peekOfCode": "def test_fit_transform_other_df():\n    scaler = GroupByScaler(by=\"tic\")\n    scaler.fit(test_dataframe)\n    another_dataframe = pd.DataFrame(\n        {\n            \"tic\": [\"A\", \"B\", \"A\", \"B\"],\n            \"feature_1\": [7.0, 5.0, 8.0, 10.0],\n            \"feature_2\": [1.0, 3.0, 2.0, 5.0],\n        }\n    )",
        "detail": "unit_tests.preprocessors.test_groupby_scaler",
        "documentation": {}
    },
    {
        "label": "test_minmax_fit_transform",
        "kind": 2,
        "importPath": "unit_tests.preprocessors.test_groupby_scaler",
        "description": "unit_tests.preprocessors.test_groupby_scaler",
        "peekOfCode": "def test_minmax_fit_transform():\n    scaler = GroupByScaler(by=\"tic\", scaler=MinMaxScaler)\n    transformed_df = scaler.fit_transform(test_dataframe)\n    assert pytest.approx(transformed_df[\"feature_1\"].tolist()) == [\n        5 / 9,\n        0.0,\n        1.0,\n        1.0,\n        0.0,\n        2 / 9,",
        "detail": "unit_tests.preprocessors.test_groupby_scaler",
        "documentation": {}
    },
    {
        "label": "test_minmax_fit_transform_specific_column",
        "kind": 2,
        "importPath": "unit_tests.preprocessors.test_groupby_scaler",
        "description": "unit_tests.preprocessors.test_groupby_scaler",
        "peekOfCode": "def test_minmax_fit_transform_specific_column():\n    scaler = GroupByScaler(by=\"tic\", scaler=MinMaxScaler, columns=[\"feature_1\"])\n    transformed_df = scaler.fit_transform(test_dataframe)\n    assert pytest.approx(transformed_df[\"feature_1\"].tolist()) == [\n        5 / 9,\n        0.0,\n        1.0,\n        1.0,\n        0.0,\n        2 / 9,",
        "detail": "unit_tests.preprocessors.test_groupby_scaler",
        "documentation": {}
    },
    {
        "label": "test_minmax_fit_transform_other_df",
        "kind": 2,
        "importPath": "unit_tests.preprocessors.test_groupby_scaler",
        "description": "unit_tests.preprocessors.test_groupby_scaler",
        "peekOfCode": "def test_minmax_fit_transform_other_df():\n    scaler = GroupByScaler(by=\"tic\", scaler=MinMaxScaler)\n    scaler.fit(test_dataframe)\n    another_dataframe = pd.DataFrame(\n        {\n            \"tic\": [\"A\", \"B\", \"A\", \"B\"],\n            \"feature_1\": [7.0, 5.0, 8.0, 10.0],\n            \"feature_2\": [1.0, 3.0, 2.0, 5.0],\n        }\n    )",
        "detail": "unit_tests.preprocessors.test_groupby_scaler",
        "documentation": {}
    },
    {
        "label": "test_dataframe",
        "kind": 5,
        "importPath": "unit_tests.preprocessors.test_groupby_scaler",
        "description": "unit_tests.preprocessors.test_groupby_scaler",
        "peekOfCode": "test_dataframe = pd.DataFrame(\n    {\n        \"tic\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\"],\n        \"feature_1\": [5.0, 3.0, 9.0, 12.0, 0.0, 5.0],\n        \"feature_2\": [9.0, 11.0, 7.0, 3.0, 9.0, 13.0],\n    }\n)\ndef test_fit_transform():\n    scaler = GroupByScaler(by=\"tic\")\n    transformed_df = scaler.fit_transform(test_dataframe)",
        "detail": "unit_tests.preprocessors.test_groupby_scaler",
        "documentation": {}
    },
    {
        "label": "DIRS",
        "kind": 2,
        "importPath": "unit_tests.test_core",
        "description": "unit_tests.test_core",
        "peekOfCode": "def DIRS():\n    return [DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR]\n@pytest.fixture(scope=\"session\")\ndef ticker_list():\n    return config_tickers.DOW_30_TICKER\n@pytest.fixture(scope=\"session\")\ndef ticker_list_small():\n    return [\"AAPL\", \"GOOG\"]\n@pytest.fixture(scope=\"session\")\ndef indicators():",
        "detail": "unit_tests.test_core",
        "documentation": {}
    },
    {
        "label": "ticker_list",
        "kind": 2,
        "importPath": "unit_tests.test_core",
        "description": "unit_tests.test_core",
        "peekOfCode": "def ticker_list():\n    return config_tickers.DOW_30_TICKER\n@pytest.fixture(scope=\"session\")\ndef ticker_list_small():\n    return [\"AAPL\", \"GOOG\"]\n@pytest.fixture(scope=\"session\")\ndef indicators():\n    return config.INDICATORS\n@pytest.fixture(scope=\"session\")\ndef old_start_date():",
        "detail": "unit_tests.test_core",
        "documentation": {}
    },
    {
        "label": "ticker_list_small",
        "kind": 2,
        "importPath": "unit_tests.test_core",
        "description": "unit_tests.test_core",
        "peekOfCode": "def ticker_list_small():\n    return [\"AAPL\", \"GOOG\"]\n@pytest.fixture(scope=\"session\")\ndef indicators():\n    return config.INDICATORS\n@pytest.fixture(scope=\"session\")\ndef old_start_date():\n    return \"2009-01-01\"\n@pytest.fixture(scope=\"session\")\ndef start_date():",
        "detail": "unit_tests.test_core",
        "documentation": {}
    },
    {
        "label": "indicators",
        "kind": 2,
        "importPath": "unit_tests.test_core",
        "description": "unit_tests.test_core",
        "peekOfCode": "def indicators():\n    return config.INDICATORS\n@pytest.fixture(scope=\"session\")\ndef old_start_date():\n    return \"2009-01-01\"\n@pytest.fixture(scope=\"session\")\ndef start_date():\n    return \"2021-01-01\"\n@pytest.fixture(scope=\"session\")\ndef end_date():",
        "detail": "unit_tests.test_core",
        "documentation": {}
    },
    {
        "label": "old_start_date",
        "kind": 2,
        "importPath": "unit_tests.test_core",
        "description": "unit_tests.test_core",
        "peekOfCode": "def old_start_date():\n    return \"2009-01-01\"\n@pytest.fixture(scope=\"session\")\ndef start_date():\n    return \"2021-01-01\"\n@pytest.fixture(scope=\"session\")\ndef end_date():\n    return \"2021-10-31\"\ndef test_check_and_make_directories(DIRS: list[str]) -> None:\n    \"\"\"",
        "detail": "unit_tests.test_core",
        "documentation": {}
    },
    {
        "label": "start_date",
        "kind": 2,
        "importPath": "unit_tests.test_core",
        "description": "unit_tests.test_core",
        "peekOfCode": "def start_date():\n    return \"2021-01-01\"\n@pytest.fixture(scope=\"session\")\ndef end_date():\n    return \"2021-10-31\"\ndef test_check_and_make_directories(DIRS: list[str]) -> None:\n    \"\"\"\n    Tests the creation of directories\n    parameters:\n    ----------",
        "detail": "unit_tests.test_core",
        "documentation": {}
    },
    {
        "label": "end_date",
        "kind": 2,
        "importPath": "unit_tests.test_core",
        "description": "unit_tests.test_core",
        "peekOfCode": "def end_date():\n    return \"2021-10-31\"\ndef test_check_and_make_directories(DIRS: list[str]) -> None:\n    \"\"\"\n    Tests the creation of directories\n    parameters:\n    ----------\n    DIRS : a List of str, which indicate the name of the folders to create\n    \"\"\"\n    assert isinstance(DIRS, list)",
        "detail": "unit_tests.test_core",
        "documentation": {}
    },
    {
        "label": "test_check_and_make_directories",
        "kind": 2,
        "importPath": "unit_tests.test_core",
        "description": "unit_tests.test_core",
        "peekOfCode": "def test_check_and_make_directories(DIRS: list[str]) -> None:\n    \"\"\"\n    Tests the creation of directories\n    parameters:\n    ----------\n    DIRS : a List of str, which indicate the name of the folders to create\n    \"\"\"\n    assert isinstance(DIRS, list)\n    check_and_make_directories(DIRS)\n    for dir in DIRS:",
        "detail": "unit_tests.test_core",
        "documentation": {}
    },
    {
        "label": "test_download_large",
        "kind": 2,
        "importPath": "unit_tests.test_core",
        "description": "unit_tests.test_core",
        "peekOfCode": "def test_download_large(ticker_list: list[str], start_date: str, end_date: str) -> None:\n    \"\"\"\n    Tests the Yahoo Downloader and the returned data shape\n    \"\"\"\n    assert isinstance(ticker_list, list)\n    assert len(ticker_list) > 0\n    assert isinstance(ticker_list[0], str)\n    assert isinstance(start_date, str)\n    assert isinstance(end_date, str)\n    df = YahooDownloader(",
        "detail": "unit_tests.test_core",
        "documentation": {}
    },
    {
        "label": "test_feature_engineer_no_turbulence",
        "kind": 2,
        "importPath": "unit_tests.test_core",
        "description": "unit_tests.test_core",
        "peekOfCode": "def test_feature_engineer_no_turbulence(\n    ticker_list: list[str],\n    indicators: list[str],\n    start_date: str,\n    end_date: str,\n) -> None:\n    \"\"\"\n    Tests the feature_engineer function - WIP\n    \"\"\"\n    assert isinstance(ticker_list, list)",
        "detail": "unit_tests.test_core",
        "documentation": {}
    },
    {
        "label": "test_feature_engineer_turbulence_less_than_a_year",
        "kind": 2,
        "importPath": "unit_tests.test_core",
        "description": "unit_tests.test_core",
        "peekOfCode": "def test_feature_engineer_turbulence_less_than_a_year(\n    ticker_list: list[str],\n    indicators: list[str],\n    start_date: str,\n    end_date: str,\n) -> None:\n    \"\"\"\n    Tests the feature_engineer function - with turbulence, start and end date\n    are less than 1 year apart.\n    the code should raise an error",
        "detail": "unit_tests.test_core",
        "documentation": {}
    },
    {
        "label": "test_feature_engineer_turbulence_more_than_a_year",
        "kind": 2,
        "importPath": "unit_tests.test_core",
        "description": "unit_tests.test_core",
        "peekOfCode": "def test_feature_engineer_turbulence_more_than_a_year(\n    ticker_list: list[str],\n    indicators: list[str],\n    old_start_date: str,\n    end_date: str,\n) -> None:\n    \"\"\"\n    Tests the feature_engineer function - with turbulence, start and end date\n    are less than 1 year apart.\n    the code should raise an error",
        "detail": "unit_tests.test_core",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "kind": 6,
        "importPath": "venv.bin.pwiz",
        "description": "venv.bin.pwiz",
        "peekOfCode": "class BaseModel(Model):\n    class Meta:\n        database = database\n\"\"\"\nUNKNOWN_FIELD = \"\"\"\\\nclass UnknownField(object):\n    def __init__(self, *_, **__): pass\n\"\"\"\nDATABASE_ALIASES = {\n    CockroachDatabase: ['cockroach', 'cockroachdb', 'crdb'],",
        "detail": "venv.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "UnknownField",
        "kind": 6,
        "importPath": "venv.bin.pwiz",
        "description": "venv.bin.pwiz",
        "peekOfCode": "class UnknownField(object):\n    def __init__(self, *_, **__): pass\n\"\"\"\nDATABASE_ALIASES = {\n    CockroachDatabase: ['cockroach', 'cockroachdb', 'crdb'],\n    MySQLDatabase: ['mysql', 'mysqldb'],\n    PostgresqlDatabase: ['postgres', 'postgresql'],\n    SqliteDatabase: ['sqlite', 'sqlite3'],\n}\nDATABASE_MAP = dict((value, key)",
        "detail": "venv.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "make_introspector",
        "kind": 2,
        "importPath": "venv.bin.pwiz",
        "description": "venv.bin.pwiz",
        "peekOfCode": "def make_introspector(database_type, database_name, **kwargs):\n    if database_type not in DATABASE_MAP:\n        err('Unrecognized database, must be one of: %s' %\n            ', '.join(DATABASE_MAP.keys()))\n        sys.exit(1)\n    schema = kwargs.pop('schema', None)\n    DatabaseClass = DATABASE_MAP[database_type]\n    db = DatabaseClass(database_name, **kwargs)\n    return Introspector.from_database(db, schema=schema)\ndef print_models(introspector, tables=None, preserve_order=False,",
        "detail": "venv.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "print_models",
        "kind": 2,
        "importPath": "venv.bin.pwiz",
        "description": "venv.bin.pwiz",
        "peekOfCode": "def print_models(introspector, tables=None, preserve_order=False,\n                 include_views=False, ignore_unknown=False, snake_case=True):\n    database = introspector.introspect(table_names=tables,\n                                       include_views=include_views,\n                                       snake_case=snake_case)\n    db_kwargs = introspector.get_database_kwargs()\n    header = HEADER % (\n        introspector.get_additional_imports(),\n        introspector.get_database_class().__name__,\n        introspector.get_database_name(),",
        "detail": "venv.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "print_header",
        "kind": 2,
        "importPath": "venv.bin.pwiz",
        "description": "venv.bin.pwiz",
        "peekOfCode": "def print_header(cmd_line, introspector):\n    timestamp = datetime.datetime.now()\n    print_('# Code generated by:')\n    print_('# python -m pwiz %s' % cmd_line)\n    print_('# Date: %s' % timestamp.strftime('%B %d, %Y %I:%M%p'))\n    print_('# Database: %s' % introspector.get_database_name())\n    print_('# Peewee version: %s' % peewee_version)\n    print_('')\ndef err(msg):\n    sys.stderr.write('\\033[91m%s\\033[0m\\n' % msg)",
        "detail": "venv.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "err",
        "kind": 2,
        "importPath": "venv.bin.pwiz",
        "description": "venv.bin.pwiz",
        "peekOfCode": "def err(msg):\n    sys.stderr.write('\\033[91m%s\\033[0m\\n' % msg)\n    sys.stderr.flush()\ndef get_option_parser():\n    parser = OptionParser(usage='usage: %prog [options] database_name')\n    ao = parser.add_option\n    ao('-H', '--host', dest='host')\n    ao('-p', '--port', dest='port', type='int')\n    ao('-u', '--user', dest='user')\n    ao('-P', '--password', dest='password', action='store_true')",
        "detail": "venv.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "get_option_parser",
        "kind": 2,
        "importPath": "venv.bin.pwiz",
        "description": "venv.bin.pwiz",
        "peekOfCode": "def get_option_parser():\n    parser = OptionParser(usage='usage: %prog [options] database_name')\n    ao = parser.add_option\n    ao('-H', '--host', dest='host')\n    ao('-p', '--port', dest='port', type='int')\n    ao('-u', '--user', dest='user')\n    ao('-P', '--password', dest='password', action='store_true')\n    engines = sorted(DATABASE_MAP)\n    ao('-e', '--engine', dest='engine', choices=engines,\n       help=('Database type, e.g. sqlite, mysql, postgresql or cockroachdb. '",
        "detail": "venv.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "get_connect_kwargs",
        "kind": 2,
        "importPath": "venv.bin.pwiz",
        "description": "venv.bin.pwiz",
        "peekOfCode": "def get_connect_kwargs(options):\n    ops = ('host', 'port', 'user', 'schema')\n    kwargs = dict((o, getattr(options, o)) for o in ops if getattr(options, o))\n    if options.password:\n        kwargs['password'] = getpass()\n    return kwargs\nif __name__ == '__main__':\n    raw_argv = sys.argv\n    parser = get_option_parser()\n    options, args = parser.parse_args()",
        "detail": "venv.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "HEADER",
        "kind": 5,
        "importPath": "venv.bin.pwiz",
        "description": "venv.bin.pwiz",
        "peekOfCode": "HEADER = \"\"\"from peewee import *%s\ndatabase = %s('%s'%s)\n\"\"\"\nBASE_MODEL = \"\"\"\\\nclass BaseModel(Model):\n    class Meta:\n        database = database\n\"\"\"\nUNKNOWN_FIELD = \"\"\"\\\nclass UnknownField(object):",
        "detail": "venv.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "database",
        "kind": 5,
        "importPath": "venv.bin.pwiz",
        "description": "venv.bin.pwiz",
        "peekOfCode": "database = %s('%s'%s)\n\"\"\"\nBASE_MODEL = \"\"\"\\\nclass BaseModel(Model):\n    class Meta:\n        database = database\n\"\"\"\nUNKNOWN_FIELD = \"\"\"\\\nclass UnknownField(object):\n    def __init__(self, *_, **__): pass",
        "detail": "venv.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "BASE_MODEL",
        "kind": 5,
        "importPath": "venv.bin.pwiz",
        "description": "venv.bin.pwiz",
        "peekOfCode": "BASE_MODEL = \"\"\"\\\nclass BaseModel(Model):\n    class Meta:\n        database = database\n\"\"\"\nUNKNOWN_FIELD = \"\"\"\\\nclass UnknownField(object):\n    def __init__(self, *_, **__): pass\n\"\"\"\nDATABASE_ALIASES = {",
        "detail": "venv.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "UNKNOWN_FIELD",
        "kind": 5,
        "importPath": "venv.bin.pwiz",
        "description": "venv.bin.pwiz",
        "peekOfCode": "UNKNOWN_FIELD = \"\"\"\\\nclass UnknownField(object):\n    def __init__(self, *_, **__): pass\n\"\"\"\nDATABASE_ALIASES = {\n    CockroachDatabase: ['cockroach', 'cockroachdb', 'crdb'],\n    MySQLDatabase: ['mysql', 'mysqldb'],\n    PostgresqlDatabase: ['postgres', 'postgresql'],\n    SqliteDatabase: ['sqlite', 'sqlite3'],\n}",
        "detail": "venv.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "DATABASE_ALIASES",
        "kind": 5,
        "importPath": "venv.bin.pwiz",
        "description": "venv.bin.pwiz",
        "peekOfCode": "DATABASE_ALIASES = {\n    CockroachDatabase: ['cockroach', 'cockroachdb', 'crdb'],\n    MySQLDatabase: ['mysql', 'mysqldb'],\n    PostgresqlDatabase: ['postgres', 'postgresql'],\n    SqliteDatabase: ['sqlite', 'sqlite3'],\n}\nDATABASE_MAP = dict((value, key)\n                    for key in DATABASE_ALIASES\n                    for value in DATABASE_ALIASES[key])\ndef make_introspector(database_type, database_name, **kwargs):",
        "detail": "venv.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "DATABASE_MAP",
        "kind": 5,
        "importPath": "venv.bin.pwiz",
        "description": "venv.bin.pwiz",
        "peekOfCode": "DATABASE_MAP = dict((value, key)\n                    for key in DATABASE_ALIASES\n                    for value in DATABASE_ALIASES[key])\ndef make_introspector(database_type, database_name, **kwargs):\n    if database_type not in DATABASE_MAP:\n        err('Unrecognized database, must be one of: %s' %\n            ', '.join(DATABASE_MAP.keys()))\n        sys.exit(1)\n    schema = kwargs.pop('schema', None)\n    DatabaseClass = DATABASE_MAP[database_type]",
        "detail": "venv.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "description",
        "kind": 5,
        "importPath": "venv.bin.rst2html",
        "description": "venv.bin.rst2html",
        "peekOfCode": "description = ('Generates (X)HTML documents from standalone reStructuredText '\n               'sources.  ' + default_description)\npublish_cmdline(writer_name='html', description=description)",
        "detail": "venv.bin.rst2html",
        "documentation": {}
    },
    {
        "label": "description",
        "kind": 5,
        "importPath": "venv.bin.rst2html4",
        "description": "venv.bin.rst2html4",
        "peekOfCode": "description = ('Generates (X)HTML documents from standalone reStructuredText '\n               'sources.  ' + default_description)\npublish_cmdline(writer_name='html4', description=description)",
        "detail": "venv.bin.rst2html4",
        "documentation": {}
    },
    {
        "label": "description",
        "kind": 5,
        "importPath": "venv.bin.rst2html5",
        "description": "venv.bin.rst2html5",
        "peekOfCode": "description = ('Generates HTML5 documents from standalone '\n               'reStructuredText sources.\\n'\n               + default_description)\npublish_cmdline(writer_name='html5', description=description)",
        "detail": "venv.bin.rst2html5",
        "documentation": {}
    },
    {
        "label": "description",
        "kind": 5,
        "importPath": "venv.bin.rst2latex",
        "description": "venv.bin.rst2latex",
        "peekOfCode": "description = ('Generates LaTeX documents from standalone reStructuredText '\n               'sources. '\n               'Reads from <source> (default is stdin) and writes to '\n               '<destination> (default is stdout).  See '\n               '<https://docutils.sourceforge.io/docs/user/latex.html> for '\n               'the full reference.')\npublish_cmdline(writer_name='latex', description=description)",
        "detail": "venv.bin.rst2latex",
        "documentation": {}
    },
    {
        "label": "description",
        "kind": 5,
        "importPath": "venv.bin.rst2man",
        "description": "venv.bin.rst2man",
        "peekOfCode": "description = (\"Generates plain unix manual documents.  \"\n               + default_description)\npublish_cmdline(writer=manpage.Writer(), description=description)",
        "detail": "venv.bin.rst2man",
        "documentation": {}
    },
    {
        "label": "description",
        "kind": 5,
        "importPath": "venv.bin.rst2odt",
        "description": "venv.bin.rst2odt",
        "peekOfCode": "description = ('Generates OpenDocument/OpenOffice/ODF documents from '\n               'standalone reStructuredText sources.  ' + default_description)\nwriter = Writer()\nreader = Reader()\noutput = publish_cmdline_to_binary(reader=reader, writer=writer,\n                                   description=description)",
        "detail": "venv.bin.rst2odt",
        "documentation": {}
    },
    {
        "label": "writer",
        "kind": 5,
        "importPath": "venv.bin.rst2odt",
        "description": "venv.bin.rst2odt",
        "peekOfCode": "writer = Writer()\nreader = Reader()\noutput = publish_cmdline_to_binary(reader=reader, writer=writer,\n                                   description=description)",
        "detail": "venv.bin.rst2odt",
        "documentation": {}
    },
    {
        "label": "reader",
        "kind": 5,
        "importPath": "venv.bin.rst2odt",
        "description": "venv.bin.rst2odt",
        "peekOfCode": "reader = Reader()\noutput = publish_cmdline_to_binary(reader=reader, writer=writer,\n                                   description=description)",
        "detail": "venv.bin.rst2odt",
        "documentation": {}
    },
    {
        "label": "output",
        "kind": 5,
        "importPath": "venv.bin.rst2odt",
        "description": "venv.bin.rst2odt",
        "peekOfCode": "output = publish_cmdline_to_binary(reader=reader, writer=writer,\n                                   description=description)",
        "detail": "venv.bin.rst2odt",
        "documentation": {}
    },
    {
        "label": "description",
        "kind": 5,
        "importPath": "venv.bin.rst2pseudoxml",
        "description": "venv.bin.rst2pseudoxml",
        "peekOfCode": "description = ('Generates pseudo-XML from standalone reStructuredText '\n               'sources (for testing purposes).  ' + default_description)\npublish_cmdline(description=description)",
        "detail": "venv.bin.rst2pseudoxml",
        "documentation": {}
    },
    {
        "label": "description",
        "kind": 5,
        "importPath": "venv.bin.rst2s5",
        "description": "venv.bin.rst2s5",
        "peekOfCode": "description = ('Generates S5 (X)HTML slideshow documents from standalone '\n               'reStructuredText sources.  ' + default_description)\npublish_cmdline(writer_name='s5', description=description)",
        "detail": "venv.bin.rst2s5",
        "documentation": {}
    },
    {
        "label": "description",
        "kind": 5,
        "importPath": "venv.bin.rst2xetex",
        "description": "venv.bin.rst2xetex",
        "peekOfCode": "description = ('Generates LaTeX documents from standalone reStructuredText '\n               'sources for compilation with the Unicode-aware TeX variants '\n               'XeLaTeX or LuaLaTeX. '\n               'Reads from <source> (default is stdin) and writes to '\n               '<destination> (default is stdout).  See '\n               '<https://docutils.sourceforge.io/docs/user/latex.html> for '\n               'the full reference.')\npublish_cmdline(writer_name='xetex', description=description)",
        "detail": "venv.bin.rst2xetex",
        "documentation": {}
    },
    {
        "label": "description",
        "kind": 5,
        "importPath": "venv.bin.rst2xml",
        "description": "venv.bin.rst2xml",
        "peekOfCode": "description = ('Generates Docutils-native XML from standalone '\n               'reStructuredText sources.  ' + default_description)\npublish_cmdline(writer_name='xml', description=description)",
        "detail": "venv.bin.rst2xml",
        "documentation": {}
    },
    {
        "label": "description",
        "kind": 5,
        "importPath": "venv.bin.rstpep2html",
        "description": "venv.bin.rstpep2html",
        "peekOfCode": "description = ('Generates (X)HTML from reStructuredText-format PEP files.  '\n               + default_description)\npublish_cmdline(reader_name='pep', writer_name='pep_html',\n                description=description)",
        "detail": "venv.bin.rstpep2html",
        "documentation": {}
    },
    {
        "label": "SinopacProcessor",
        "kind": 6,
        "importPath": "processor_sinopac",
        "description": "processor_sinopac",
        "peekOfCode": "class SinopacProcessor:\n    def __init__(self, API_KEY=None, API_SECRET=None, api=None):\n        if api is None:\n            try:\n                self.api = sj.Shioaji()\n                self.api.login(\n                    api_key=API_KEY,\n                    secret_key=API_SECRET,\n                    contracts_cb=lambda security_type: print(\n                        f\"{repr(security_type)} fetch done.\"",
        "detail": "processor_sinopac",
        "documentation": {}
    },
    {
        "label": "API_KEY",
        "kind": 5,
        "importPath": "t7",
        "description": "t7",
        "peekOfCode": "API_KEY = \"PKVD6WOSPEMKS0UI6A3K\"\nAPI_SECRET = \"RJICB6GmO6FPff1e8pGq5IArPYabYi2ZaAqpHEar\"\nAPI_BASE_URL = 'https://paper-api.alpaca.markets'\nAPACA_EMAIL =  \"dpeles20@gmail.com\"\nAPACA_PWD1 = \"102774Dov9012\"\nAPACA_PWD2 = \"f1ecd682-009e-49fc-893e-bc595cc4e015\"\n# Initialize the Alpaca API\napi = tradeapi.REST(API_KEY, API_SECRET, API_BASE_URL, api_version='v2')\n# Specify the stock symbol and quantity you want to buy\nsymbol = \"AAPL\"",
        "detail": "t7",
        "documentation": {}
    },
    {
        "label": "API_SECRET",
        "kind": 5,
        "importPath": "t7",
        "description": "t7",
        "peekOfCode": "API_SECRET = \"RJICB6GmO6FPff1e8pGq5IArPYabYi2ZaAqpHEar\"\nAPI_BASE_URL = 'https://paper-api.alpaca.markets'\nAPACA_EMAIL =  \"dpeles20@gmail.com\"\nAPACA_PWD1 = \"102774Dov9012\"\nAPACA_PWD2 = \"f1ecd682-009e-49fc-893e-bc595cc4e015\"\n# Initialize the Alpaca API\napi = tradeapi.REST(API_KEY, API_SECRET, API_BASE_URL, api_version='v2')\n# Specify the stock symbol and quantity you want to buy\nsymbol = \"AAPL\"\nquantity = 10  # Number of shares to buy",
        "detail": "t7",
        "documentation": {}
    },
    {
        "label": "API_BASE_URL",
        "kind": 5,
        "importPath": "t7",
        "description": "t7",
        "peekOfCode": "API_BASE_URL = 'https://paper-api.alpaca.markets'\nAPACA_EMAIL =  \"dpeles20@gmail.com\"\nAPACA_PWD1 = \"102774Dov9012\"\nAPACA_PWD2 = \"f1ecd682-009e-49fc-893e-bc595cc4e015\"\n# Initialize the Alpaca API\napi = tradeapi.REST(API_KEY, API_SECRET, API_BASE_URL, api_version='v2')\n# Specify the stock symbol and quantity you want to buy\nsymbol = \"AAPL\"\nquantity = 10  # Number of shares to buy\n# limit, stop, stop_limit orders. ",
        "detail": "t7",
        "documentation": {}
    },
    {
        "label": "APACA_EMAIL",
        "kind": 5,
        "importPath": "t7",
        "description": "t7",
        "peekOfCode": "APACA_EMAIL =  \"dpeles20@gmail.com\"\nAPACA_PWD1 = \"102774Dov9012\"\nAPACA_PWD2 = \"f1ecd682-009e-49fc-893e-bc595cc4e015\"\n# Initialize the Alpaca API\napi = tradeapi.REST(API_KEY, API_SECRET, API_BASE_URL, api_version='v2')\n# Specify the stock symbol and quantity you want to buy\nsymbol = \"AAPL\"\nquantity = 10  # Number of shares to buy\n# limit, stop, stop_limit orders. \n# Place a market order to buy the specified quantity of AAPL",
        "detail": "t7",
        "documentation": {}
    },
    {
        "label": "APACA_PWD1",
        "kind": 5,
        "importPath": "t7",
        "description": "t7",
        "peekOfCode": "APACA_PWD1 = \"102774Dov9012\"\nAPACA_PWD2 = \"f1ecd682-009e-49fc-893e-bc595cc4e015\"\n# Initialize the Alpaca API\napi = tradeapi.REST(API_KEY, API_SECRET, API_BASE_URL, api_version='v2')\n# Specify the stock symbol and quantity you want to buy\nsymbol = \"AAPL\"\nquantity = 10  # Number of shares to buy\n# limit, stop, stop_limit orders. \n# Place a market order to buy the specified quantity of AAPL\ntry:",
        "detail": "t7",
        "documentation": {}
    },
    {
        "label": "APACA_PWD2",
        "kind": 5,
        "importPath": "t7",
        "description": "t7",
        "peekOfCode": "APACA_PWD2 = \"f1ecd682-009e-49fc-893e-bc595cc4e015\"\n# Initialize the Alpaca API\napi = tradeapi.REST(API_KEY, API_SECRET, API_BASE_URL, api_version='v2')\n# Specify the stock symbol and quantity you want to buy\nsymbol = \"AAPL\"\nquantity = 10  # Number of shares to buy\n# limit, stop, stop_limit orders. \n# Place a market order to buy the specified quantity of AAPL\ntry:\n    order = api.submit_order(",
        "detail": "t7",
        "documentation": {}
    },
    {
        "label": "api",
        "kind": 5,
        "importPath": "t7",
        "description": "t7",
        "peekOfCode": "api = tradeapi.REST(API_KEY, API_SECRET, API_BASE_URL, api_version='v2')\n# Specify the stock symbol and quantity you want to buy\nsymbol = \"AAPL\"\nquantity = 10  # Number of shares to buy\n# limit, stop, stop_limit orders. \n# Place a market order to buy the specified quantity of AAPL\ntry:\n    order = api.submit_order(\n        symbol=symbol,\n        qty=quantity,",
        "detail": "t7",
        "documentation": {}
    },
    {
        "label": "symbol",
        "kind": 5,
        "importPath": "t7",
        "description": "t7",
        "peekOfCode": "symbol = \"AAPL\"\nquantity = 10  # Number of shares to buy\n# limit, stop, stop_limit orders. \n# Place a market order to buy the specified quantity of AAPL\ntry:\n    order = api.submit_order(\n        symbol=symbol,\n        qty=quantity,\n        side='buy', # buy or sell order for a security \n        type='market',  # Market order to be executed immediately at the current market price    ",
        "detail": "t7",
        "documentation": {}
    },
    {
        "label": "quantity",
        "kind": 5,
        "importPath": "t7",
        "description": "t7",
        "peekOfCode": "quantity = 10  # Number of shares to buy\n# limit, stop, stop_limit orders. \n# Place a market order to buy the specified quantity of AAPL\ntry:\n    order = api.submit_order(\n        symbol=symbol,\n        qty=quantity,\n        side='buy', # buy or sell order for a security \n        type='market',  # Market order to be executed immediately at the current market price    \n        time_in_force='gtc'  # Good 'til canceled",
        "detail": "t7",
        "documentation": {}
    }
]